{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c8d59ad3-40c7-494c-bd7e-509844f42d92",
   "metadata": {},
   "source": [
    "# Linear Assignment Problem"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "1cfee44e-47da-408c-87f9-bfb9e723215e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>.container { width:100% !important; }</style>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Force keras to run on CPU\n",
    "import os\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"\"\n",
    "\n",
    "# Notebook at full width in the browser\n",
    "from IPython.display import display, HTML\n",
    "display(HTML(\"<style>.container { width:100% !important; }</style>\"))\n",
    "\n",
    "import sys\n",
    "from urllib.request import urlretrieve\n",
    "from pathlib import Path\n",
    "from collections import defaultdict\n",
    "from abc import ABC, abstractmethod\n",
    "\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "matplotlib.rcParams[\"image.interpolation\"] = \"none\"\n",
    "matplotlib.rcParams['figure.figsize'] = (14, 10)\n",
    "import numpy as np\n",
    "from tifffile import imread, imwrite\n",
    "from tqdm.auto import tqdm\n",
    "import skimage\n",
    "import pandas as pd\n",
    "import scipy\n",
    "import pathlib\n",
    "# from stardist import fill_label_holes, random_label_cmap\n",
    "# from stardist.plot import render_label\n",
    "# from stardist.models import StarDist2D\n",
    "# from stardist import _draw_polygons\n",
    "# from csbdeep.utils import normalize\n",
    "\n",
    "# import napari\n",
    "\n",
    "# lbl_cmap = random_label_cmap()\n",
    "# # Pretty tqdm progress bars \n",
    "# ! jupyter nbextension enable --py widgetsnbextension"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b60da261-b95b-460b-90c2-7befbe1abd74",
   "metadata": {},
   "source": [
    "# Calculate Euclidean Distances"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f2981ca7-333b-4749-bd7b-0f3a4aa7d90f",
   "metadata": {},
   "source": [
    "## Calculate Centroids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "54c34ee7-e1bb-4030-b4ed-42fcee391b5f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# function to convert 'TRA' channel into cell and frame-wise centroid positions\n",
    "## Function to extract trajectories from data\n",
    "\n",
    "base_path = pathlib.Path(\"/mnt/shared/celltracking/data/cho/\")\n",
    "\n",
    "# read parent-child links from file\n",
    "links = np.loadtxt(base_path / \"01_GT/TRA\" / \"man_track.txt\", dtype=int)\n",
    "\n",
    "# read annotated image stack\n",
    "centroids = np.stack([imread(xi) for xi in sorted((base_path / \"01_GT/TRA\").glob(\"*.tif\"))])  # images\n",
    "\n",
    "# extract centroids from annotated image stacks\n",
    "centers = skimage.measure.regionprops(centroids[0,0,:,:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "9a611589-cbad-4257-84f6-188a3475a3ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Solution Exercise 1.3\n",
    "\n",
    "def pairwise_euclidian_distance(points0, points1):\n",
    "    print(\"Iterative pairwise euclidian distance\")\n",
    "    dists = []\n",
    "    for p0 in points0:\n",
    "        for p1 in points1:\n",
    "            dists.append(np.sqrt(((p0 - p1)**2).sum()))\n",
    "            \n",
    "    dists = np.array(dists).reshape(len(points0), len(points1))\n",
    "    return dists"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ed96942-2d86-4a91-b1b5-739dc1c5bb02",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "dae49da3-92d9-4018-8c96-8ce09ff0b40c",
   "metadata": {
    "tags": []
   },
   "source": [
    "Optimal frame-by-frame matching (Linear assignment problem or Weighted bipartite matching)\n",
    "The nearest neighbor algorithm above will not pick the best solution in many cases. For example, it does not consider the local arrangement of a few detections to create links, something which the human visual system is very good at.\n",
    "\n",
    "We need a better optimization algorithm to minimize the total minimal linking distance between two frames. To use a classic and efficient optimization algorithm, we will represent this linking problem as a bipartite graph. Here is an example:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "06ba7710-528e-46a3-a158-3e6595e11cf2",
   "metadata": {},
   "outputs": [],
   "source": [
    "class FrameByFrameLinker(ABC):\n",
    "    \"\"\"Abstract base class for linking detections by considering pairs of adjacent frames.\"\"\"\n",
    "    \n",
    "    def link(self, detections, images=None):\n",
    "        \"\"\"Links detections in t frames.\n",
    "        \n",
    "        Args:\n",
    "        \n",
    "            detections:\n",
    "            \n",
    "                List of t numpy arrays of shape (x,y) with contiguous label ids. Background = 0.\n",
    "                \n",
    "            images (optional):\n",
    "            \n",
    "                List of t numpy arrays of shape (x,y).\n",
    "        \n",
    "        Returns:\n",
    "        \n",
    "            Linking dictionary:\n",
    "                \"links\":\n",
    "                    \n",
    "                    Tuple of lists. Links from frame t to frame t+1 of form (from0, to0) are split up into two lists: \n",
    "                    - idgs_from: [from0, from1 , ...])\n",
    "                    - ids_to: [to0, to1 , ...])\n",
    "                \n",
    "                \"births\": List of ids from frame t that are \n",
    "                \"deaths\": List of ids.\n",
    "            Ids are one-based, 0 is reserved for background.\n",
    "        \"\"\"\n",
    "        if images is not None:\n",
    "            assert len(images) == len(detections)\n",
    "        else:\n",
    "            images = [None] * len(detections)\n",
    "\n",
    "        links = []\n",
    "        for i in tqdm(range(len(images) - 1), desc=\"Linking\"):\n",
    "            detections0 = detections[i]\n",
    "            detections1 = detections[i+1]\n",
    "            self._assert_relabeled(detections0)\n",
    "            self._assert_relabeled(detections1)\n",
    "            \n",
    "            cost_matrix = self.linking_cost_function(detections0, detections1, images[i], images[i+1])\n",
    "            li = self._link_two_frames(cost_matrix)\n",
    "            self._assert_links(links=li, time=i, detections0=detections0, detections1=detections1) \n",
    "            links.append(li)\n",
    "            \n",
    "        return links\n",
    "\n",
    "    @abstractmethod\n",
    "    def linking_cost_function(self, detections0, detections1, image0=None, image1=None):\n",
    "        \"\"\"Calculate features for each detection and extract pairwise costs.\n",
    "        \n",
    "        To be overwritten in subclass.\n",
    "        \n",
    "        Args:\n",
    "        \n",
    "            detections0: image with background 0 and detections 1, ..., m\n",
    "            detections1: image with backgruond 0 and detections 1, ..., n\n",
    "            image0 (optional): image corresponding to detections0\n",
    "            image1 (optional): image corresponding to detections1\n",
    "            \n",
    "        Returns:\n",
    "        \n",
    "            m x n cost matrix \n",
    "        \"\"\"\n",
    "        pass\n",
    "    \n",
    "    @abstractmethod\n",
    "    def _link_two_frames(self, cost_matrix):\n",
    "        \"\"\"Link two frames.\n",
    "        \n",
    "        To be overwritten in subclass.\n",
    "\n",
    "        Args:\n",
    "\n",
    "            cost_matrix: m x n matrix\n",
    "\n",
    "        Returns:\n",
    "        \n",
    "            \"links\":\n",
    "\n",
    "                Tuple of lists. Links from frame t to frame t+1 of form (from0, to0) are split up into two lists: \n",
    "                - idgs_from: [from0, from1 , ...])\n",
    "                - ids_to: [to0, to1 , ...])\n",
    "\n",
    "            \"births\": List of ids from frame t that are \n",
    "            \"deaths\": List of ids.\n",
    "            \n",
    "            Ids are one-based, 0 is reserved for background.\n",
    "        \"\"\"\n",
    "        pass\n",
    "\n",
    "    def relabel_detections(self, detections, links):\n",
    "        \"\"\"Relabel dense detections according to computed links, births and deaths.\n",
    "        \n",
    "        Args:\n",
    "        \n",
    "            detections: \n",
    "                 \n",
    "                 List of t numpy arrays of shape (x,y) with contiguous label ids. Background = 0.\n",
    "                 \n",
    "            links:\n",
    "                \n",
    "                List of t linking dictionaries, each containing:\n",
    "                    \"links\": Tuple of lists (ids frame t, ids frame t+1),\n",
    "                    \"births\": List of ids,\n",
    "                    \"deaths\": List of ids.\n",
    "                Ids are one-based, 0 is reserved for background.\n",
    "        \"\"\"\n",
    "        detections = detections.copy()\n",
    "        \n",
    "        assert len(detections) - 1 == len(links)\n",
    "        self._assert_relabeled(detections[0])\n",
    "        out = [detections[0]]\n",
    "        n_tracks = out[0].max()\n",
    "        lookup_tables = [{i: i for i in range(1, out[0].max() + 1)}]\n",
    "\n",
    "        for i in tqdm(range(len(links)), desc=\"Recoloring detections\"):\n",
    "            (ids_from, ids_to) = links[i][\"links\"]\n",
    "            births = links[i][\"births\"]\n",
    "            deaths = links[i+1][\"deaths\"] if i+1 < len(links) else []\n",
    "            new_frame = np.zeros_like(detections[i+1])\n",
    "            self._assert_relabeled(detections[i+1])\n",
    "            \n",
    "            lut = {}\n",
    "            for _from, _to in zip(ids_from, ids_to):\n",
    "                # Copy over ID\n",
    "                new_frame[detections[i+1] == _to] = lookup_tables[i][_from]\n",
    "                lut[_to] = lookup_tables[i][_from]\n",
    "\n",
    "            \n",
    "            # Start new track for birth tracks\n",
    "            for b in births:\n",
    "                if b in deaths:\n",
    "                    continue\n",
    "                \n",
    "                n_tracks += 1\n",
    "                lut[b] = n_tracks\n",
    "                new_frame[detections[i+1] == b] = n_tracks\n",
    "                \n",
    "            # print(lut)\n",
    "            lookup_tables.append(lut)\n",
    "            out.append(new_frame)\n",
    "                \n",
    "        return np.stack(out)\n",
    "\n",
    "    def _assert_links(self, links, time, detections0, detections1):\n",
    "        if len(links[\"links\"][0]) != len(links[\"links\"][1]):\n",
    "            raise RuntimeError(\"Format of links['links'] not correct.\")\n",
    "            \n",
    "        if sorted([*links[\"links\"][0], *links[\"deaths\"]]) != list(range(1, len(np.unique(detections0)))):\n",
    "            raise RuntimeError(f\"Some detections in frame {time} are not properly assigned as either linked or death.\")\n",
    "            \n",
    "        if sorted([*links[\"links\"][1], *links[\"births\"]]) != list(range(1, len(np.unique(detections1)))):\n",
    "            raise RuntimeError(f\"Some detections in frame {time + 1} are not properly assigned as either linked or birth.\")\n",
    "            \n",
    "        for b in links[\"births\"]:\n",
    "            if b in links[\"links\"][1]:\n",
    "                raise RuntimeError(f\"Links frame {time+1}: Detection {b} marked as birth, but also linked.\")\n",
    "        \n",
    "        for d in links[\"deaths\"]:\n",
    "            if d in links[\"links\"][0]:\n",
    "                raise RuntimeError(f\"Links frame {time}: Detection {d} marked as death, but also linked.\")\n",
    "        \n",
    "        \n",
    "    def _assert_relabeled(self, x):\n",
    "        if x.min() < 0:\n",
    "            raise ValueError(\"Negative ID in detections.\")\n",
    "        if x.min() == 0:\n",
    "            n = x.max() + 1\n",
    "        else:\n",
    "            n = x.max()\n",
    "        if n != len(np.unique(x)):\n",
    "            raise ValueError(\"Detection IDs are not contiguous.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "31179bee-ede5-42c9-a0c3-00c96920f59b",
   "metadata": {},
   "outputs": [],
   "source": [
    "class BipartiteMatchingLinker(FrameByFrameLinker):\n",
    "    \"\"\".\n",
    "    \n",
    "    Args:\n",
    "        threshold (float): Maximum euclidian distance for linking.\n",
    "        drift: tuple of (x,y) drift correction per frame.\n",
    "        birth_cost_factor (float): Multiply factor with maximum entry in cost matrix.\n",
    "        death_cost_factor (float): Multiply factor with maximum entry in cost matrix.\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(\n",
    "        self,\n",
    "        threshold=np.finfo(float).max,\n",
    "        drift=(0,0),\n",
    "        birth_cost_factor=1.05,\n",
    "        death_cost_factor=1.05,\n",
    "        *args,\n",
    "        **kwargs\n",
    "    ):\n",
    "        self.threshold = threshold\n",
    "        self.drift = np.array(drift)\n",
    "        self.birth_cost_factor = birth_cost_factor\n",
    "        self.death_cost_factor = death_cost_factor\n",
    "        \n",
    "        super().__init__(*args, **kwargs)\n",
    "        \n",
    "    def linking_cost_function(self, detections0, detections1, image0=None, image1=None):\n",
    "        \"\"\" Get centroids from detections and compute pairwise euclidian distances with drift correction.\n",
    "                \n",
    "        Args:\n",
    "        \n",
    "            detections0: image with background 0 and detections 1, ..., m\n",
    "            detections1: image with backgruond 0 and detections 1, ..., n\n",
    "            \n",
    "        Returns:\n",
    "        \n",
    "            m x n cost matrix \n",
    "        \"\"\"\n",
    "        # regionprops regions are sorted by label\n",
    "        regions0 = skimage.measure.regionprops(detections0)\n",
    "        points0 = [np.array(r.centroid) for r in regions0]\n",
    "        \n",
    "        regions1 = skimage.measure.regionprops(detections1)\n",
    "        points1 = [np.array(r.centroid) for r in regions1]\n",
    "        \n",
    "        dists = []\n",
    "        for p0 in points0:\n",
    "            for p1 in points1:\n",
    "                dists.append(np.sqrt(((p0 + self.drift - p1)**2).sum()))\n",
    "\n",
    "        dists = np.array(dists).reshape(len(points0), len(points1))\n",
    "        \n",
    "        return dists\n",
    "    \n",
    "    def _link_two_frames(self, cost_matrix):\n",
    "        \"\"\"Weighted bipartite matching with square matrix from Jaqaman et al (2008).\n",
    "\n",
    "        Args:\n",
    "\n",
    "            cost_matrix: m x n matrix.\n",
    "\n",
    "        Returns:\n",
    "            \"links\":\n",
    "    \n",
    "                Tuple of lists. Links from frame t to frame t+1 of form (from0, to0) are split up into two lists: \n",
    "                    - idgs_from: [from0, from1 , ...])\n",
    "                    - ids_to: [to0, to1 , ...])\n",
    "                \n",
    "                \"births\": List of ids from frame t that are \n",
    "                \"deaths\": List of ids.\n",
    "                \n",
    "            Ids are one-based, 0 is reserved for background.\n",
    "        \"\"\"\n",
    "        \n",
    "        cost_matrix = cost_matrix.copy().astype(float)\n",
    "        b = self.birth_cost_factor * min(self.threshold, cost_matrix.max())\n",
    "        d = self.death_cost_factor * min(self.threshold, cost_matrix.max())\n",
    "        no_link = max(cost_matrix.max(), max(b, d)) * 1e9\n",
    "        \n",
    "        cost_matrix[cost_matrix > self.threshold] = no_link\n",
    "        lower_right = cost_matrix.transpose()\n",
    "\n",
    "        deaths = np.full(shape=(cost_matrix.shape[0], cost_matrix.shape[0]), fill_value=no_link)\n",
    "        np.fill_diagonal(deaths, d)\n",
    "        births = np.full(shape=(cost_matrix.shape[1], cost_matrix.shape[1]), fill_value=no_link)\n",
    "        np.fill_diagonal(births, b)\n",
    "        \n",
    "        square_cost_matrix = np.block([\n",
    "            [cost_matrix, deaths],\n",
    "            [births, lower_right],\n",
    "        ])\n",
    "        row_ind, col_ind = scipy.optimize.linear_sum_assignment(square_cost_matrix)\n",
    "        \n",
    "        ids_from = []\n",
    "        ids_to = []\n",
    "        births = []\n",
    "        deaths = []\n",
    "        for row, col in zip(row_ind, col_ind):\n",
    "            if row < cost_matrix.shape[0] and col < cost_matrix.shape[1]:\n",
    "                ids_from.append(row)\n",
    "                ids_to.append(col)\n",
    "\n",
    "            if row >= cost_matrix.shape[0] and col < cost_matrix.shape[1]:\n",
    "                births.append(col)\n",
    "            if row < cost_matrix.shape[0] and col >= cost_matrix.shape[1]:\n",
    "                deaths.append(row)\n",
    "\n",
    "        ids_from = np.array(ids_from)\n",
    "        ids_to = np.array(ids_to)\n",
    "        births = np.array(births)\n",
    "        deaths = np.array(deaths)\n",
    "                        \n",
    "        # Account for +1 offset of the dense labels\n",
    "        ids_from += 1\n",
    "        ids_to += 1\n",
    "        births += 1\n",
    "        deaths += 1\n",
    "        \n",
    "        links = {\"links\": (ids_from, ids_to), \"births\": births, \"deaths\": deaths}\n",
    "        return links"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8fd0e45d-cf75-4015-8fe8-9cf500b9f2c4",
   "metadata": {},
   "source": [
    "# Testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "637b06ca-2656-49c4-a050-c0d4dec4b82a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
