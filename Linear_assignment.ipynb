{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c8d59ad3-40c7-494c-bd7e-509844f42d92",
   "metadata": {},
   "source": [
    "# Linear Assignment Problem"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1cfee44e-47da-408c-87f9-bfb9e723215e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>.container { width:100% !important; }</style>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/llanosp/miniconda3/envs/celltracking/lib/python3.9/site-packages/tqdm/auto.py:22: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "# Force keras to run on CPU\n",
    "import os\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"\"\n",
    "\n",
    "# Notebook at full width in the browser\n",
    "from IPython.display import display, HTML\n",
    "display(HTML(\"<style>.container { width:100% !important; }</style>\"))\n",
    "\n",
    "import sys\n",
    "from urllib.request import urlretrieve\n",
    "from pathlib import Path\n",
    "from collections import defaultdict\n",
    "from abc import ABC, abstractmethod\n",
    "\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "matplotlib.rcParams[\"image.interpolation\"] = \"none\"\n",
    "matplotlib.rcParams['figure.figsize'] = (14, 10)\n",
    "import numpy as np\n",
    "from tifffile import imread, imwrite\n",
    "from tqdm.auto import tqdm\n",
    "import skimage\n",
    "import pandas as pd\n",
    "import scipy\n",
    "import pathlib\n",
    "import networkx\n",
    "import pathlib\n",
    "from tifffile import imread, imwrite\n",
    "import tensorboard\n",
    "\n",
    "# from stardist import fill_label_holes, random_label_cmap\n",
    "# from stardist.plot import render_label\n",
    "# from stardist.models import StarDist2D\n",
    "# from stardist import _draw_polygons\n",
    "# from csbdeep.utils import normalize\n",
    "\n",
    "# import napari\n",
    "\n",
    "# lbl_cmap = random_label_cmap()\n",
    "# # Pretty tqdm progress bars \n",
    "# ! jupyter nbextension enable --py widgetsnbextension"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b60da261-b95b-460b-90c2-7befbe1abd74",
   "metadata": {},
   "source": [
    "# Calculate Euclidean Distances"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f2981ca7-333b-4749-bd7b-0f3a4aa7d90f",
   "metadata": {},
   "source": [
    "## Calculate Centroids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "54c34ee7-e1bb-4030-b4ed-42fcee391b5f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# function to convert 'TRA' channel into cell and frame-wise centroid positions\n",
    "## Function to extract trajectories from data\n",
    "\n",
    "base_path = pathlib.Path(\"/mnt/shared/celltracking/data/cho/\")\n",
    "\n",
    "# read parent-child links from file\n",
    "links = np.loadtxt(base_path / \"01_GT/TRA\" / \"man_track.txt\", dtype=int)\n",
    "\n",
    "# read annotated image stack\n",
    "centroids = np.stack([imread(xi) for xi in sorted((base_path / \"01_GT/TRA\").glob(\"*.tif\"))])  # images\n",
    "\n",
    "# extract centroids from annotated image stacks\n",
    "centers = skimage.measure.regionprops(centroids[0,0,:,:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "697b0c23-a9c4-4e60-a0f6-bc7dca8657c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# function to convert 'TRA' channel into cell and frame-wise centroid positions\n",
    "## Function to extract trajectories from data\n",
    "\n",
    "base_path = pathlib.Path(\"/mnt/shared/celltracking/data/cho/\")\n",
    "\n",
    "\n",
    "# read parent-child links from file\n",
    "links = np.loadtxt(base_path / \"01_GT/TRA\" / \"man_track.txt\", dtype=int)\n",
    "\n",
    "# read annotated image stack\n",
    "centroids = np.stack([imread(xi) for xi in sorted((base_path / \"01_GT/TRA\").glob(\"*.tif\"))])  # images\n",
    "\n",
    "# extract centroids from annotated image stacks\n",
    "centers = skimage.measure.regionprops(centroids[0,0,:,:])\n",
    "tracks = []\n",
    "for t, frame in enumerate(centroids):\n",
    "    centers = skimage.measure.regionprops(frame)\n",
    "    for c in centers:\n",
    "        tracks.append([c.label, t, int(c.centroid[1]), int(c.centroid[2])])\n",
    "        \n",
    "# constructs graph \n",
    "tracks = np.array(tracks)\n",
    "\n",
    "graph = networkx.DiGraph()\n",
    "for cell_id, t, x, y in tracks:\n",
    "    graph.add_node((cell_id,t), x=x, y=y, t=t)\n",
    "    \n",
    "for cell_id, t in graph.nodes():\n",
    "    if (cell_id, t+1) in graph.nodes():\n",
    "        graph.add_edge((cell_id, t), (cell_id,t+1))\n",
    "\n",
    "for child_id, child_from, _, child_parent_id in links:\n",
    "    for parent_id, _, parent_to, _ in links:\n",
    "        if child_parent_id == parent_id:\n",
    "            graph.add_edge((parent_id, parent_to), (child_id, child_from))\n",
    "            \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "dd0119d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def pairwise_euclidian_distance(points0, points1):\n",
    "    print(\"Iterative pairwise euclidian distance\")\n",
    "    dists = []\n",
    "    for p0 in points0:\n",
    "        for p1 in points1:\n",
    "            dists.append(np.sqrt(((p0 - p1)**2).sum()))\n",
    "            \n",
    "    dists = np.array(dists).reshape(len(points0), len(points1))\n",
    "    return dists"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "id": "b008a0a8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[  1,   0,  55,  55],\n",
       "       [  4,   0, 123, 212],\n",
       "       [  7,   0, 177,  87],\n",
       "       ...,\n",
       "       [ 26,  91, 351, 367],\n",
       "       [ 27,  91, 176,  67],\n",
       "       [ 28,  91, 389, 432]])"
      ]
     },
     "execution_count": 138,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tracks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "e5f55674",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "numpy.ndarray"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(tracks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "5e2679c3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tracks[0][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66f73d37",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "5e3dbdb4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([  0,  10,  20,  30,  39,  48,  57,  66,  75,  84,  93, 102, 111,\n",
       "        119, 127, 135, 143, 151, 159, 167, 175, 183, 191, 199, 207, 215,\n",
       "        223, 231, 239, 247, 255, 262, 268, 274, 281]),)"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.where(tracks[:,0]==1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "id": "31157ec9",
   "metadata": {},
   "outputs": [],
   "source": [
    "idx=np.where(tracks[:,1]==11)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "id": "1a16bfce",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([102, 103, 104, 105, 106, 107, 108, 109, 110]),)"
      ]
     },
     "execution_count": 144,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "idx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "id": "22cca94f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 59, 122, 178, 290,  80, 242, 397, 393, 395, 359]])"
      ]
     },
     "execution_count": 100,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tracks[idxt_next,2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0b4575c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "5b2e1b12",
   "metadata": {},
   "source": [
    "## Creating matrix t x (t+1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "id": "48653a65",
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.spatial import distance\n",
    "distances = []\n",
    "#row corresponds to index of cells in t\n",
    "rows = [] \n",
    "#row corresponds to index of cells in t+1\n",
    "cols = []\n",
    "\n",
    "#Loop throug the times frames\n",
    "for t in range(max(tracks[:,1])):\n",
    "\n",
    "    #get index\n",
    "    idxt=np.where(tracks[:,1]==t)[0]\n",
    "    idxt_next=np.where(tracks[:,1]==t+1)[0]\n",
    "    t_matrix=np.zeros((len(idxt),len(idxt_next)), dtype=float)\n",
    "\n",
    "    for ii in range(0, len(idxt)):\n",
    "        for jj in range(0, len(idxt_next)):\n",
    "            #coordinate x,y cellN in t\n",
    "            pt1=[tracks[ii,2], tracks[ii,3]]\n",
    "            #pt1=tracks[ii,2:]-->embedding\n",
    "            #coordinate x,y cellN in t next\n",
    "            pt2=[tracks[jj,2], tracks[jj,3]] \n",
    "            #distance from pt1 and pt2\n",
    "            dist=distance.euclidean(pt1,pt2)\n",
    "            #dist = np.sqrt(np.sum(np.square(pt1-pt2)))\n",
    "            #fill matrix with the distances\n",
    "            \n",
    "            t_matrix[ii,jj]= dist\n",
    "            \n",
    "    #print(t, len(idxt), len(idxt_next))\n",
    "    distances.append(t_matrix)\n",
    "    rows.append(idxt)\n",
    "    cols.append(idxt_next)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1adacdbe",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "id": "68d30f93",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Creating matrix t x (t+1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "id": "fda02f3a-db83-45a1-b4fe-b1ebd7a3b107",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "too many values to unpack (expected 4)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Input \u001b[0;32mIn [156]\u001b[0m, in \u001b[0;36m<cell line: 9>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      5\u001b[0m tracks \u001b[38;5;241m=\u001b[39m [track \u001b[38;5;28;01mfor\u001b[39;00m track \u001b[38;5;129;01min\u001b[39;00m tracks \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(track\u001b[38;5;241m.\u001b[39medges)\u001b[38;5;241m>\u001b[39m\u001b[38;5;241m0\u001b[39m]\n\u001b[1;32m      8\u001b[0m graph \u001b[38;5;241m=\u001b[39m networkx\u001b[38;5;241m.\u001b[39mDiGraph()\n\u001b[0;32m----> 9\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m cell_id, t, x, y \u001b[38;5;129;01min\u001b[39;00m tracks:\n\u001b[1;32m     10\u001b[0m     graph\u001b[38;5;241m.\u001b[39madd_node((cell_id,t), x\u001b[38;5;241m=\u001b[39mx, y\u001b[38;5;241m=\u001b[39my, t\u001b[38;5;241m=\u001b[39mt)\n\u001b[1;32m     12\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m cell_id, t \u001b[38;5;129;01min\u001b[39;00m graph\u001b[38;5;241m.\u001b[39mnodes():\n",
      "\u001b[0;31mValueError\u001b[0m: too many values to unpack (expected 4)"
     ]
    }
   ],
   "source": [
    "# extract trajectories from graph set\n",
    "#tracks = [graph.subgraph(c) for c in networkx.weakly_connected_components(graph) if len(c)>0]\n",
    "\n",
    "# remove tracks with 0 edges\n",
    "#tracks = [track for track in tracks if len(track.edges)>0]\n",
    "\n",
    "\n",
    "#graph = networkx.DiGraph()\n",
    "#for cell_id, t, x, y in tracks:\n",
    "#    graph.add_node((cell_id,t), x=x, y=y, t=t)\n",
    "    \n",
    "#for cell_id, t in graph.nodes():\n",
    "#    if (cell_id, t+1) in graph.nodes():\n",
    "#        graph.add_edge((cell_id, t), (cell_id,t+1))\n",
    "\n",
    "#for child_id, child_from, _, child_parent_id in links:\n",
    "#    for parent_id, _, parent_to, _ in links:\n",
    "#        if child_parent_id == parent_id:\n",
    "#            graph.add_edge((parent_id, parent_to), (child_id, child_from))\n",
    "            \n",
    "# extract trajectories from graph set\n",
    "#tracks = [graph.subgraph(c) for c in networkx.weakly_connected_components(graph) if len(c)>0]\n",
    "\n",
    "# remove tracks with 0 edges\n",
    "#tracks = [track for track in tracks if len(track.edges)>0]\n",
    "#tracks.label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "02e311d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "a2409302",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of images: 92\n",
      "Shape of images: (5, 443, 512)\n",
      "Shape of images: (5, 443, 512)\n"
     ]
    }
   ],
   "source": [
    "x = np.stack([imread(xi) for xi in sorted((base_path / \"01\").glob(\"*.tif\"))])\n",
    "y = np.stack([imread(xi) for xi in sorted((base_path / \"01_GT/TRA\").glob(\"*.tif\"))])\n",
    "\n",
    "assert x.shape == y.shape\n",
    "print(f\"Number of images: {len(x)}\")\n",
    "print(f\"Shape of images: {x[0].shape}\")\n",
    "print(f\"Shape of images: {y[0].shape}\")\n",
    "#x, y = preprocess(x, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "7d593da7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Links\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>track_id</th>\n",
       "      <th>from</th>\n",
       "      <th>to</th>\n",
       "      <th>parent_id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>34</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>38</td>\n",
       "      <td>39</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>39</td>\n",
       "      <td>40</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>29</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>33</td>\n",
       "      <td>91</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "      <td>30</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>8</td>\n",
       "      <td>34</td>\n",
       "      <td>91</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>9</td>\n",
       "      <td>43</td>\n",
       "      <td>91</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>10</td>\n",
       "      <td>0</td>\n",
       "      <td>91</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>11</td>\n",
       "      <td>0</td>\n",
       "      <td>91</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>12</td>\n",
       "      <td>0</td>\n",
       "      <td>58</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>13</td>\n",
       "      <td>62</td>\n",
       "      <td>91</td>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>14</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>15</td>\n",
       "      <td>0</td>\n",
       "      <td>11</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>16</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>17</td>\n",
       "      <td>0</td>\n",
       "      <td>51</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>18</td>\n",
       "      <td>56</td>\n",
       "      <td>91</td>\n",
       "      <td>17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>19</td>\n",
       "      <td>56</td>\n",
       "      <td>91</td>\n",
       "      <td>17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>20</td>\n",
       "      <td>4</td>\n",
       "      <td>74</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>23</td>\n",
       "      <td>86</td>\n",
       "      <td>91</td>\n",
       "      <td>20</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    track_id  from  to  parent_id\n",
       "0          1     0  34          0\n",
       "1          2    38  39          1\n",
       "2          3    39  40          1\n",
       "3          4     0  29          0\n",
       "4          5    33  91          4\n",
       "5          7     0  30          0\n",
       "6          8    34  91          7\n",
       "7          9    43  91          7\n",
       "8         10     0  91          0\n",
       "9         11     0  91          0\n",
       "10        12     0  58          0\n",
       "11        13    62  91         12\n",
       "12        14     0   2          0\n",
       "13        15     0  11          0\n",
       "14        16     0   3          0\n",
       "15        17     0  51          0\n",
       "16        18    56  91         17\n",
       "17        19    56  91         17\n",
       "18        20     4  74          0\n",
       "19        23    86  91         20"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "links = np.loadtxt(base_path / \"01_GT/TRA\" / \"man_track.txt\", dtype=int)\n",
    "links = pd.DataFrame(data=links, columns=[\"track_id\", \"from\", \"to\", \"parent_id\"])\n",
    "print(\"Links\")\n",
    "links[:20]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "id": "f4485c15",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Check birth and death"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c274e52e",
   "metadata": {},
   "outputs": [],
   "source": [
    "ids_from, ids_to = nearest_neighbor(cost_matrix)\n",
    "    births = np.array(list(set(range(cost_matrix.shape[1])) - set(ids_to)))\n",
    "    deaths = np.array(list(set(range(cost_matrix.shape[0])) - set(ids_from)))\n",
    "        \n",
    "        # Account for +1 offset of the dense labels\n",
    "    ids_from += 1\n",
    "    ids_to += 1\n",
    "    births += 1\n",
    "    deaths += 1\n",
    "        \n",
    "    links = {\"links\": (ids_from, ids_to), \"births\": births, \"deaths\": deaths}\n",
    "    return links"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aea9b222",
   "metadata": {},
   "outputs": [],
   "source": [
    " ids_from, ids_to = nearest_neighbor(cost_matrix, self.threshold)\n",
    "        births = np.array(list(set(range(cost_matrix.shape[1])) - set(ids_to)))\n",
    "        deaths = np.array(list(set(range(cost_matrix.shape[0])) - set(ids_from)))\n",
    "        \n",
    "        # Account for +1 offset of the dense labels\n",
    "        ids_from += 1\n",
    "        ids_to += 1\n",
    "        births += 1\n",
    "        deaths += 1\n",
    "        \n",
    "        links = {\"links\": (ids_from, ids_to), \"births\": births, \"deaths\": deaths}\n",
    "        return links"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dae49da3-92d9-4018-8c96-8ce09ff0b40c",
   "metadata": {
    "tags": []
   },
   "source": [
    "Optimal frame-by-frame matching (Linear assignment problem or Weighted bipartite matching)\n",
    "The nearest neighbor algorithm above will not pick the best solution in many cases. For example, it does not consider the local arrangement of a few detections to create links, something which the human visual system is very good at.\n",
    "\n",
    "We need a better optimization algorithm to minimize the total minimal linking distance between two frames. To use a classic and efficient optimization algorithm, we will represent this linking problem as a bipartite graph. Here is an example:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "06ba7710-528e-46a3-a158-3e6595e11cf2",
   "metadata": {},
   "outputs": [],
   "source": [
    "class FrameByFrameLinker(ABC):\n",
    "    \"\"\"Abstract base class for linking detections by considering pairs of adjacent frames.\"\"\"\n",
    "    \n",
    "    def link(self, detections, images=None):\n",
    "        \"\"\"Links detections in t frames.\n",
    "        \n",
    "        Args:\n",
    "        \n",
    "            detections:\n",
    "            \n",
    "                List of t numpy arrays of shape (x,y) with contiguous label ids. Background = 0.\n",
    "                \n",
    "            images (optional):\n",
    "            \n",
    "                List of t numpy arrays of shape (x,y).\n",
    "        \n",
    "        Returns:\n",
    "        \n",
    "            Linking dictionary:\n",
    "                \"links\":\n",
    "                    \n",
    "                    Tuple of lists. Links from frame t to frame t+1 of form (from0, to0) are split up into two lists: \n",
    "                    - idgs_from: [from0, from1 , ...])\n",
    "                    - ids_to: [to0, to1 , ...])\n",
    "                \n",
    "                \"births\": List of ids from frame t that are \n",
    "                \"deaths\": List of ids.\n",
    "            Ids are one-based, 0 is reserved for background.\n",
    "        \"\"\"\n",
    "        if images is not None:\n",
    "            assert len(images) == len(detections)\n",
    "        else:\n",
    "            images = [None] * len(detections)\n",
    "\n",
    "        links = []\n",
    "        for i in tqdm(range(len(images) - 1), desc=\"Linking\"):\n",
    "            detections0 = detections[i]\n",
    "            detections1 = detections[i+1]\n",
    "            self._assert_relabeled(detections0)\n",
    "            self._assert_relabeled(detections1)\n",
    "            \n",
    "            cost_matrix = self.linking_cost_function(detections0, detections1, images[i], images[i+1])\n",
    "            li = self._link_two_frames(cost_matrix)\n",
    "            self._assert_links(links=li, time=i, detections0=detections0, detections1=detections1) \n",
    "            links.append(li)\n",
    "            \n",
    "        return links\n",
    "\n",
    "    @abstractmethod\n",
    "    def linking_cost_function(self, detections0, detections1, image0=None, image1=None):\n",
    "        \"\"\"Calculate features for each detection and extract pairwise costs.\n",
    "        \n",
    "        To be overwritten in subclass.\n",
    "        \n",
    "        Args:\n",
    "        \n",
    "            detections0: image with background 0 and detections 1, ..., m\n",
    "            detections1: image with backgruond 0 and detections 1, ..., n\n",
    "            image0 (optional): image corresponding to detections0\n",
    "            image1 (optional): image corresponding to detections1\n",
    "            \n",
    "        Returns:\n",
    "        \n",
    "            m x n cost matrix \n",
    "        \"\"\"\n",
    "        pass\n",
    "    \n",
    "    @abstractmethod\n",
    "    def _link_two_frames(self, cost_matrix):\n",
    "        \"\"\"Link two frames.\n",
    "        \n",
    "        To be overwritten in subclass.\n",
    "\n",
    "        Args:\n",
    "\n",
    "            cost_matrix: m x n matrix\n",
    "\n",
    "        Returns:\n",
    "        \n",
    "            \"links\":\n",
    "\n",
    "                Tuple of lists. Links from frame t to frame t+1 of form (from0, to0) are split up into two lists: \n",
    "                - idgs_from: [from0, from1 , ...])\n",
    "                - ids_to: [to0, to1 , ...])\n",
    "\n",
    "            \"births\": List of ids from frame t that are \n",
    "            \"deaths\": List of ids.\n",
    "            \n",
    "            Ids are one-based, 0 is reserved for background.\n",
    "        \"\"\"\n",
    "        pass\n",
    "\n",
    "    def relabel_detections(self, detections, links):\n",
    "        \"\"\"Relabel dense detections according to computed links, births and deaths.\n",
    "        \n",
    "        Args:\n",
    "        \n",
    "            detections: \n",
    "                 \n",
    "                 List of t numpy arrays of shape (x,y) with contiguous label ids. Background = 0.\n",
    "                 \n",
    "            links:\n",
    "                \n",
    "                List of t linking dictionaries, each containing:\n",
    "                    \"links\": Tuple of lists (ids frame t, ids frame t+1),\n",
    "                    \"births\": List of ids,\n",
    "                    \"deaths\": List of ids.\n",
    "                Ids are one-based, 0 is reserved for background.\n",
    "        \"\"\"\n",
    "        detections = detections.copy()\n",
    "        \n",
    "        assert len(detections) - 1 == len(links)\n",
    "        self._assert_relabeled(detections[0])\n",
    "        out = [detections[0]]\n",
    "        n_tracks = out[0].max()\n",
    "        lookup_tables = [{i: i for i in range(1, out[0].max() + 1)}]\n",
    "\n",
    "        for i in tqdm(range(len(links)), desc=\"Recoloring detections\"):\n",
    "            (ids_from, ids_to) = links[i][\"links\"]\n",
    "            births = links[i][\"births\"]\n",
    "            deaths = links[i+1][\"deaths\"] if i+1 < len(links) else []\n",
    "            new_frame = np.zeros_like(detections[i+1])\n",
    "            self._assert_relabeled(detections[i+1])\n",
    "            \n",
    "            lut = {}\n",
    "            for _from, _to in zip(ids_from, ids_to):\n",
    "                # Copy over ID\n",
    "                new_frame[detections[i+1] == _to] = lookup_tables[i][_from]\n",
    "                lut[_to] = lookup_tables[i][_from]\n",
    "\n",
    "            \n",
    "            # Start new track for birth tracks\n",
    "            for b in births:\n",
    "                if b in deaths:\n",
    "                    continue\n",
    "                \n",
    "                n_tracks += 1\n",
    "                lut[b] = n_tracks\n",
    "                new_frame[detections[i+1] == b] = n_tracks\n",
    "                \n",
    "            # print(lut)\n",
    "            lookup_tables.append(lut)\n",
    "            out.append(new_frame)\n",
    "                \n",
    "        return np.stack(out)\n",
    "\n",
    "    def _assert_links(self, links, time, detections0, detections1):\n",
    "        if len(links[\"links\"][0]) != len(links[\"links\"][1]):\n",
    "            raise RuntimeError(\"Format of links['links'] not correct.\")\n",
    "            \n",
    "        if sorted([*links[\"links\"][0], *links[\"deaths\"]]) != list(range(1, len(np.unique(detections0)))):\n",
    "            raise RuntimeError(f\"Some detections in frame {time} are not properly assigned as either linked or death.\")\n",
    "            \n",
    "        if sorted([*links[\"links\"][1], *links[\"births\"]]) != list(range(1, len(np.unique(detections1)))):\n",
    "            raise RuntimeError(f\"Some detections in frame {time + 1} are not properly assigned as either linked or birth.\")\n",
    "            \n",
    "        for b in links[\"births\"]:\n",
    "            if b in links[\"links\"][1]:\n",
    "                raise RuntimeError(f\"Links frame {time+1}: Detection {b} marked as birth, but also linked.\")\n",
    "        \n",
    "        for d in links[\"deaths\"]:\n",
    "            if d in links[\"links\"][0]:\n",
    "                raise RuntimeError(f\"Links frame {time}: Detection {d} marked as death, but also linked.\")\n",
    "        \n",
    "        \n",
    "    def _assert_relabeled(self, x):\n",
    "        if x.min() < 0:\n",
    "            raise ValueError(\"Negative ID in detections.\")\n",
    "        if x.min() == 0:\n",
    "            n = x.max() + 1\n",
    "        else:\n",
    "            n = x.max()\n",
    "        if n != len(np.unique(x)):\n",
    "            raise ValueError(\"Detection IDs are not contiguous.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "31179bee-ede5-42c9-a0c3-00c96920f59b",
   "metadata": {},
   "outputs": [],
   "source": [
    "class BipartiteMatchingLinker(FrameByFrameLinker):\n",
    "    \"\"\".\n",
    "    \n",
    "    Args:\n",
    "        threshold (float): Maximum euclidian distance for linking.\n",
    "        drift: tuple of (x,y) drift correction per frame.\n",
    "        birth_cost_factor (float): Multiply factor with maximum entry in cost matrix.\n",
    "        death_cost_factor (float): Multiply factor with maximum entry in cost matrix.\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(\n",
    "        self,\n",
    "        threshold=np.finfo(float).max,\n",
    "        drift=(0,0),\n",
    "        birth_cost_factor=1.05,\n",
    "        death_cost_factor=1.05,\n",
    "        *args,\n",
    "        **kwargs\n",
    "    ):\n",
    "        self.threshold = threshold\n",
    "        self.drift = np.array(drift)\n",
    "        self.birth_cost_factor = birth_cost_factor\n",
    "        self.death_cost_factor = death_cost_factor\n",
    "        \n",
    "        super().__init__(*args, **kwargs)\n",
    "        \n",
    "    def linking_cost_function(self, detections0, detections1, image0=None, image1=None):\n",
    "        \"\"\" Get centroids from detections and compute pairwise euclidian distances with drift correction.\n",
    "                \n",
    "        Args:\n",
    "        \n",
    "            detections0: image with background 0 and detections 1, ..., m\n",
    "            detections1: image with backgruond 0 and detections 1, ..., n\n",
    "            \n",
    "        Returns:\n",
    "        \n",
    "            m x n cost matrix \n",
    "        \"\"\"\n",
    "        # regionprops regions are sorted by label\n",
    "        regions0 = skimage.measure.regionprops(detections0)\n",
    "        points0 = [np.array(r.centroid) for r in regions0]\n",
    "        \n",
    "        regions1 = skimage.measure.regionprops(detections1)\n",
    "        points1 = [np.array(r.centroid) for r in regions1]\n",
    "        \n",
    "        dists = []\n",
    "        for p0 in points0:\n",
    "            for p1 in points1:\n",
    "                dists.append(np.sqrt(((p0 + self.drift - p1)**2).sum()))\n",
    "\n",
    "        dists = np.array(dists).reshape(len(points0), len(points1))\n",
    "        \n",
    "        return dists\n",
    "    \n",
    "    def _link_two_frames(self, cost_matrix):\n",
    "        \"\"\"Weighted bipartite matching with square matrix from Jaqaman et al (2008).\n",
    "\n",
    "        Args:\n",
    "\n",
    "            cost_matrix: m x n matrix.\n",
    "\n",
    "        Returns:\n",
    "            \"links\":\n",
    "    \n",
    "                Tuple of lists. Links from frame t to frame t+1 of form (from0, to0) are split up into two lists: \n",
    "                    - idgs_from: [from0, from1 , ...])\n",
    "                    - ids_to: [to0, to1 , ...])\n",
    "                \n",
    "                \"births\": List of ids from frame t that are \n",
    "                \"deaths\": List of ids.\n",
    "                \n",
    "            Ids are one-based, 0 is reserved for background.\n",
    "        \"\"\"\n",
    "        \n",
    "        cost_matrix = cost_matrix.copy().astype(float)\n",
    "        b = self.birth_cost_factor * min(self.threshold, cost_matrix.max())\n",
    "        d = self.death_cost_factor * min(self.threshold, cost_matrix.max())\n",
    "        no_link = max(cost_matrix.max(), max(b, d)) * 1e9\n",
    "        \n",
    "        cost_matrix[cost_matrix > self.threshold] = no_link\n",
    "        lower_right = cost_matrix.transpose()\n",
    "\n",
    "        deaths = np.full(shape=(cost_matrix.shape[0], cost_matrix.shape[0]), fill_value=no_link)\n",
    "        np.fill_diagonal(deaths, d)\n",
    "        births = np.full(shape=(cost_matrix.shape[1], cost_matrix.shape[1]), fill_value=no_link)\n",
    "        np.fill_diagonal(births, b)\n",
    "        \n",
    "        square_cost_matrix = np.block([\n",
    "            [cost_matrix, deaths],\n",
    "            [births, lower_right],\n",
    "        ])\n",
    "        row_ind, col_ind = scipy.optimize.linear_sum_assignment(square_cost_matrix)\n",
    "        \n",
    "        ids_from = []\n",
    "        ids_to = []\n",
    "        births = []\n",
    "        deaths = []\n",
    "        for row, col in zip(row_ind, col_ind):\n",
    "            if row < cost_matrix.shape[0] and col < cost_matrix.shape[1]:\n",
    "                ids_from.append(row)\n",
    "                ids_to.append(col)\n",
    "\n",
    "            if row >= cost_matrix.shape[0] and col < cost_matrix.shape[1]:\n",
    "                births.append(col)\n",
    "            if row < cost_matrix.shape[0] and col >= cost_matrix.shape[1]:\n",
    "                deaths.append(row)\n",
    "\n",
    "        ids_from = np.array(ids_from)\n",
    "        ids_to = np.array(ids_to)\n",
    "        births = np.array(births)\n",
    "        deaths = np.array(deaths)\n",
    "                        \n",
    "        # Account for +1 offset of the dense labels\n",
    "        ids_from += 1\n",
    "        ids_to += 1\n",
    "        births += 1\n",
    "        deaths += 1\n",
    "        \n",
    "        links = {\"links\": (ids_from, ids_to), \"births\": births, \"deaths\": deaths}\n",
    "        return links"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8fd0e45d-cf75-4015-8fe8-9cf500b9f2c4",
   "metadata": {},
   "source": [
    "# Testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "637b06ca-2656-49c4-a050-c0d4dec4b82a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
