{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c8785982-9655-49cb-8f12-e8f43dd02b19",
   "metadata": {},
   "source": [
    "# imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1c484a69-ab7c-454c-9e8a-190ad19567e0",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/bourquea/miniconda3/envs/celltracking/lib/python3.9/site-packages/tqdm/auto.py:22: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "from torch.utils.data import DataLoader, random_split\n",
    "from torch.utils.data.sampler import WeightedRandomSampler\n",
    "from torchvision.datasets import ImageFolder\n",
    "from torchvision import transforms\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import numpy as np\n",
    "import random \n",
    "import matplotlib.pyplot as plt\n",
    "from torchvision import models\n",
    "from torchsummary import summary\n",
    "\n",
    "from torchvision import datasets\n",
    "from torchvision import transforms\n",
    "from torch.utils.data.sampler import SubsetRandomSampler\n",
    "import gunpowder as gp\n",
    "import zarr\n",
    "import math\n",
    "%load_ext tensorboard\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "import skimage\n",
    "import networkx\n",
    "import pathlib\n",
    "from tifffile import imread, imwrite\n",
    "import tensorboard\n",
    "import torch.nn.functional as F\n",
    "import glob\n",
    "from abc import ABC, abstractmethod\n",
    "from tqdm.auto import tqdm \n",
    "import napari\n",
    "\n",
    "import scipy\n",
    "#Device configuration\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "11b8553a-bec0-4bb6-a756-98c407823208",
   "metadata": {},
   "source": [
    "# Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6816beac-5aa1-4c6f-b9e8-6c3c612813ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "# model parameters\n",
    "input_size = (1, 64, 64, 5)\n",
    "downsample_factors =[(2, 2, 1), (2, 2, 1), (2, 2, 1), (2, 2, 1)];\n",
    "output_classes = 12\n",
    "\n",
    "# model definition\n",
    "class Vgg3D(torch.nn.Module):\n",
    "\n",
    "    def __init__(self, input_size, output_classes, downsample_factors, fmaps=12):\n",
    "\n",
    "        super(Vgg3D, self).__init__()\n",
    "\n",
    "        self.input_size = input_size\n",
    "        self.downsample_factors = downsample_factors\n",
    "        self.output_classes = 2\n",
    "\n",
    "        current_fmaps, h, w, d = tuple(input_size)\n",
    "        current_size = (h, w,d)\n",
    "\n",
    "        features = []\n",
    "        for i in range(len(downsample_factors)):\n",
    "\n",
    "            features += [\n",
    "                torch.nn.Conv3d(current_fmaps,fmaps,kernel_size=3,padding=1),\n",
    "                torch.nn.BatchNorm3d(fmaps),\n",
    "                torch.nn.ReLU(inplace=True),\n",
    "                torch.nn.Conv3d(fmaps,fmaps,kernel_size=3,padding=1),\n",
    "                torch.nn.BatchNorm3d(fmaps),\n",
    "                torch.nn.ReLU(inplace=True),\n",
    "                torch.nn.MaxPool3d(downsample_factors[i])\n",
    "            ]\n",
    "\n",
    "            current_fmaps = fmaps\n",
    "            fmaps *= 2\n",
    "\n",
    "            size = tuple(\n",
    "                int(c/d)\n",
    "                for c, d in zip(current_size, downsample_factors[i]))\n",
    "            check = (\n",
    "                s*d == c\n",
    "                for s, d, c in zip(size, downsample_factors[i], current_size))\n",
    "            assert all(check), \\\n",
    "                \"Can not downsample %s by chosen downsample factor\" % \\\n",
    "                (current_size,)\n",
    "            current_size = size\n",
    "\n",
    "        self.features = torch.nn.Sequential(*features)\n",
    "\n",
    "        classifier = [\n",
    "            torch.nn.Linear(current_size[0] *current_size[1]*current_size[2] *current_fmaps,4096),\n",
    "            torch.nn.ReLU(inplace=True),\n",
    "            torch.nn.Dropout(),\n",
    "            torch.nn.Linear(4096,4096),\n",
    "            torch.nn.ReLU(inplace=True),\n",
    "            torch.nn.Dropout(),\n",
    "            torch.nn.Linear(4096,output_classes)\n",
    "        ]\n",
    "\n",
    "        self.classifier = torch.nn.Sequential(*classifier)\n",
    "    \n",
    "    def forward(self, raw):\n",
    "\n",
    "        # add a channel dimension to raw\n",
    "        # shape = tuple(raw.shape)\n",
    "        # raw = raw.reshape(shape[0], 1, shape[1], shape[2])\n",
    "        \n",
    "        # compute features\n",
    "        f = self.features(raw)\n",
    "        f = f.view(f.size(0), -1)\n",
    "        \n",
    "        # classify\n",
    "        y = self.classifier(f)\n",
    "\n",
    "        return y\n",
    "\n",
    "# create the model to train\n",
    "model = Vgg3D(input_size, output_classes,  downsample_factors = downsample_factors)\n",
    "model = model.to(device)\n",
    "#summary(model, input_size)\n",
    "\n",
    "# define loss function\n",
    "loss_function = torch.nn.CosineEmbeddingLoss()\n",
    "#loss_function = ContrastiveLoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=1e-4, weight_decay=0.0005)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec756973-b147-45fc-a919-a6baf16d4ff1",
   "metadata": {},
   "source": [
    "# Load model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f58afb48-ae4b-4f28-9b2f-1ed313b77963",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Vgg3D(\n",
       "  (features): Sequential(\n",
       "    (0): Conv3d(1, 12, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))\n",
       "    (1): BatchNorm3d(12, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (2): ReLU(inplace=True)\n",
       "    (3): Conv3d(12, 12, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))\n",
       "    (4): BatchNorm3d(12, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (5): ReLU(inplace=True)\n",
       "    (6): MaxPool3d(kernel_size=(2, 2, 1), stride=(2, 2, 1), padding=0, dilation=1, ceil_mode=False)\n",
       "    (7): Conv3d(12, 24, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))\n",
       "    (8): BatchNorm3d(24, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (9): ReLU(inplace=True)\n",
       "    (10): Conv3d(24, 24, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))\n",
       "    (11): BatchNorm3d(24, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (12): ReLU(inplace=True)\n",
       "    (13): MaxPool3d(kernel_size=(2, 2, 1), stride=(2, 2, 1), padding=0, dilation=1, ceil_mode=False)\n",
       "    (14): Conv3d(24, 48, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))\n",
       "    (15): BatchNorm3d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (16): ReLU(inplace=True)\n",
       "    (17): Conv3d(48, 48, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))\n",
       "    (18): BatchNorm3d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (19): ReLU(inplace=True)\n",
       "    (20): MaxPool3d(kernel_size=(2, 2, 1), stride=(2, 2, 1), padding=0, dilation=1, ceil_mode=False)\n",
       "    (21): Conv3d(48, 96, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))\n",
       "    (22): BatchNorm3d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (23): ReLU(inplace=True)\n",
       "    (24): Conv3d(96, 96, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))\n",
       "    (25): BatchNorm3d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (26): ReLU(inplace=True)\n",
       "    (27): MaxPool3d(kernel_size=(2, 2, 1), stride=(2, 2, 1), padding=0, dilation=1, ceil_mode=False)\n",
       "  )\n",
       "  (classifier): Sequential(\n",
       "    (0): Linear(in_features=7680, out_features=4096, bias=True)\n",
       "    (1): ReLU(inplace=True)\n",
       "    (2): Dropout(p=0.5, inplace=False)\n",
       "    (3): Linear(in_features=4096, out_features=4096, bias=True)\n",
       "    (4): ReLU(inplace=True)\n",
       "    (5): Dropout(p=0.5, inplace=False)\n",
       "    (6): Linear(in_features=4096, out_features=12, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# path to state file\n",
    "modelstateP = '/mnt/shared/celltracking/modelstates/klaus/'\n",
    "stateFile = 'epoch_30'\n",
    "\n",
    "model.load_state_dict(torch.load(modelstateP+stateFile))\n",
    "model.eval()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "55913bed-2a6a-448d-9a66-87875ecdd73d",
   "metadata": {},
   "source": [
    "# Extract cell- and frame-wise model outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "eb9cc256-d559-4b6c-9946-e2bf3b4a631d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "done with: 50/614 total\n",
      "done with: 100/614 total\n",
      "done with: 150/614 total\n",
      "done with: 200/614 total\n",
      "done with: 250/614 total\n",
      "done with: 300/614 total\n",
      "done with: 350/614 total\n",
      "done with: 400/614 total\n",
      "done with: 450/614 total\n",
      "done with: 500/614 total\n",
      "done with: 550/614 total\n",
      "done with: 600/614 total\n"
     ]
    }
   ],
   "source": [
    "# set parameters\n",
    "volSize = (1,5,64, 64)\n",
    "zarrdir = '/mnt/shared/celltracking/data/cho/02.zarr'\n",
    "raw = gp.ArrayKey('raw')\n",
    "\n",
    "# extract centroids from annotated image stacks\n",
    "annotationPath = pathlib.Path(\"/mnt/shared/celltracking/data/cho/\")\n",
    "annotations = np.stack([imread(xi) for xi in sorted((annotationPath / \"02_GT/TRA\").glob(\"*.tif\"))])  # images\n",
    "cells = []\n",
    "for t, frame in enumerate(annotations):\n",
    "    centers = skimage.measure.regionprops(frame)\n",
    "    for c in centers:\n",
    "        cells.append([c.label, t, int(c.centroid[1]), int(c.centroid[2])])\n",
    "\n",
    "# define gp pipeline\n",
    "pipeline_allCentroids = (gp.ZarrSource(\n",
    "    zarrdir,  # the zarr container\n",
    "    {raw: 'raw'},  # which dataset to associate to the array key\n",
    "    {raw: gp.ArraySpec(voxel_size=(1,1,1,1), interpolatable=True)})  # meta-information\n",
    "    + gp.Pad(raw, None))\n",
    "\n",
    "# constructs gp pipeline\n",
    "\n",
    "gp.ArraySpec()\n",
    "\n",
    "# loop over all cell centroids\n",
    "predictions = []\n",
    "i=0\n",
    "for id,t,x,y in cells:\n",
    "    # determine coordinates\n",
    "    coord = (t,0,x-(volSize[2]/2),y-(volSize[3]/2))\n",
    "    request = gp.BatchRequest()\n",
    "    request[raw] = gp.Roi(coord, volSize)\n",
    "    \n",
    "    with gp.build(pipeline_allCentroids):\n",
    "        batch = pipeline_allCentroids.request_batch(request)\n",
    "        \n",
    "    # show the content of the batch\n",
    "    # print(f\"batch returned: {batch}\")\n",
    "\n",
    "    # # plot first slice of volume\n",
    "    # print(batch[raw].data.shape)\n",
    "    # plt.imshow(np.flipud(batch[raw].data[0,0,:,:]))\n",
    "\n",
    "    ## evaluate model for each centroid using gp pipeline\n",
    "    vol = batch[raw].data\n",
    "    vol = np.reshape(vol, (1,64, 64, 5))\n",
    "    vol = np.expand_dims(vol, axis =0)\n",
    "    vol = torch.from_numpy(vol).to(device).float()\n",
    "    pred = model(vol)\n",
    "    pred = pred.detach().cpu().numpy()\n",
    "    \n",
    "    # save pred into list with id + position information\n",
    "    predictions.append([id, t, x, y, pred])\n",
    "    i += 1\n",
    "    if i%50==0:\n",
    "        print(f'done with: {i}/{len(cells)} total')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "4f97e2e7-2ecb-4ffd-9fe3-93d803cd5c18",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/bourquea/miniconda3/envs/celltracking/lib/python3.9/site-packages/numpy/core/fromnumeric.py:2009: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
      "  result = asarray(a).shape\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(614, 5)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#predictions # cellid, frame, x,y, embedding vectorp\n",
    "\n",
    "np.shape(predictions)\n",
    "#predictions[600:]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "61a1899b-cc11-4fc3-8ef4-9ccfab5968b4",
   "metadata": {},
   "source": [
    "# Linear Assignment Part"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ef201fb-1eea-499c-92cf-dc4a90857ff1",
   "metadata": {
    "tags": []
   },
   "source": [
    "# From Paola"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d829e5da-0609-4d84-9441-f64923336e84",
   "metadata": {},
   "source": [
    "# Time Matrices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "18e9a197-9232-411a-a49a-049c99922ef4",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-6-9442b887089a>:1: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
      "  tracks = np.array(predictions)[:,0:4]# T matrices\n"
     ]
    }
   ],
   "source": [
    "tracks = np.array(predictions)[:,0:4]# T matrices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "1abe0189-0345-4988-91fc-d6bd27ae6e7f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1, 0, 160, 297],\n",
       "       [4, 0, 273, 208],\n",
       "       [7, 0, 356, 272],\n",
       "       [10, 0, 315, 365],\n",
       "       [1, 1, 160, 297],\n",
       "       [4, 1, 273, 210],\n",
       "       [7, 1, 356, 272],\n",
       "       [10, 1, 315, 365],\n",
       "       [1, 2, 167, 297],\n",
       "       [4, 2, 273, 210]], dtype=object)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tracks[0:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "d5f6f8c3-0cd4-46f7-bd0d-33a643927c35",
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.spatial import distance\n",
    "distances = []\n",
    "#row corresponds to index of cells in t\n",
    "rows = [] \n",
    "#row corresponds to index of cells in t+1\n",
    "cols = []\n",
    "\n",
    "#Loop throug the times frames\n",
    "for t in range(max(tracks[:,1])):\n",
    "\n",
    "    #get index\n",
    "    idxt=np.where(tracks[:,1]==t)[0]\n",
    "    idxt_next=np.where(tracks[:,1]==t+1)[0]\n",
    "    t_matrix=np.zeros((len(idxt),len(idxt_next)), dtype=float)\n",
    "\n",
    "    for ii in range(0, len(idxt)):\n",
    "        for jj in range(0, len(idxt_next)):\n",
    "            #coordinate x,y cellN in t\n",
    "            pt1=[tracks[ii,2], tracks[ii,3]]\n",
    "            #pt1=tracks[ii,2:]-->embedding\n",
    "            #coordinate x,y cellN in t next\n",
    "            pt2=[tracks[jj,2], tracks[jj,3]] \n",
    "            #distance from pt1 and pt2\n",
    "            dist=distance.euclidean(pt1,pt2)\n",
    "            #dist = np.sqrt(np.sum(np.square(pt1-pt2)))\n",
    "            #fill matrix with the distances\n",
    "            \n",
    "            t_matrix[ii,jj]= dist\n",
    "            \n",
    "    #print(t, len(idxt), len(idxt_next))\n",
    "    distances.append(t_matrix)\n",
    "    rows.append(idxt)\n",
    "    cols.append(idxt_next)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d1a9c910-4501-49e1-83a9-f5614c15e653",
   "metadata": {},
   "source": [
    "# Embedding Vector matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "d1cfe4f1-5139-4ebd-9aed-d4367aa5a633",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-9-0a95b8899d1f>:3: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
      "  predictnp=np.array(predictions)\n"
     ]
    }
   ],
   "source": [
    "from scipy.spatial import distance\n",
    "\n",
    "predictnp=np.array(predictions)\n",
    "\n",
    "distances_em = []\n",
    "#row corresponds to index of cells in t\n",
    "rows_em = [] \n",
    "#row corresponds to index of cells in t+1\n",
    "cols_em = []\n",
    "\n",
    "#Loop throug the times frames\n",
    "for t in range(max(predictnp[:,1])):\n",
    "\n",
    "    #get index\n",
    "    idxt=np.where(predictnp[:,1]==t)[0]\n",
    "    idxt_next=np.where(predictnp[:,1]==t+1)[0]\n",
    "    t_matrix_emb=np.zeros((len(idxt),len(idxt_next)), dtype=float)\n",
    "\n",
    "    for ii in range(0, len(idxt)):\n",
    "        for jj in range(0, len(idxt_next)):\n",
    "            #coordinate x,y cellN in t\n",
    "            pt1=predictnp[ii,4][0]\n",
    "            #pt1=tracks[ii,2:]-->embedding\n",
    "            #coordinate x,y cellN in t next\n",
    "            pt2=predictnp[jj,4][0]\n",
    "            #distance from pt1 and pt2\n",
    "            dist=distance.euclidean(pt1,pt2)\n",
    "            #dist = np.sqrt(np.sum(np.square(pt1-pt2)))\n",
    "            #fill matrix with the distances\n",
    "            \n",
    "            t_matrix_emb[ii,jj]= dist\n",
    "            \n",
    "    #print(t, len(idxt), len(idxt_next))\n",
    "    distances_em.append(t_matrix_emb)\n",
    "    rows_em.append(idxt)\n",
    "    cols_em.append(idxt_next)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92b11540-3367-4981-9559-7fb681416849",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "66a5b4a2-669b-426a-a03f-059cdb610776",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Calculate Centroids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "ca650a5e-7ede-43a3-8832-af1c0809a9a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# function to convert 'TRA' channel into cell and frame-wise centroid positions\n",
    "## Function to extract trajectories from data\n",
    "\n",
    "base_path = pathlib.Path(\"/mnt/shared/celltracking/data/cho/\")\n",
    "\n",
    "# read parent-child links from file\n",
    "links = np.loadtxt(base_path / \"02_GT/TRA\" / \"man_track.txt\", dtype=int)\n",
    "\n",
    "# read annotated image stack\n",
    "centroids = np.stack([imread(xi) for xi in sorted((base_path / \"02_GT/TRA\").glob(\"*.tif\"))])  # images\n",
    "\n",
    "pts = []\n",
    "# extract centroids from annotated image stacks\n",
    "\n",
    "# for img in range(len(centroids))\n",
    "#     blobs = skimage.measure.regionprops(centroids[img,0,:,:])\n",
    "#     for blob in blobs:\n",
    "#         y0, x0 = blob.centroid\n",
    "#         pts.append((x0, y0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "43360bb8-497f-42a5-9795-d7dda09dbd13",
   "metadata": {},
   "outputs": [],
   "source": [
    "# function to convert 'TRA' channel into cell and frame-wise centroid positions\n",
    "## Function to extract trajectories from data\n",
    "\n",
    "base_path = pathlib.Path(\"/mnt/shared/celltracking/data/cho/\")\n",
    "\n",
    "# read parent-child links from file\n",
    "links = np.loadtxt(base_path / \"02_GT/TRA\" / \"man_track.txt\", dtype=int)\n",
    "\n",
    "# read annotated image stack\n",
    "centroids = np.stack([imread(xi) for xi in sorted((base_path / \"02_GT/TRA\").glob(\"*.tif\"))])  # images\n",
    "\n",
    "# extract centroids from annotated image stacks\n",
    "centers = skimage.measure.regionprops(centroids[0,0,:,:])\n",
    "tracks = []\n",
    "centroid_info = []\n",
    "cntrs = []\n",
    "for t, frame in enumerate(centroids):\n",
    "    centers = skimage.measure.regionprops(frame)\n",
    "    temp = []\n",
    "    for c in centers:\n",
    "        tracks.append([c.label, t, int(c.centroid[1]), int(c.centroid[2])])\n",
    "        centroid_info.append([c.label, t, int(c.centroid[1]), int(c.centroid[2])])\n",
    "        temp.append([int(c.centroid[1]), int(c.centroid[2])])\n",
    "    \n",
    "    cntrs.append(temp)\n",
    "        \n",
    "# constructs graph \n",
    "tracks = np.array(tracks)\n",
    "graph = networkx.DiGraph()\n",
    "for cell_id, t, x, y in tracks:\n",
    "    graph.add_node((cell_id,t), x=x, y=y, t=t)\n",
    "    \n",
    "for cell_id, t in graph.nodes():\n",
    "    if (cell_id, t+1) in graph.nodes():\n",
    "        graph.add_edge((cell_id, t), (cell_id,t+1))\n",
    "\n",
    "for child_id, child_from, _, child_parent_id in links:\n",
    "    for parent_id, _, parent_to, _ in links:\n",
    "        if child_parent_id == parent_id:\n",
    "            graph.add_edge((parent_id, parent_to), (child_id, child_from))\n",
    "            \n",
    "# extract trajectories from graph set\n",
    "tracks = [graph.subgraph(c) for c in networkx.weakly_connected_components(graph) if len(c)>0]\n",
    "\n",
    "# remove tracks with 0 edges\n",
    "tracks = [track for track in tracks if len(track.edges)>0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "4c4300ce-f4e5-4e04-9b02-4ff5339e8fbe",
   "metadata": {},
   "outputs": [],
   "source": [
    "# plt.figure(figsize=(10,6))\n",
    "# plt.bar(range(len(cntrs)), [len(xi) for xi in cntrs])\n",
    "# plt.title(f\"Number of detections in each frame\")\n",
    "# plt.xticks(range(len(centers)))\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "8e2798a1-330c-46ac-a00d-c5277e5dc729",
   "metadata": {},
   "outputs": [],
   "source": [
    "# G = networkx.complete_graph(tracks)\n",
    "# networkx.draw_spring(G)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f736fa76-69df-4590-b1ab-f848d1524bad",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Euc Distance Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "77b47a63-1fec-4e02-91d8-3d03bd760096",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Solution Exercise 1.3\n",
    "def pairwise_euclidian_distance(points0, points1):\n",
    "    #print(\"Iterative pairwise euclidian distance\")\n",
    "    dists = []\n",
    "    for p0 in points0:\n",
    "        for p1 in points1:\n",
    "            dists.append(np.sqrt(((p0 - p1)**2).sum()))\n",
    "            \n",
    "    dists = np.array(dists).reshape(len(points0), len(points1))\n",
    "    return dists"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a3b1a619-181a-4bcd-aefe-fccab1aa00d9",
   "metadata": {},
   "source": [
    "## Testing function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "2689388c-72f5-4892-a352-ae96388290c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# p0 = np.array(cntrs[0]);\n",
    "# p1 = np.array(cntrs[1]);\n",
    "\n",
    "# dists = pairwise_euclidian_distance(p0, p1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "088d09c7-6e73-4439-beab-a64e01518015",
   "metadata": {
    "tags": []
   },
   "source": [
    "Optimal frame-by-frame matching (Linear assignment problem or Weighted bipartite matching)\n",
    "The nearest neighbor algorithm above will not pick the best solution in many cases. For example, it does not consider the local arrangement of a few detections to create links, something which the human visual system is very good at.\n",
    "\n",
    "We need a better optimization algorithm to minimize the total minimal linking distance between two frames. To use a classic and efficient optimization algorithm, we will represent this linking problem as a bipartite graph. Here is an example:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "315a0e09-9cac-43bc-92e7-19492629696f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "class FrameByFrameLinker(ABC):\n",
    "    \"\"\"Abstract base class for linking detections by considering pairs of adjacent frames.\"\"\"\n",
    "    \n",
    "    def link(self, detections, weight = 0.1, images=None):\n",
    "        \"\"\"Links detections in t frames.\n",
    "        \n",
    "        Args:\n",
    "        \n",
    "            detections:\n",
    "            \n",
    "                List of t numpy arrays of shape (x,y) with contiguous label ids. Background = 0.\n",
    "                \n",
    "            images (optional):\n",
    "            \n",
    "                List of t numpy arrays of shape (x,y).\n",
    "        \n",
    "        Returns:\n",
    "        \n",
    "            Linking dictionary:\n",
    "                \"links\":\n",
    "                    \n",
    "                    Tuple of lists. Links from frame t to frame t+1 of form (from0, to0) are split up into two lists: \n",
    "                    - idgs_from: [from0, from1 , ...])\n",
    "                    - ids_to: [to0, to1 , ...])\n",
    "                \n",
    "                \"births\": List of ids from frame t that are \n",
    "                \"deaths\": List of ids.\n",
    "            Ids are one-based, 0 is reserved for background.\n",
    "        \"\"\"\n",
    "        if images is not None:\n",
    "            assert len(images) == len(detections)\n",
    "        else:\n",
    "            images = [None] * len(detections)\n",
    "\n",
    "        links = []\n",
    "        for i in tqdm(range(len(images) - 1), desc=\"Linking\"):\n",
    "            detections0 = detections[i]\n",
    "            detections1 = detections[i+1]\n",
    "            self._assert_relabeled(detections0)\n",
    "            self._assert_relabeled(detections1)\n",
    "            \n",
    "            # t_mat_embed = getEmbeddedMatrix()\n",
    "            # t_mat_euc_dis = getEucDisMatrix()\n",
    "            #cost_matrix = weight* t_mat_embed + t_mat_euc_dis #s\n",
    "            #cost_matrix = self.linking_cost_function(detections0, detections1, images[i], images[i+1])\n",
    "            li = self._link_two_frames(cost_matrix)\n",
    "            self._assert_links(links=li, time=i, detections0=detections0, detections1=detections1) \n",
    "            links.append(li)\n",
    "            \n",
    "        return links\n",
    "\n",
    "    @abstractmethod\n",
    "    def linking_cost_function(self, detections0, detections1, image0=None, image1=None):\n",
    "        \"\"\"Calculate features for each detection and extract pairwise costs.\n",
    "        \n",
    "        To be overwritten in subclass.\n",
    "        \n",
    "        Args:\n",
    "        \n",
    "            detections0: image with background 0 and detections 1, ..., m\n",
    "            detections1: image with backgruond 0 and detections 1, ..., n\n",
    "            image0 (optional): image corresponding to detections0\n",
    "            image1 (optional): image corresponding to detections1\n",
    "            \n",
    "        Returns:\n",
    "        \n",
    "            m x n cost matrix \n",
    "        \"\"\"\n",
    "        pass\n",
    "    \n",
    "    @abstractmethod\n",
    "    def _link_two_frames(self, cost_matrix):\n",
    "        \"\"\"Link two frames.\n",
    "        \n",
    "        To be overwritten in subclass.\n",
    "\n",
    "        Args:\n",
    "\n",
    "            cost_matrix: m x n matrix\n",
    "\n",
    "        Returns:\n",
    "        \n",
    "            \"links\":\n",
    "\n",
    "                Tuple of lists. Links from frame t to frame t+1 of form (from0, to0) are split up into two lists: \n",
    "                - idgs_from: [from0, from1 , ...])\n",
    "                - ids_to: [to0, to1 , ...])\n",
    "\n",
    "            \"births\": List of ids from frame t that are \n",
    "            \"deaths\": List of ids.\n",
    "            \n",
    "            Ids are one-based, 0 is reserved for background.\n",
    "        \"\"\"\n",
    "        pass\n",
    "\n",
    "    def relabel_detections(self, detections, links):\n",
    "        \"\"\"Relabel dense detections according to computed links, births and deaths.\n",
    "        \n",
    "        Args:\n",
    "        \n",
    "            detections: \n",
    "                 \n",
    "                 List of t numpy arrays of shape (x,y) with contiguous label ids. Background = 0.\n",
    "                 \n",
    "            links:\n",
    "                \n",
    "                List of t linking dictionaries, each containing:\n",
    "                    \"links\": Tuple of lists (ids frame t, ids frame t+1),\n",
    "                    \"births\": List of ids,\n",
    "                    \"deaths\": List of ids.\n",
    "                Ids are one-based, 0 is reserved for background.\n",
    "        \"\"\"\n",
    "        detections = detections.copy()\n",
    "        \n",
    "        assert len(detections) - 1 == len(links)\n",
    "        # self._assert_relabeled(detections[0])\n",
    "        out = [detections[0]]\n",
    "        n_tracks = out[0].max()\n",
    "        lookup_tables = [{i: i for i in range(1, out[0].max() + 1)}]\n",
    "\n",
    "        for i in tqdm(range(len(links)), desc=\"Recoloring detections\"):\n",
    "            (ids_from, ids_to) = links[i][\"links\"]\n",
    "            births = links[i][\"births\"]\n",
    "            deaths = links[i+1][\"deaths\"] if i+1 < len(links) else []\n",
    "            new_frame = np.zeros_like(detections[i+1])\n",
    "            # self._assert_relabeled(detections[i+1])\n",
    "            \n",
    "            lut = {}\n",
    "            for _from, _to in zip(ids_from, ids_to):\n",
    "                # Copy over ID\n",
    "                #ipdb.set_trace()\n",
    "                new_frame[detections[i+1] == _to] = lookup_tables[i][_from]\n",
    "                lut[_to] = lookup_tables[i][_from]\n",
    "\n",
    "            \n",
    "            # Start new track for birth tracks\n",
    "            for b in births:\n",
    "                if b in deaths:\n",
    "                    continue\n",
    "                \n",
    "                n_tracks += 1\n",
    "                lut[b] = n_tracks\n",
    "                new_frame[detections[i+1] == b] = n_tracks\n",
    "                \n",
    "            # print(lut)\n",
    "            lookup_tables.append(lut)\n",
    "            out.append(new_frame)\n",
    "                \n",
    "        return np.stack(out)\n",
    "\n",
    "    def _assert_links(self, links, time, detections0, detections1):\n",
    "        if len(links[\"links\"][0]) != len(links[\"links\"][1]):\n",
    "            raise RuntimeError(\"Format of links['links'] not correct.\")\n",
    "            \n",
    "        if sorted([*links[\"links\"][0], *links[\"deaths\"]]) != list(range(1, len(np.unique(detections0)))):\n",
    "            raise RuntimeError(f\"Some detections in frame {time} are not properly assigned as either linked or death.\")\n",
    "            \n",
    "        if sorted([*links[\"links\"][1], *links[\"births\"]]) != list(range(1, len(np.unique(detections1)))):\n",
    "            raise RuntimeError(f\"Some detections in frame {time + 1} are not properly assigned as either linked or birth.\")\n",
    "            \n",
    "        for b in links[\"births\"]:\n",
    "            if b in links[\"links\"][1]:\n",
    "                raise RuntimeError(f\"Links frame {time+1}: Detection {b} marked as birth, but also linked.\")\n",
    "        \n",
    "        for d in links[\"deaths\"]:\n",
    "            if d in links[\"links\"][0]:\n",
    "                raise RuntimeError(f\"Links frame {time}: Detection {d} marked as death, but also linked.\")\n",
    "        \n",
    "        \n",
    "    def _assert_relabeled(self, x):\n",
    "        if x.min() < 0:\n",
    "            raise ValueError(\"Negative ID in detections.\")\n",
    "        if x.min() == 0:\n",
    "            n = x.max() + 1\n",
    "        else:\n",
    "            n = x.max()\n",
    "        if n != len(np.unique(x)):\n",
    "            pass\n",
    "            #raise ValueError(\"Detection IDs are not contiguous.\")\n",
    "    \n",
    "#     def getEmbeddedMatrix(tracks, t):\n",
    "#         #get index\n",
    "#         idxt=np.where(predictnp[:,1]==t)[0]\n",
    "#         idxt_next=np.where(predictnp[:,1]==t+1)[0]\n",
    "#         t_matrix_emb=np.zeros((len(idxt),len(idxt_next)), dtype=float)\n",
    "\n",
    "#         for ii in range(0, len(idxt)):\n",
    "#             for jj in range(0, len(idxt_next)):\n",
    "#                 #coordinate x,y cellN in t\n",
    "#                 pt1=predictnp[ii,4][0]\n",
    "#                 #pt1=tracks[ii,2:]-->embedding\n",
    "#                 #coordinate x,y cellN in t next\n",
    "#                 pt2=predictnp[jj,4][0]\n",
    "#                 #distance from pt1 and pt2\n",
    "#                 dist=distance.euclidean(pt1,pt2)\n",
    "#                 #dist = np.sqrt(np.sum(np.square(pt1-pt2)))\n",
    "#                 #fill matrix with the distances\n",
    "\n",
    "#                 t_matrix_emb[ii,jj]= dist\n",
    "\n",
    "#             return t_matrix_emb\n",
    "    \n",
    "#     def getEucDistMatrix(tracks, t):\n",
    "#         #get index\n",
    "#         idxt=np.where(tracks[:,1]==t)[0]\n",
    "#         idxt_next=np.where(tracks[:,1]==t+1)[0]\n",
    "#         t_matrix=np.zeros((len(idxt),len(idxt_next)), dtype=float)\n",
    "\n",
    "#         for ii in range(0, len(idxt)):\n",
    "#             for jj in range(0, len(idxt_next)):\n",
    "#                 #coordinate x,y cellN in t\n",
    "#                 pt1=[tracks[ii,2], tracks[ii,3]]\n",
    "#                 #pt1=tracks[ii,2:]-->embedding\n",
    "#                 #coordinate x,y cellN in t next\n",
    "#                 pt2=[tracks[jj,2], tracks[jj,3]] \n",
    "#                 #distance from pt1 and pt2\n",
    "#                 dist=distance.euclidean(pt1,pt2)\n",
    "#                 #dist = np.sqrt(np.sum(np.square(pt1-pt2)))\n",
    "#                 #fill matrix with the distances\n",
    "\n",
    "#                 t_matrix[ii,jj]= dist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "5f395973-d47c-44ae-9c05-b964b9edeaeb",
   "metadata": {},
   "outputs": [],
   "source": [
    "class BipartiteMatchingLinker(FrameByFrameLinker):\n",
    "    \"\"\".\n",
    "    \n",
    "    Args:\n",
    "        threshold (float): Maximum euclidian distance for linking.\n",
    "        drift: tuple of (x,y) drift correction per frame.\n",
    "        birth_cost_factor (float): Multiply factor with maximum entry in cost matrix.\n",
    "        death_cost_factor (float): Multiply factor with maximum entry in cost matrix.\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(\n",
    "        self,\n",
    "        threshold=np.finfo(float).max,\n",
    "        drift=(0,0),\n",
    "        birth_cost_factor=1.05,\n",
    "        death_cost_factor=1.05,\n",
    "        *args,\n",
    "        **kwargs\n",
    "    ):\n",
    "        self.threshold = threshold\n",
    "        self.drift = np.array(drift)\n",
    "        self.birth_cost_factor = birth_cost_factor\n",
    "        self.death_cost_factor = death_cost_factor\n",
    "        \n",
    "        super().__init__(*args, **kwargs)\n",
    "        \n",
    "    def linking_cost_function(self, detections0, detections1, image0=None, image1=None):\n",
    "        \"\"\" Get centroids from detections and compute pairwise euclidian distances with drift correction.\n",
    "                \n",
    "        Args:\n",
    "        \n",
    "            detections0: image with background 0 and detections 1, ..., m\n",
    "            detections1: image with backgruond 0 and detections 1, ..., n\n",
    "            \n",
    "        Returns:\n",
    "        \n",
    "            m x n cost matrix \n",
    "        \"\"\"\n",
    "#         # regionprops regions are sorted by label\n",
    "#         regions0 = skimage.measure.regionprops(detections0)\n",
    "#         #points0 = [np.array(r.centroid) for r in regions0]\n",
    "#         points0 = []\n",
    "#         for c in regions0:\n",
    "#             points0.append([int(c.centroid[1]), int(c.centroid[2])])\n",
    "        \n",
    "#         points0 = np.array(points0)\n",
    "        \n",
    "#         regions1 = skimage.measure.regionprops(detections1)\n",
    "#         #points1 = [np.array(r.centroid) for r in regions1]\n",
    "#         points1 = []\n",
    "#         for c in regions1:\n",
    "#             points1.append([int(c.centroid[1]), int(c.centroid[2])])\n",
    "        \n",
    "#         points1 = np.array(points1)\n",
    "        \n",
    "#         dists = []\n",
    "\n",
    "#         euc_dists = pairwise_euclidian_distance(points0, points1)\n",
    "#         euc_dists = np.array(euc_dists).reshape(len(points0), len(points1))\n",
    "\n",
    "        \n",
    "\n",
    "        ## incorporate embeddings\n",
    "        #dists = euc_dists + cos\n",
    "        \n",
    "        \n",
    "        \n",
    "        return euc_dists\n",
    "    \n",
    "    def _link_two_frames(self, cost_matrix):\n",
    "        \"\"\"Weighted bipartite matching with square matrix from Jaqaman et al (2008).\n",
    "\n",
    "        Args:\n",
    "\n",
    "            cost_matrix: m x n matrix.\n",
    "\n",
    "        Returns:\n",
    "            \"links\":\n",
    "    \n",
    "                Tuple of lists. Links from frame t to frame t+1 of form (from0, to0) are split up into two lists: \n",
    "                    - idgs_from: [from0, from1 , ...])\n",
    "                    - ids_to: [to0, to1 , ...])\n",
    "                \n",
    "                \"births\": List of ids from frame t that are \n",
    "                \"deaths\": List of ids.\n",
    "                \n",
    "            Ids are one-based, 0 is reserved for background.\n",
    "        \"\"\"\n",
    "        \n",
    "        cost_matrix = cost_matrix.copy().astype(float)\n",
    "        b = self.birth_cost_factor * min(self.threshold, cost_matrix.max())\n",
    "        d = self.death_cost_factor * min(self.threshold, cost_matrix.max())\n",
    "        no_link = max(cost_matrix.max(), max(b, d)) * 1e9\n",
    "        \n",
    "        cost_matrix[cost_matrix > self.threshold] = no_link\n",
    "        lower_right = cost_matrix.transpose()\n",
    "\n",
    "        deaths = np.full(shape=(cost_matrix.shape[0], cost_matrix.shape[0]), fill_value=no_link)\n",
    "        np.fill_diagonal(deaths, d)\n",
    "        births = np.full(shape=(cost_matrix.shape[1], cost_matrix.shape[1]), fill_value=no_link)\n",
    "        np.fill_diagonal(births, b)\n",
    "        \n",
    "        square_cost_matrix = np.block([\n",
    "            [cost_matrix, deaths],\n",
    "            [births, lower_right],\n",
    "        ])\n",
    "        row_ind, col_ind = scipy.optimize.linear_sum_assignment(square_cost_matrix)\n",
    "        \n",
    "        ids_from = []\n",
    "        ids_to = []\n",
    "        births = []\n",
    "        deaths = []\n",
    "        for row, col in zip(row_ind, col_ind):\n",
    "            if row < cost_matrix.shape[0] and col < cost_matrix.shape[1]:\n",
    "                ids_from.append(row)\n",
    "                ids_to.append(col)\n",
    "\n",
    "            if row >= cost_matrix.shape[0] and col < cost_matrix.shape[1]:\n",
    "                births.append(col)\n",
    "            if row < cost_matrix.shape[0] and col >= cost_matrix.shape[1]:\n",
    "                deaths.append(row)\n",
    "\n",
    "        ids_from = np.array(ids_from)\n",
    "        ids_to = np.array(ids_to)\n",
    "        births = np.array(births)\n",
    "        deaths = np.array(deaths)\n",
    "                        \n",
    "        # Account for +1 offset of the dense labels\n",
    "        ids_from += 1\n",
    "        ids_to += 1\n",
    "        births += 1\n",
    "        deaths += 1\n",
    "        \n",
    "        links = {\"links\": (ids_from, ids_to), \"births\": births, \"deaths\": deaths}\n",
    "        return links"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "27938762-a0d4-4b2d-9f0f-38a341819c4a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "91"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(distances)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "e619511b-c643-4b16-bcb3-0326f860d0e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def relabel_tracks(links, ann, ann1, id_previous, new_track_id):\n",
    "    #links: a list of link_two_frames dict’’'\n",
    "    id_relabeled = np.zeros((len(ann1),), dtype = int)\n",
    "    (ids_from, ids_to) = links['links']\n",
    "    births = links['births']\n",
    "    deaths = links['deaths']\n",
    "    for _from, _to in zip(ids_from, ids_to):\n",
    "        # Copy over ID\n",
    "        id_relabeled[_to] = id_previous[_from]\n",
    "    if len(births) != 0:\n",
    "        for jj in range(len(births)):\n",
    "            id_relabeled[births[jj]] = new_track_id\n",
    "            new_track_id += 1\n",
    "    ann1['id'] = id_relabeled\n",
    "    id_previous = id_relabeled\n",
    "    ann = pd.concat((ann, ann1))\n",
    "    return ann, id_previous, new_track_id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "a8bfae22-25e0-484f-93e8-e59c7d4bb33a",
   "metadata": {},
   "outputs": [],
   "source": [
    "relabeled = np.zeros_like(centroids)\n",
    "for t in range(centroids.shape[0]):\n",
    "    relabeled[t, 0] = skimage.segmentation.relabel_sequential(centroids[t, 0])[0]\n",
    "\n",
    "bm_linker = BipartiteMatchingLinker(threshold=50, drift=(0, 0), birth_cost_factor=1.05, death_cost_factor=1.05)\n",
    "\n",
    "all_links = []\n",
    "weight = 0.10\n",
    "\n",
    "for t in range(len(distances)):\n",
    "    cost_matrix = distances[t] + weight*distances_em[t]\n",
    "    bm_links = bm_linker._link_two_frames(cost_matrix)\n",
    "    all_links.append(bm_links)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "701b1463-49f0-4c93-860f-7454f3378357",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Recoloring detections: 100%|██████████| 91/91 [00:00<00:00, 323.33it/s]\n"
     ]
    }
   ],
   "source": [
    "bm_tracks = bm_linker.relabel_detections(relabeled, all_links)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "04f6bed8-f6eb-483f-9b46-bdc579a19d9e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(4, 4)\n"
     ]
    }
   ],
   "source": [
    "print(distances[0].shape)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
