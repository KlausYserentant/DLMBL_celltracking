{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "96fa3a08-111f-4d26-8e65-7be9ba004054",
   "metadata": {},
   "source": [
    "# Model Implementation for 3D Cell Tracking\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "15fd6961-5904-42c4-9fd7-190c0685c312",
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install torchsummary \n",
    "# !pip install gunpowder\n",
    "# !pip install zarr\n",
    "# !pip install matplotlib\n",
    "# !pip install tensorboard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2503c9e5-eea9-4751-9600-fd8c537aecea",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/bourquea/miniconda3/envs/celltracking/lib/python3.9/site-packages/tqdm/auto.py:22: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "from torch.utils.data import DataLoader, random_split\n",
    "from torch.utils.data.sampler import WeightedRandomSampler\n",
    "from torchvision.datasets import ImageFolder\n",
    "from torchvision import transforms\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import numpy as np\n",
    "import random \n",
    "import matplotlib.pyplot as plt\n",
    "from torchvision import models\n",
    "from torchsummary import summary\n",
    "\n",
    "from torchvision import datasets\n",
    "from torchvision import transforms\n",
    "from torch.utils.data.sampler import SubsetRandomSampler\n",
    "import gunpowder as gp\n",
    "import zarr\n",
    "import math\n",
    "%load_ext tensorboard\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "import skimage\n",
    "import networkx\n",
    "import pathlib\n",
    "from tifffile import imread, imwrite\n",
    "import tensorboard\n",
    "import torch.nn.functional as F\n",
    "\n",
    "# Device configuration\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "835c90df-e975-4373-9a30-ff0977d23544",
   "metadata": {},
   "source": [
    "# Data Importing"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "235c18c9-a9f7-4312-8b09-501b6bbc53d7",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Extract Centroids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b93a13da-0440-4782-a888-a49085a172d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# function to convert 'TRA' channel into cell and frame-wise centroid positions\n",
    "## Function to extract trajectories from data\n",
    "\n",
    "base_path = pathlib.Path(\"/mnt/shared/celltracking/data/cho/\")\n",
    "\n",
    "\n",
    "# read parent-child links from file\n",
    "links = np.loadtxt(base_path / \"01_GT/TRA\" / \"man_track.txt\", dtype=int)\n",
    "\n",
    "# read annotated image stack\n",
    "centroids = np.stack([imread(xi) for xi in sorted((base_path / \"01_GT/TRA\").glob(\"*.tif\"))])  # images\n",
    "\n",
    "# extract centroids from annotated image stacks\n",
    "centers = skimage.measure.regionprops(centroids[0,0,:,:])\n",
    "tracks = []\n",
    "for t, frame in enumerate(centroids):\n",
    "    centers = skimage.measure.regionprops(frame)\n",
    "    for c in centers:\n",
    "        tracks.append([c.label, t, int(c.centroid[1]), int(c.centroid[2])])\n",
    "        \n",
    "# constructs graph \n",
    "tracks = np.array(tracks)\n",
    "graph = networkx.DiGraph()\n",
    "for cell_id, t, x, y in tracks:\n",
    "    graph.add_node((cell_id,t), x=x, y=y, t=t)\n",
    "    \n",
    "for cell_id, t in graph.nodes():\n",
    "    if (cell_id, t+1) in graph.nodes():\n",
    "        graph.add_edge((cell_id, t), (cell_id,t+1))\n",
    "\n",
    "for child_id, child_from, _, child_parent_id in links:\n",
    "    for parent_id, _, parent_to, _ in links:\n",
    "        if child_parent_id == parent_id:\n",
    "            graph.add_edge((parent_id, parent_to), (child_id, child_from))\n",
    "            \n",
    "# extract trajectories from graph set\n",
    "tracks = [graph.subgraph(c) for c in networkx.weakly_connected_components(graph) if len(c)>0]\n",
    "\n",
    "# remove tracks with 0 edges\n",
    "tracks = [track for track in tracks if len(track.edges)>0]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "81f68ecf-4eea-4477-94a4-545c211c7290",
   "metadata": {},
   "outputs": [],
   "source": [
    "tracks_valid = tracks[12:]\n",
    "tracks = tracks[:12]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8226e7f8-90f8-41ee-ad99-f0b63fddd0f7",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Define function to make image pairs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a770c1f1-4e52-49ae-9f50-abd61b92b360",
   "metadata": {},
   "outputs": [],
   "source": [
    "class getPaired(gp.BatchFilter):\n",
    "\n",
    "    def __init__(self, raw, raw_shift, tracks, paired=True):\n",
    "        self.raw = raw\n",
    "        self.raw_shift = raw_shift\n",
    "        self.tracks = tracks\n",
    "        self.paired = paired\n",
    "    \n",
    "    # _ref channel array is stored in raw_ref, while second volume in pair will be stored raw_new\n",
    "    def prepare(self, request):\n",
    "        # obtain volume coordinates from tracks                \n",
    "        deps = gp.BatchRequest()\n",
    "        vol1,vol2 = self.sampler(request)\n",
    "                \n",
    "        deps[self.raw] = gp.ArraySpec(roi=gp.Roi(vol1,request[self.raw].roi.get_shape()))\n",
    "        deps[self.raw_shift] = gp.ArraySpec(roi=gp.Roi(vol2,request[self.raw_shift].roi.get_shape()))\n",
    "\n",
    "        return deps\n",
    "    \n",
    "    # required to inform downstream nodes about new array \n",
    "    def process(self, batch, request):\n",
    "        # create a new batch to hold the new array\n",
    "        out_batch = gp.Batch()\n",
    "\n",
    "        # create new array and store it in the batch\n",
    "        out_batch[self.raw_shift] = batch[self.raw_shift]\n",
    "        out_batch[self.raw] = batch[self.raw]\n",
    "        \n",
    "        #print(f'raw: {batch[self.raw].spec.roi}')\n",
    "        #print(batch[self.raw_shift].spec.roi)\n",
    "        \n",
    "        # make sure that coordinates for batch[raw] and batch[raw_shift] are reset to (0,0,0,0,0)\n",
    "        out_batch[self.raw].spec.roi = request[self.raw].roi\n",
    "        out_batch[self.raw_shift].spec.roi = request[self.raw_shift].roi\n",
    "\n",
    "        # return the new batch\n",
    "        return out_batch\n",
    "    \n",
    "    # select pairs of subvolumes from data\n",
    "    def sampler(self,request):\n",
    "        tracks = self.tracks\n",
    "        paired = self.paired\n",
    "        # choose connected nodes\n",
    "        # if self.paired:\n",
    "        if paired:\n",
    "            t0 = tracks[np.random.randint(0,len(tracks),1).item()]\n",
    "            e0 = list(t0.edges)[np.random.randint(len(list(t0.edges)))]\n",
    "            node0 = t0.nodes[e0[0]]\n",
    "            node1 = t0.nodes[e0[1]]\n",
    "            \n",
    "        # choose random unconnected nodes\n",
    "        else:\n",
    "            # randomly choose two tracks and make sure they are not identical\n",
    "            t0,t1 = np.random.randint(0,len(tracks),2)\n",
    "            while t0==t1:\n",
    "                t0,t1 = np.random.randint(0,len(tracks),2)\n",
    "\n",
    "            #print(f'trackids: {t0,t1}')\n",
    "            t0 = tracks[t0]\n",
    "            t1 = tracks[t1]\n",
    "\n",
    "            # choose random edges from each track\n",
    "            #print(f'number edges per track{len(list(t0.nodes)),len(list(t1.nodes))}')\n",
    "\n",
    "            r0 = np.random.randint(0,len(list(t0.nodes))) \n",
    "            r1 = np.random.randint(0,len(list(t1.nodes)))\n",
    "\n",
    "            node0 = t0.nodes[list(t0.nodes)[r0]]\n",
    "            node1 = t1.nodes[list(t1.nodes)[r1]]\n",
    "            \n",
    "\n",
    "\n",
    "        node0_xyt = [node0[\"x\"], node0[\"y\"], node0[\"t\"]]\n",
    "        node1_xyt = [node1[\"x\"], node1[\"y\"], node1[\"t\"]]\n",
    "\n",
    "        #print(f'input coord: {node0_xyt,node1_xyt}')\n",
    "\n",
    "        roi_in = request[self.raw_shift].roi.get_shape()\n",
    "        #t,z,y,x\n",
    "        coords_vol0 = (node0_xyt[2],0,node0_xyt[0]-(roi_in[2]/2),node0_xyt[1]-(roi_in[3]/2))\n",
    "        coords_vol1 = (node1_xyt[2],0,node1_xyt[0]-(roi_in[2]/2),node1_xyt[1]-(roi_in[3]/2))\n",
    "        #print(f'output coords - vol0: {coords_vol0}, vol1:{coords_vol1}')\n",
    "\n",
    "        return coords_vol0, coords_vol1\n",
    "            "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bbe16d12-0fe2-41dd-bf22-eeaf290b3e65",
   "metadata": {},
   "source": [
    "# Make batches "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "9374eed7-3581-4bae-a4e3-a59c6134da27",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ROI: None, voxel size: None, interpolatable: None, non-spatial: False, dtype: None, placeholder: False"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#specify subvolume size and volume source\n",
    "volSize = (1,5,64, 64)\n",
    "coord = (0,0,0,0)\n",
    "batch_size = 8\n",
    "\n",
    "zarrdir = '/mnt/shared/celltracking/data/cho/01.zarr'\n",
    "raw = gp.ArrayKey('raw')\n",
    "raw_shift = gp.ArrayKey('raw_shift')\n",
    "\n",
    "# create \"pipeline\" consisting only of a data source\n",
    "\n",
    "\n",
    "#Augmentations=\n",
    "\n",
    "# chose a random source (i.e., sample) from the above\n",
    "#random_location = gp.RandomLocation()\n",
    "\n",
    "pipeline_paired = (gp.ZarrSource(\n",
    "    zarrdir,  # the zarr container\n",
    "    {raw_shift: 'raw', raw: 'raw'},  # which dataset to associate to the array key\n",
    "    {raw_shift: gp.ArraySpec(voxel_size=(1,1,1,1), interpolatable=True), raw:gp.ArraySpec(voxel_size=(1,1,1,1), interpolatable=True)}  # meta-information\n",
    "    )+ gp.Normalize(raw)+gp.Normalize(raw_shift)+ \n",
    "    gp.Pad(raw_shift, None) + \n",
    "    gp.Pad(raw, None) + gp.IntensityAugment(\n",
    "    raw,\n",
    "    scale_min=0.9,\n",
    "    scale_max=1.1,\n",
    "    shift_min=-0.1,\n",
    "    shift_max=0.1,\n",
    "    ) + gp.NoiseAugment(raw, mode=\"gaussian\")) + gp.IntensityAugment(\n",
    "    raw_shift,\n",
    "    scale_min=0.9,\n",
    "    scale_max=1.1,\n",
    "    shift_min=-0.1,\n",
    "    shift_max=0.1,\n",
    "    ) + gp.NoiseAugment(raw_shift, mode=\"gaussian\") + getPaired(raw,raw_shift,tracks,paired=True) + gp.ElasticAugment(\n",
    "    [2,10,10],\n",
    "    [0,2,2],\n",
    "    [0,0*math.pi/2.0],\n",
    "    prob_slip=0.05,\n",
    "    prob_shift=0.05,\n",
    "    max_misalign=25) + gp.SimpleAugment(transpose_only=[2, 3], mirror_only=[])\n",
    "\n",
    "\n",
    "\n",
    "pipeline_unpaired = (gp.ZarrSource(\n",
    "    zarrdir,  # the zarr container\n",
    "    {raw_shift: 'raw', raw: 'raw'},  # which dataset to associate to the array key\n",
    "    {raw_shift: gp.ArraySpec(voxel_size=(1,1,1,1), interpolatable=True), raw:gp.ArraySpec(voxel_size=(1,1,1,1), interpolatable=True)}  # meta-information\n",
    "    )+ gp.Normalize(raw)+gp.Normalize(raw_shift)+ \n",
    "    gp.Pad(raw_shift, None) + \n",
    "    gp.Pad(raw, None) + gp.IntensityAugment(\n",
    "    raw,\n",
    "    scale_min=0.9,\n",
    "    scale_max=1.1,\n",
    "    shift_min=-0.1,\n",
    "    shift_max=0.1,\n",
    "    ) + gp.NoiseAugment(raw, mode=\"gaussian\") + gp.IntensityAugment(\n",
    "    raw_shift,\n",
    "    scale_min=0.9,\n",
    "    scale_max=1.1,\n",
    "    shift_min=-0.1,\n",
    "    shift_max=0.1,\n",
    "    ) + gp.NoiseAugment(raw_shift, mode=\"gaussian\")) + getPaired(raw,raw_shift,tracks,paired=False)  + gp.ElasticAugment(\n",
    "    [2,10,10],\n",
    "    [0,2,2],\n",
    "    [0,0*math.pi/2.0],\n",
    "    prob_slip=0.05,\n",
    "    prob_shift=0.05,\n",
    "    max_misalign=25) + gp.SimpleAugment(transpose_only=[2, 3], mirror_only=[]) \n",
    "\n",
    "pipeline_paired += gp.PreCache(num_workers=6) \n",
    "pipeline_unpaired += gp.PreCache(num_workers=6)\n",
    "pipeline_paired += gp.Stack(batch_size)\n",
    "pipeline_unpaired += gp.Stack(batch_size)\n",
    "\n",
    "# specify request\n",
    "request = gp.BatchRequest()\n",
    "request[raw] = gp.Roi(coord, volSize)\n",
    "request[raw_shift] = gp.Roi(coord, volSize)\n",
    "\n",
    "gp.ArraySpec()\n",
    "# build the pipeline...\n",
    "# with gp.build(pipeline_paired), gp.build(pipeline_unpaired):\n",
    "\n",
    "  # ...and request a batch\n",
    "  # batch = pipeline_unpaired.request_batch(request)\n",
    "  \n",
    "#show the content of the batch\n",
    "#print(f\"batch returned: {batch}\")\n",
    "\n",
    "# plot first slice of volume\n",
    "#fig, axs = plt.subplots(1,2)\n",
    "# print(batch[raw].data.shape)\n",
    "# axs[0].imshow(np.flipud(batch[raw].data[0,0,:,:]))\n",
    "# axs[1].imshow(np.flipud(batch[raw_shift].data[0,0,:,:]))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ead44e01-a035-424e-84e3-3d2968cf0132",
   "metadata": {},
   "outputs": [],
   "source": [
    "# provide path to zarr directory\n",
    "zarrdir = '/mnt/shared/celltracking/data/cho/01.zarr'\n",
    "\n",
    "data = zarr.open(zarrdir)\n",
    "loader = []"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6717dd30-e83f-4443-8f6d-1666d2021de4",
   "metadata": {},
   "source": [
    "## Define Augmentation pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "31f1af22-baa3-4eba-ae20-c9c752d661d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# provide path to zarr directory\n",
    "#zarrdir = '/mnt/shared/celltracking/data/cho/01.zarr'\n",
    "\n",
    "# pre-selected volumes from cho dataset\n",
    "coord_paired = ((0,0,80, 175),(1,0,80, 180))\n",
    "coord_unpaired = ((0,0,80, 175),(1,0,92, 232))\n",
    "\n",
    "# specify subvolume size and volume source\n",
    "volSize = (1,5,64, 64)\n",
    "coord = coord_paired[0]\n",
    "\n",
    "# declare arrays to use in the pipeline\n",
    "key ='raw'\n",
    "raw = gp.ArrayKey(key)\n",
    "\n",
    "# create \"pipeline\" consisting only of a data source\n",
    "source = gp.ZarrSource(\n",
    "    zarrdir,  # the zarr container\n",
    "    {raw: key},  # which dataset to associate to the array key\n",
    "    {raw: gp.ArraySpec(interpolatable=True, voxel_size = (1,1,1,1))}  # meta-information\n",
    ")\n",
    "pipeline = source\n",
    "\n",
    "# specify request paired\n",
    "request_vol1p = gp.BatchRequest()\n",
    "request_vol2p = gp.BatchRequest()\n",
    "request_vol1p[raw] = gp.Roi(coord_paired[0], volSize)\n",
    "request_vol2p[raw] = gp.Roi(coord_paired[1], volSize)\n",
    "\n",
    "# specify request unpaired\n",
    "request_vol1u = gp.BatchRequest()\n",
    "request_vol2u = gp.BatchRequest()\n",
    "request_vol1u[raw] = gp.Roi(coord_unpaired[0], volSize)\n",
    "request_vol2u[raw] = gp.Roi(coord_unpaired[1], volSize)\n",
    "\n",
    "# build the pipeline\n",
    "with gp.build(pipeline):\n",
    "    batch_vol1p = pipeline.request_batch(request_vol1p)\n",
    "    batch_vol2p = pipeline.request_batch(request_vol2p)\n",
    "    batch_vol1u = pipeline.request_batch(request_vol1u)\n",
    "    batch_vol2u = pipeline.request_batch(request_vol2u)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b322f3f-106a-484b-a790-bee3da998c0d",
   "metadata": {},
   "source": [
    "# Augmentations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "286b229d-0e67-4fce-b2df-509b31132f0d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Augmentations=\n",
    "\n",
    "# chose a random source (i.e., sample) from the above\n",
    "#random_location = gp.RandomLocation()\n",
    "\n",
    "# elastically deform the batch\n",
    "Elastic_augment=gp.ElasticAugment(\n",
    "    [2,10,10],\n",
    "    [0,2,2],\n",
    "    [0,0*math.pi/2.0],\n",
    "    prob_slip=0.05,\n",
    "    prob_shift=0.05,\n",
    "    max_misalign=25)\n",
    "\n",
    "# apply transpose and mirror augmentations\n",
    "# Simple_augment=gp.SimpleAugment(transpose_only=[2, 3], mirror_only=[]) \n",
    "Simple_augment=gp.SimpleAugment(transpose_only=[], mirror_only=[])\n",
    "\n",
    "# scale and shift the intensity of the raw array\n",
    "Intensity_augment=gp.IntensityAugment(\n",
    "    raw,\n",
    "    scale_min=0.9,\n",
    "    scale_max=1.1,\n",
    "    shift_min=-0.1,\n",
    "    shift_max=0.1,\n",
    "    )\n",
    "\n",
    "Noise_augment = gp.NoiseAugment(raw, mode=\"gaussian\")\n",
    "\n",
    "pipeline = (\n",
    "    source + gp.Normalize(raw)+\n",
    "            Intensity_augment+Elastic_augment + Simple_augment + Noise_augment\n",
    "           )\n",
    "\n",
    "# build the pipeline\n",
    "with gp.build(pipeline):\n",
    "    for x in range(10):\n",
    "        batch_vol1p = pipeline.request_batch(request_vol1p)\n",
    "        batch_vol2p = pipeline.request_batch(request_vol2p)\n",
    "        batch_vol1u = pipeline.request_batch(request_vol1u)\n",
    "        batch_vol2u = pipeline.request_batch(request_vol2u)\n",
    "        # show the content of the batch\n",
    "        #print(f\"batch returned: {batch}\")\n",
    "\n",
    "        # plot first slice of volume\n",
    "\n",
    "        # fig, (ax1, ax2) = plt.subplots(1, 2)\n",
    "        # ax1.imshow(np.flipud(batch_vol1p[raw].data[0,1,:,:]))\n",
    "        # ax2.imshow(np.flipud(batch_vol2p[raw].data[0,1,:,:]))\n",
    "        # plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "54945ec0-4a63-486a-bd16-8d8829fef1a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# specify request \n",
    "#plt.imshow(np.flipud(batch_vol1[raw].data[0,0,:,:]))\n",
    "\n",
    "# request = gp.BatchRequest()\n",
    "# request[raw] = gp.Roi(coord, volSize)\n",
    "\n",
    "# with gp.build(pipeline):\n",
    "#     batch_vol1_aug = pipeline.request_batch(request)\n",
    "#     batch_vol2_aug = pipeline.request_batch(request)\n",
    "\n",
    "# fig, (ax1, ax2, ax3, ax4) = plt.subplots(1, 4)\n",
    "# ax1.imshow(np.flipud(batch_vol1[raw].data[0,0,:,:]))\n",
    "# ax1.set_title('input vol1')\n",
    "# ax2.imshow(np.flipud(batch_vol1_aug[raw].data[0,0,:,:]))\n",
    "# ax2.set_title('aug vol1')\n",
    "# ax3.imshow(np.flipud(batch_vol2[raw].data[0,0,:,:]))\n",
    "# ax3.set_title('input vol2')\n",
    "# ax4.imshow(np.flipud(batch_vol2_aug[raw].data[0,0,:,:]))\n",
    "# ax4.set_title('aug vol2')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a77f74b5-d746-4fe4-8661-2f5efcc0e95b",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Define the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "4517e490-95cb-4786-b8d8-52b7a051da79",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Vgg3D(torch.nn.Module):\n",
    "\n",
    "    def __init__(self, input_size, output_classes, downsample_factors, fmaps=12):\n",
    "\n",
    "        super(Vgg3D, self).__init__()\n",
    "\n",
    "        self.input_size = input_size\n",
    "        self.downsample_factors = downsample_factors\n",
    "        self.output_classes = 2\n",
    "\n",
    "        current_fmaps, h, w, d = tuple(input_size)\n",
    "        current_size = (h, w,d)\n",
    "\n",
    "        features = []\n",
    "        for i in range(len(downsample_factors)):\n",
    "\n",
    "            features += [\n",
    "                torch.nn.Conv3d(current_fmaps,fmaps,kernel_size=3,padding=1),\n",
    "                torch.nn.BatchNorm3d(fmaps),\n",
    "                torch.nn.ReLU(inplace=True),\n",
    "                torch.nn.Conv3d(fmaps,fmaps,kernel_size=3,padding=1),\n",
    "                torch.nn.BatchNorm3d(fmaps),\n",
    "                torch.nn.ReLU(inplace=True),\n",
    "                torch.nn.MaxPool3d(downsample_factors[i])\n",
    "            ]\n",
    "\n",
    "            current_fmaps = fmaps\n",
    "            fmaps *= 2\n",
    "\n",
    "            size = tuple(\n",
    "                int(c/d)\n",
    "                for c, d in zip(current_size, downsample_factors[i]))\n",
    "            check = (\n",
    "                s*d == c\n",
    "                for s, d, c in zip(size, downsample_factors[i], current_size))\n",
    "            assert all(check), \\\n",
    "                \"Can not downsample %s by chosen downsample factor\" % \\\n",
    "                (current_size,)\n",
    "            current_size = size\n",
    "\n",
    "        self.features = torch.nn.Sequential(*features)\n",
    "\n",
    "        classifier = [\n",
    "            torch.nn.Linear(current_size[0] *current_size[1]*current_size[2] *current_fmaps,4096),\n",
    "            torch.nn.ReLU(inplace=True),\n",
    "            torch.nn.Dropout(),\n",
    "            torch.nn.Linear(4096,4096),\n",
    "            torch.nn.ReLU(inplace=True),\n",
    "            torch.nn.Dropout(),\n",
    "            torch.nn.Linear(4096,output_classes)\n",
    "        ]\n",
    "\n",
    "        self.classifier = torch.nn.Sequential(*classifier)\n",
    "    \n",
    "    def forward(self, raw):\n",
    "\n",
    "        # add a channel dimension to raw\n",
    "        # shape = tuple(raw.shape)\n",
    "        # raw = raw.reshape(shape[0], 1, shape[1], shape[2])\n",
    "        \n",
    "        # compute features\n",
    "        f = self.features(raw)\n",
    "        f = f.view(f.size(0), -1)\n",
    "        \n",
    "        # classify\n",
    "        y = self.classifier(f)\n",
    "\n",
    "        return y"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "29ff22bf-d49f-42bf-b92d-b110037d97fc",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Loss Functions\n",
    "\n",
    "We'll probably need to test some different loss functions. List some here:\n",
    "Contrastive loss\n",
    "cosine similarity\n",
    "triplet loss\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "7c52a2b5-1749-4209-b022-41a445109799",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ContrastiveLoss(nn.Module):\n",
    "    \"Contrastive loss function\"\n",
    "\n",
    "    def __init__(self, margin=2.0):\n",
    "        super(ContrastiveLoss, self).__init__()\n",
    "        self.margin = margin\n",
    "\n",
    "    def forward(self, output1, output2, label):\n",
    "        euclidean_distance = F.pairwise_distance(output1, output2)\n",
    "        loss_contrastive = torch.mean(\n",
    "            (1 - label) * torch.pow(euclidean_distance, 2)\n",
    "            + (label)\n",
    "            * torch.pow(torch.clamp(self.margin - euclidean_distance, min=0.0), 2)\n",
    "        )\n",
    "\n",
    "        return loss_contrastive"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "9da12ed3-cb32-4e26-809d-8aed7cf9ec28",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_size = (1, 64, 64, 5)\n",
    "downsample_factors =[(2, 2, 1), (2, 2, 1), (2, 2, 1), (2, 2, 1)];\n",
    "output_classes = 12\n",
    "\n",
    "# create the model to train\n",
    "model = Vgg3D(input_size, output_classes,  downsample_factors = downsample_factors)\n",
    "model = model.to(device)\n",
    "\n",
    "#summary(model, input_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "27bbf7d8-1dfb-441b-a523-894c3be93493",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Training length\n",
    "epochs = 100\n",
    "\n",
    "#loss_function = torch.nn.BCELoss()\n",
    "loss_function = torch.nn.CosineEmbeddingLoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=1e-4, weight_decay=0.0005)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e03dec6c-14c4-4400-8ff5-d523845d6105",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Training Test"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "79686e15-7006-4f8d-8875-b2f9aa03b396",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Implementing the Siamese Network\n",
    "\n",
    "The above training is just to test if the VGG model works for 3D data. Here, the training will take two pairs of images and calculate the loss from both pairs of images."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "28a74c3a-e50e-47c1-9689-4cbea55308e6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "      <iframe id=\"tensorboard-frame-ab8d9eb6bfd85254\" width=\"100%\" height=\"800\" frameborder=\"0\">\n",
       "      </iframe>\n",
       "      <script>\n",
       "        (function() {\n",
       "          const frame = document.getElementById(\"tensorboard-frame-ab8d9eb6bfd85254\");\n",
       "          const url = new URL(\"/\", window.location);\n",
       "          const port = 6006;\n",
       "          if (port) {\n",
       "            url.port = port;\n",
       "          }\n",
       "          frame.src = url;\n",
       "        })();\n",
       "      </script>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#%tensorboard --logdir models\n",
    "\n",
    "logger = SummaryWriter()\n",
    "%tensorboard --logdir runs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71160755-6f76-42e1-9d36-c70fca812139",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/100 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "..................................................epoch 0, total_loss = 337.4620666503906, positive_loss=98.49934387207031, negative_loss=238.96278381347656\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  1%|          | 1/100 [24:36<40:35:26, 1476.03s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ".................................................."
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  2%|▏         | 2/100 [49:25<40:24:09, 1484.18s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 1, total_loss = 253.28677368164062, positive_loss=87.8821029663086, negative_loss=165.4046173095703\n",
      ".................................................."
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  3%|▎         | 3/100 [1:13:21<39:23:44, 1462.11s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 2, total_loss = 214.09352111816406, positive_loss=84.0785140991211, negative_loss=130.0149383544922\n",
      "..................................................epoch 3, total_loss = 198.96368408203125, positive_loss=71.08006286621094, negative_loss=127.88374328613281\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  4%|▍         | 4/100 [1:37:35<38:53:58, 1458.73s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ".................................................."
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  5%|▌         | 5/100 [2:01:43<38:23:37, 1454.92s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 4, total_loss = 177.09120178222656, positive_loss=59.187835693359375, negative_loss=117.90338897705078\n",
      ".................................................."
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  6%|▌         | 6/100 [2:26:25<38:14:02, 1464.28s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 5, total_loss = 172.8775634765625, positive_loss=55.37092590332031, negative_loss=117.50662231445312\n",
      "..................................................epoch 6, total_loss = 170.76229858398438, positive_loss=51.94095993041992, negative_loss=118.8213119506836\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  7%|▋         | 7/100 [2:50:40<37:44:58, 1461.27s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ".................................................."
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  8%|▊         | 8/100 [3:15:17<37:27:51, 1466.00s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 7, total_loss = 159.0780792236328, positive_loss=51.91497039794922, negative_loss=107.16304779052734\n",
      ".................................................."
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  9%|▉         | 9/100 [3:39:40<37:01:57, 1465.03s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 8, total_loss = 148.15090942382812, positive_loss=49.794376373291016, negative_loss=98.35643768310547\n",
      "..................................................epoch 9, total_loss = 141.6306915283203, positive_loss=44.489601135253906, negative_loss=97.14107513427734\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 10%|█         | 10/100 [4:03:52<36:31:30, 1461.00s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ".................................................."
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 11%|█         | 11/100 [4:27:38<35:51:34, 1450.50s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 10, total_loss = 132.94293212890625, positive_loss=41.20863342285156, negative_loss=91.73429107666016\n",
      ".................................................."
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 12%|█▏        | 12/100 [4:51:56<35:30:43, 1452.77s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 11, total_loss = 127.73004150390625, positive_loss=41.46647262573242, negative_loss=86.26354217529297\n",
      "..................................................epoch 12, total_loss = 122.68574523925781, positive_loss=40.49368667602539, negative_loss=82.19200897216797\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 13%|█▎        | 13/100 [5:15:52<34:59:03, 1447.62s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ".................................................."
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 14%|█▍        | 14/100 [5:39:56<34:33:12, 1446.43s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 13, total_loss = 119.66268920898438, positive_loss=42.64120101928711, negative_loss=77.02149963378906\n",
      ".................................................."
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 15%|█▌        | 15/100 [6:04:06<34:10:49, 1447.64s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 14, total_loss = 116.99079895019531, positive_loss=41.2808952331543, negative_loss=75.70986938476562\n",
      "..................................................epoch 15, total_loss = 111.013916015625, positive_loss=37.588768005371094, negative_loss=73.4251937866211\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 16%|█▌        | 16/100 [6:27:47<33:35:32, 1439.67s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ".................................................."
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 17%|█▋        | 17/100 [6:51:05<32:53:59, 1426.98s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 16, total_loss = 114.76478576660156, positive_loss=38.8961296081543, negative_loss=75.8686752319336\n",
      ".................................................."
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 18%|█▊        | 18/100 [7:15:07<32:36:20, 1431.47s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 17, total_loss = 107.42520141601562, positive_loss=33.15119171142578, negative_loss=74.27405548095703\n",
      "..................................................epoch 18, total_loss = 107.76107025146484, positive_loss=36.26688003540039, negative_loss=71.49414825439453\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 19%|█▉        | 19/100 [7:39:36<32:28:03, 1443.01s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ".................................................."
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 20%|██        | 20/100 [8:03:53<32:09:26, 1447.09s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 19, total_loss = 111.64989471435547, positive_loss=35.31226348876953, negative_loss=76.33757781982422\n",
      ".................................................."
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 21%|██        | 21/100 [8:28:11<31:49:47, 1450.47s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 20, total_loss = 103.95399475097656, positive_loss=33.305564880371094, negative_loss=70.64836883544922\n",
      "..................................................epoch 21, total_loss = 108.86979675292969, positive_loss=34.09258270263672, negative_loss=74.77716064453125\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 22%|██▏       | 22/100 [8:52:11<31:21:31, 1447.32s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ".................................................."
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 23%|██▎       | 23/100 [9:16:32<31:02:23, 1451.21s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 22, total_loss = 105.49922943115234, positive_loss=32.1782341003418, negative_loss=73.3210678100586\n",
      ".................................................."
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 24%|██▍       | 24/100 [9:41:09<30:48:17, 1459.18s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 23, total_loss = 102.30107879638672, positive_loss=31.65283966064453, negative_loss=70.64825439453125\n",
      "..................................................epoch 24, total_loss = 111.62601470947266, positive_loss=32.634300231933594, negative_loss=78.99175262451172\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 25%|██▌       | 25/100 [10:06:15<30:41:22, 1473.10s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ".................................................."
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 26%|██▌       | 26/100 [10:31:18<30:27:58, 1482.14s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 25, total_loss = 101.5271987915039, positive_loss=31.448143005371094, negative_loss=70.07905578613281\n",
      ".................................................."
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 27%|██▋       | 27/100 [10:56:42<30:18:24, 1494.58s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 26, total_loss = 102.49300384521484, positive_loss=32.07850646972656, negative_loss=70.41447448730469\n",
      "..................................................epoch 27, total_loss = 97.88349151611328, positive_loss=29.561983108520508, negative_loss=68.32158660888672\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 28%|██▊       | 28/100 [11:21:52<29:59:12, 1499.34s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "."
     ]
    }
   ],
   "source": [
    "from tqdm import tqdm\n",
    "\n",
    "def train(tb_logger = None, log_image_interval = 10):\n",
    "    if torch.cuda.is_available():\n",
    "        device = torch.device(\"cuda\")\n",
    "    else:\n",
    "        device = torch.device(\"cpu\")\n",
    "        \n",
    "    loss=[] \n",
    "    counter=[]\n",
    "    with gp.build(pipeline_paired), gp.build(pipeline_unpaired):\n",
    "        for epoch in tqdm(range(epochs)):\n",
    "            epoch_loss = 0\n",
    "            epoch_loss_pos = 0\n",
    "            epoch_loss_neg = 0\n",
    "            for x in range(500):\n",
    "                if (x % 10) == 0:\n",
    "                    print('.', end='')\n",
    "                unpaired = pipeline_unpaired.request_batch(request)\n",
    "                yu = -1 #zero if using contrastive loss, -1 if using cosine similarity\n",
    "                \n",
    "                paired = pipeline_paired.request_batch(request)\n",
    "                yp = 1\n",
    "                \n",
    "                unpaired1 = unpaired[raw].data\n",
    "                unpaired2 = unpaired[raw_shift].data\n",
    "                paired1 = paired[raw].data\n",
    "                paired2 = paired[raw_shift].data\n",
    "                \n",
    "                unpaired1 = np.reshape(unpaired1, (batch_size,64, 64, 5))\n",
    "                unpaired2 = np.reshape(unpaired2, (batch_size,64, 64, 5))\n",
    "                paired1 = np.reshape(paired1, (batch_size,64, 64, 5))\n",
    "                paired2 = np.reshape(paired2, (batch_size,64, 64, 5))\n",
    "                \n",
    "                # unpaired1 = np.reshape(unpaired1, (batch_size,16, 16, 5))\n",
    "                # unpaired2 = np.reshape(unpaired2, (batch_size,16, 16, 5))\n",
    "                # paired1 = np.reshape(paired1, (batch_size,16, 16, 5))\n",
    "                # paired2 = np.reshape(paired2, (batch_size,16, 16, 5))\n",
    "                \n",
    "                unpaired1 = np.expand_dims(unpaired1, axis =1)\n",
    "                unpaired2 = np.expand_dims(unpaired2, axis=1)\n",
    "                paired1 = np.expand_dims(paired1, axis =1)\n",
    "                paired2 = np.expand_dims(paired2, axis=1)\n",
    "\n",
    "                unpaired1 = torch.from_numpy(unpaired1).to(device).float()\n",
    "                unpaired2 = torch.from_numpy(unpaired2).to(device).float()\n",
    "                yu = torch.from_numpy(np.array([yu])).to(device).float()\n",
    "                \n",
    "                paired1 = torch.from_numpy(paired1).to(device).float()\n",
    "                paired2 = torch.from_numpy(paired2).to(device).float() \n",
    "                yp = torch.from_numpy(np.array([yp])).to(device).float()\n",
    "\n",
    "                optimizer.zero_grad()\n",
    "                \n",
    "                predp1 = model(paired1)\n",
    "                predp2 = model(paired2)\n",
    "                predu1 = model(unpaired1)\n",
    "                predu2 = model(unpaired2)\n",
    "                #print(model(unpaired1).shape)\n",
    "                #print(predp1.shape)\n",
    "\n",
    "                #loss = loss_function(pred, y)\n",
    "                \n",
    "                #print(predp1.shape)\n",
    "\n",
    "                loss_contrastivep = loss_function(predp1,predp2,yp)\n",
    "                loss_contrastiveu = loss_function(predu1,predu2,yu)\n",
    "\n",
    "                loss_contrastivep.backward()\n",
    "                loss_contrastiveu.backward()\n",
    "                optimizer.step()    \n",
    "                epoch_loss_pos += loss_contrastivep\n",
    "                epoch_loss_neg += loss_contrastiveu\n",
    "                epoch_loss += loss_contrastivep + loss_contrastiveu\n",
    "                \n",
    "                \n",
    "                \n",
    "                if tb_logger is not None:\n",
    "                    step = epoch * 500 + x\n",
    "                    tb_logger.add_scalar(\n",
    "                        tag=\"positive_loss\", scalar_value=loss_contrastivep.item(), global_step=step\n",
    "                    )\n",
    "                    tb_logger.add_scalar(\n",
    "                        tag=\"negative_loss\", scalar_value=loss_contrastiveu.item(), global_step=step\n",
    "                    )\n",
    "                    tb_logger.add_scalar(\n",
    "                        tag=\"total_loss\", scalar_value=loss_contrastivep+loss_contrastiveu.item(), global_step = step\n",
    "                    )\n",
    "                    # check if we log images in this iteration\n",
    "                    # if step % log_image_interval == 0:\n",
    "                    #     tb_logger.add_images(\n",
    "                    #         tag=\"in_unpaired1\", img_tensor=unpaired1.to(\"cpu\"), global_step=step\n",
    "                    #     )\n",
    "                    #     tb_logger.add_images(\n",
    "                    #         tag=\"in_unpaired2\", img_tensor=unpaired2.to(\"cpu\"), global_step=step\n",
    "                    #     )\n",
    "                    #     tb_logger.add_images(\n",
    "                    #         tag=\"in_paired1\", img_tensor=paired1.to(\"cpu\"), global_step=step\n",
    "                    #     )\n",
    "                    #     tb_logger.add_images(\n",
    "                    #         tag=\"in_paired2\", img_tensor=paired2.to(\"cpu\"), global_step=step\n",
    "                    #     )\n",
    "\n",
    "\n",
    "            print(f\"epoch {epoch}, total_loss = {epoch_loss}, positive_loss={epoch_loss_pos}, negative_loss={epoch_loss_neg}\")\n",
    "            \n",
    "            if(epoch % 3 == 0):\n",
    "                baseP = '/mnt/shared/celltracking/modelstates/'\n",
    "                machine = 'aaron'\n",
    "                e = epoch ### replace\n",
    "                saveP = (baseP+'/'+machine+'/'+str(f'epoch_{e}'))\n",
    "                torch.save(model.state_dict(), saveP)\n",
    "\n",
    "    return model\n",
    "\n",
    "model = train(tb_logger = logger)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4bad3724-0af7-4a27-94c5-b25d542a50ee",
   "metadata": {},
   "source": [
    "# Tracking / Linear Assignment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25131276-e24d-48bd-99eb-bc3585b94fe6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6bea3437-f41e-4a70-8d7a-bfe2b7d33d07",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1cde2288-7397-4773-a7d6-049ed8e92930",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa5f64d3-699d-4347-8436-08d1d66418bb",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
