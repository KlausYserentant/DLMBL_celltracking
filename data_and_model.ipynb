{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "96fa3a08-111f-4d26-8e65-7be9ba004054",
   "metadata": {},
   "source": [
    "# Model Implementation for 3D Cell Tracking\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "15fd6961-5904-42c4-9fd7-190c0685c312",
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install torchsummary \n",
    "# !pip install gunpowder\n",
    "# !pip install zarr\n",
    "# !pip install matplotlib\n",
    "# pip install tensorboard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2503c9e5-eea9-4751-9600-fd8c537aecea",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/bourquea/miniconda3/envs/celltracking/lib/python3.9/site-packages/tqdm/auto.py:22: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "from torch.utils.data import DataLoader, random_split\n",
    "from torch.utils.data.sampler import WeightedRandomSampler\n",
    "from torchvision.datasets import ImageFolder\n",
    "from torchvision import transforms\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import numpy as np\n",
    "import random \n",
    "import matplotlib.pyplot as plt\n",
    "from torchvision import models\n",
    "from torchsummary import summary\n",
    "\n",
    "from torchvision import datasets\n",
    "from torchvision import transforms\n",
    "from torch.utils.data.sampler import SubsetRandomSampler\n",
    "import gunpowder as gp\n",
    "import zarr\n",
    "import math\n",
    "%load_ext tensorboard\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "import skimage\n",
    "import networkx\n",
    "import pathlib\n",
    "from tifffile import imread, imwrite\n",
    "import tensorboard\n",
    "import torch.nn.functional as F\n",
    "\n",
    "# Device configuration\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "835c90df-e975-4373-9a30-ff0977d23544",
   "metadata": {},
   "source": [
    "# Data Importing"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "235c18c9-a9f7-4312-8b09-501b6bbc53d7",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Extract Centroids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b93a13da-0440-4782-a888-a49085a172d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# function to convert 'TRA' channel into cell and frame-wise centroid positions\n",
    "## Function to extract trajectories from data\n",
    "\n",
    "base_path = pathlib.Path(\"/mnt/shared/celltracking/data/cho/\")\n",
    "\n",
    "\n",
    "# read parent-child links from file\n",
    "links = np.loadtxt(base_path / \"01_GT/TRA\" / \"man_track.txt\", dtype=int)\n",
    "\n",
    "# read annotated image stack\n",
    "centroids = np.stack([imread(xi) for xi in sorted((base_path / \"01_GT/TRA\").glob(\"*.tif\"))])  # images\n",
    "\n",
    "# extract centroids from annotated image stacks\n",
    "centers = skimage.measure.regionprops(centroids[0,0,:,:])\n",
    "tracks = []\n",
    "for t, frame in enumerate(centroids):\n",
    "    centers = skimage.measure.regionprops(frame)\n",
    "    for c in centers:\n",
    "        tracks.append([c.label, t, int(c.centroid[1]), int(c.centroid[2])])\n",
    "        \n",
    "# constructs graph \n",
    "tracks = np.array(tracks)\n",
    "graph = networkx.DiGraph()\n",
    "for cell_id, t, x, y in tracks:\n",
    "    graph.add_node((cell_id,t), x=x, y=y, t=t)\n",
    "    \n",
    "for cell_id, t in graph.nodes():\n",
    "    if (cell_id, t+1) in graph.nodes():\n",
    "        graph.add_edge((cell_id, t), (cell_id,t+1))\n",
    "\n",
    "for child_id, child_from, _, child_parent_id in links:\n",
    "    for parent_id, _, parent_to, _ in links:\n",
    "        if child_parent_id == parent_id:\n",
    "            graph.add_edge((parent_id, parent_to), (child_id, child_from))\n",
    "            \n",
    "# extract trajectories from graph set\n",
    "tracks = [graph.subgraph(c) for c in networkx.weakly_connected_components(graph) if len(c)>0]\n",
    "\n",
    "# remove tracks with 0 edges\n",
    "tracks = [track for track in tracks if len(track.edges)>0]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "81f68ecf-4eea-4477-94a4-545c211c7290",
   "metadata": {},
   "outputs": [],
   "source": [
    "tracks_valid = tracks[12:]\n",
    "tracks = tracks[:12]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8226e7f8-90f8-41ee-ad99-f0b63fddd0f7",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Define function to make image pairs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a770c1f1-4e52-49ae-9f50-abd61b92b360",
   "metadata": {},
   "outputs": [],
   "source": [
    "class getPaired(gp.BatchFilter):\n",
    "\n",
    "    def __init__(self, raw, raw_shift, tracks, paired=True):\n",
    "        self.raw = raw\n",
    "        self.raw_shift = raw_shift\n",
    "        self.tracks = tracks\n",
    "        self.paired = paired\n",
    "    \n",
    "    # _ref channel array is stored in raw_ref, while second volume in pair will be stored raw_new\n",
    "    def prepare(self, request):\n",
    "        # obtain volume coordinates from tracks                \n",
    "        deps = gp.BatchRequest()\n",
    "        vol1,vol2 = self.sampler(request)\n",
    "                \n",
    "        deps[self.raw] = gp.ArraySpec(roi=gp.Roi(vol1,request[self.raw].roi.get_shape()))\n",
    "        deps[self.raw_shift] = gp.ArraySpec(roi=gp.Roi(vol2,request[self.raw_shift].roi.get_shape()))\n",
    "\n",
    "        return deps\n",
    "    \n",
    "    # required to inform downstream nodes about new array \n",
    "    def process(self, batch, request):\n",
    "        # create a new batch to hold the new array\n",
    "        out_batch = gp.Batch()\n",
    "\n",
    "        # create new array and store it in the batch\n",
    "        out_batch[self.raw_shift] = batch[self.raw_shift]\n",
    "        out_batch[self.raw] = batch[self.raw]\n",
    "        \n",
    "        #print(f'raw: {batch[self.raw].spec.roi}')\n",
    "        #print(batch[self.raw_shift].spec.roi)\n",
    "        \n",
    "        # make sure that coordinates for batch[raw] and batch[raw_shift] are reset to (0,0,0,0,0)\n",
    "        out_batch[self.raw].spec.roi = request[self.raw].roi\n",
    "        out_batch[self.raw_shift].spec.roi = request[self.raw_shift].roi\n",
    "\n",
    "        # return the new batch\n",
    "        return out_batch\n",
    "    \n",
    "    # select pairs of subvolumes from data\n",
    "    def sampler(self,request):\n",
    "        tracks = self.tracks\n",
    "        paired = self.paired\n",
    "        # choose connected nodes\n",
    "        # if self.paired:\n",
    "        if paired:\n",
    "            t0 = tracks[np.random.randint(0,len(tracks),1).item()]\n",
    "            e0 = list(t0.edges)[np.random.randint(len(list(t0.edges)))]\n",
    "            node0 = t0.nodes[e0[0]]\n",
    "            node1 = t0.nodes[e0[1]]\n",
    "            \n",
    "        # choose random unconnected nodes\n",
    "        else:\n",
    "            # randomly choose two tracks and make sure they are not identical\n",
    "            t0,t1 = np.random.randint(0,len(tracks),2)\n",
    "            while t0==t1:\n",
    "                t0,t1 = np.random.randint(0,len(tracks),2)\n",
    "\n",
    "            #print(f'trackids: {t0,t1}')\n",
    "            t0 = tracks[t0]\n",
    "            t1 = tracks[t1]\n",
    "\n",
    "            # choose random edges from each track\n",
    "            #print(f'number edges per track{len(list(t0.nodes)),len(list(t1.nodes))}')\n",
    "\n",
    "            r0 = np.random.randint(0,len(list(t0.nodes))) \n",
    "            r1 = np.random.randint(0,len(list(t1.nodes)))\n",
    "\n",
    "            node0 = t0.nodes[list(t0.nodes)[r0]]\n",
    "            node1 = t1.nodes[list(t1.nodes)[r1]]\n",
    "            \n",
    "\n",
    "\n",
    "        node0_xyt = [node0[\"x\"], node0[\"y\"], node0[\"t\"]]\n",
    "        node1_xyt = [node1[\"x\"], node1[\"y\"], node1[\"t\"]]\n",
    "\n",
    "        #print(f'input coord: {node0_xyt,node1_xyt}')\n",
    "\n",
    "        roi_in = request[self.raw_shift].roi.get_shape()\n",
    "        #t,z,y,x\n",
    "        coords_vol0 = (node0_xyt[2],0,node0_xyt[0]-(roi_in[2]/2),node0_xyt[1]-(roi_in[3]/2))\n",
    "        coords_vol1 = (node1_xyt[2],0,node1_xyt[0]-(roi_in[2]/2),node1_xyt[1]-(roi_in[3]/2))\n",
    "        #print(f'output coords - vol0: {coords_vol0}, vol1:{coords_vol1}')\n",
    "\n",
    "        return coords_vol0, coords_vol1\n",
    "            "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bbe16d12-0fe2-41dd-bf22-eeaf290b3e65",
   "metadata": {},
   "source": [
    "# Make batches "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "9374eed7-3581-4bae-a4e3-a59c6134da27",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ROI: None, voxel size: None, interpolatable: None, non-spatial: False, dtype: None, placeholder: False"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#specify subvolume size and volume source\n",
    "volSize = (1,5,64, 64)\n",
    "coord = (0,0,0,0)\n",
    "batch_size = 8\n",
    "\n",
    "zarrdir = '/mnt/shared/celltracking/data/cho/01.zarr'\n",
    "raw = gp.ArrayKey('raw')\n",
    "raw_shift = gp.ArrayKey('raw_shift')\n",
    "\n",
    "# create \"pipeline\" consisting only of a data source\n",
    "\n",
    "\n",
    "#Augmentations=\n",
    "\n",
    "# chose a random source (i.e., sample) from the above\n",
    "#random_location = gp.RandomLocation()\n",
    "\n",
    "pipeline_paired = (gp.ZarrSource(\n",
    "    zarrdir,  # the zarr container\n",
    "    {raw_shift: 'raw', raw: 'raw'},  # which dataset to associate to the array key\n",
    "    {raw_shift: gp.ArraySpec(voxel_size=(1,1,1,1), interpolatable=True), raw:gp.ArraySpec(voxel_size=(1,1,1,1), interpolatable=True)}  # meta-information\n",
    "    )+ gp.Normalize(raw)+gp.Normalize(raw_shift)+ \n",
    "    gp.Pad(raw_shift, None) + \n",
    "    gp.Pad(raw, None) + gp.IntensityAugment(\n",
    "    raw,\n",
    "    scale_min=0.9,\n",
    "    scale_max=1.1,\n",
    "    shift_min=-0.1,\n",
    "    shift_max=0.1,\n",
    "    ) + gp.NoiseAugment(raw, mode=\"gaussian\")) + gp.IntensityAugment(\n",
    "    raw_shift,\n",
    "    scale_min=0.9,\n",
    "    scale_max=1.1,\n",
    "    shift_min=-0.1,\n",
    "    shift_max=0.1,\n",
    "    ) + gp.NoiseAugment(raw_shift, mode=\"gaussian\") + getPaired(raw,raw_shift,tracks,paired=True) + gp.ElasticAugment(\n",
    "    [2,10,10],\n",
    "    [0,2,2],\n",
    "    [0,0*math.pi/2.0],\n",
    "    prob_slip=0.05,\n",
    "    prob_shift=0.05,\n",
    "    max_misalign=25) + gp.SimpleAugment(transpose_only=[2, 3], mirror_only=[])\n",
    "\n",
    "\n",
    "\n",
    "pipeline_unpaired = (gp.ZarrSource(\n",
    "    zarrdir,  # the zarr container\n",
    "    {raw_shift: 'raw', raw: 'raw'},  # which dataset to associate to the array key\n",
    "    {raw_shift: gp.ArraySpec(voxel_size=(1,1,1,1), interpolatable=True), raw:gp.ArraySpec(voxel_size=(1,1,1,1), interpolatable=True)}  # meta-information\n",
    "    )+ gp.Normalize(raw)+gp.Normalize(raw_shift)+ \n",
    "    gp.Pad(raw_shift, None) + \n",
    "    gp.Pad(raw, None) + gp.IntensityAugment(\n",
    "    raw,\n",
    "    scale_min=0.9,\n",
    "    scale_max=1.1,\n",
    "    shift_min=-0.1,\n",
    "    shift_max=0.1,\n",
    "    ) + gp.NoiseAugment(raw, mode=\"gaussian\") + gp.IntensityAugment(\n",
    "    raw_shift,\n",
    "    scale_min=0.9,\n",
    "    scale_max=1.1,\n",
    "    shift_min=-0.1,\n",
    "    shift_max=0.1,\n",
    "    ) + gp.NoiseAugment(raw_shift, mode=\"gaussian\")) + getPaired(raw,raw_shift,tracks,paired=False)  + gp.ElasticAugment(\n",
    "    [2,10,10],\n",
    "    [0,2,2],\n",
    "    [0,0*math.pi/2.0],\n",
    "    prob_slip=0.05,\n",
    "    prob_shift=0.05,\n",
    "    max_misalign=25) + gp.SimpleAugment(transpose_only=[2, 3], mirror_only=[]) \n",
    "\n",
    "pipeline_paired += gp.PreCache(num_workers=6) \n",
    "pipeline_unpaired += gp.PreCache(num_workers=6)\n",
    "pipeline_paired += gp.Stack(batch_size)\n",
    "pipeline_unpaired += gp.Stack(batch_size)\n",
    "\n",
    "# specify request\n",
    "request = gp.BatchRequest()\n",
    "request[raw] = gp.Roi(coord, volSize)\n",
    "request[raw_shift] = gp.Roi(coord, volSize)\n",
    "\n",
    "gp.ArraySpec()\n",
    "# build the pipeline...\n",
    "# with gp.build(pipeline_paired), gp.build(pipeline_unpaired):\n",
    "\n",
    "  # ...and request a batch\n",
    "  # batch = pipeline_unpaired.request_batch(request)\n",
    "  \n",
    "#show the content of the batch\n",
    "#print(f\"batch returned: {batch}\")\n",
    "\n",
    "# plot first slice of volume\n",
    "#fig, axs = plt.subplots(1,2)\n",
    "# print(batch[raw].data.shape)\n",
    "# axs[0].imshow(np.flipud(batch[raw].data[0,0,:,:]))\n",
    "# axs[1].imshow(np.flipud(batch[raw_shift].data[0,0,:,:]))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "ead44e01-a035-424e-84e3-3d2968cf0132",
   "metadata": {},
   "outputs": [],
   "source": [
    "# provide path to zarr directory\n",
    "zarrdir = '/mnt/shared/celltracking/data/cho/01.zarr'\n",
    "\n",
    "data = zarr.open(zarrdir)\n",
    "loader = []"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6717dd30-e83f-4443-8f6d-1666d2021de4",
   "metadata": {},
   "source": [
    "## Define Augmentation pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "31f1af22-baa3-4eba-ae20-c9c752d661d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# provide path to zarr directory\n",
    "#zarrdir = '/mnt/shared/celltracking/data/cho/01.zarr'\n",
    "\n",
    "# pre-selected volumes from cho dataset\n",
    "coord_paired = ((0,0,80, 175),(1,0,80, 180))\n",
    "coord_unpaired = ((0,0,80, 175),(1,0,92, 232))\n",
    "\n",
    "# specify subvolume size and volume source\n",
    "volSize = (1,5,64, 64)\n",
    "coord = coord_paired[0]\n",
    "\n",
    "# declare arrays to use in the pipeline\n",
    "key ='raw'\n",
    "raw = gp.ArrayKey(key)\n",
    "\n",
    "# create \"pipeline\" consisting only of a data source\n",
    "source = gp.ZarrSource(\n",
    "    zarrdir,  # the zarr container\n",
    "    {raw: key},  # which dataset to associate to the array key\n",
    "    {raw: gp.ArraySpec(interpolatable=True, voxel_size = (1,1,1,1))}  # meta-information\n",
    ")\n",
    "pipeline = source\n",
    "\n",
    "# specify request paired\n",
    "request_vol1p = gp.BatchRequest()\n",
    "request_vol2p = gp.BatchRequest()\n",
    "request_vol1p[raw] = gp.Roi(coord_paired[0], volSize)\n",
    "request_vol2p[raw] = gp.Roi(coord_paired[1], volSize)\n",
    "\n",
    "# specify request unpaired\n",
    "request_vol1u = gp.BatchRequest()\n",
    "request_vol2u = gp.BatchRequest()\n",
    "request_vol1u[raw] = gp.Roi(coord_unpaired[0], volSize)\n",
    "request_vol2u[raw] = gp.Roi(coord_unpaired[1], volSize)\n",
    "\n",
    "# build the pipeline\n",
    "with gp.build(pipeline):\n",
    "    batch_vol1p = pipeline.request_batch(request_vol1p)\n",
    "    batch_vol2p = pipeline.request_batch(request_vol2p)\n",
    "    batch_vol1u = pipeline.request_batch(request_vol1u)\n",
    "    batch_vol2u = pipeline.request_batch(request_vol2u)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b322f3f-106a-484b-a790-bee3da998c0d",
   "metadata": {},
   "source": [
    "# Augmentations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "286b229d-0e67-4fce-b2df-509b31132f0d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Augmentations=\n",
    "\n",
    "# chose a random source (i.e., sample) from the above\n",
    "#random_location = gp.RandomLocation()\n",
    "\n",
    "# elastically deform the batch\n",
    "Elastic_augment=gp.ElasticAugment(\n",
    "    [2,10,10],\n",
    "    [0,2,2],\n",
    "    [0,0*math.pi/2.0],\n",
    "    prob_slip=0.05,\n",
    "    prob_shift=0.05,\n",
    "    max_misalign=25)\n",
    "\n",
    "# apply transpose and mirror augmentations\n",
    "# Simple_augment=gp.SimpleAugment(transpose_only=[2, 3], mirror_only=[]) \n",
    "Simple_augment=gp.SimpleAugment(transpose_only=[], mirror_only=[])\n",
    "\n",
    "# scale and shift the intensity of the raw array\n",
    "Intensity_augment=gp.IntensityAugment(\n",
    "    raw,\n",
    "    scale_min=0.9,\n",
    "    scale_max=1.1,\n",
    "    shift_min=-0.1,\n",
    "    shift_max=0.1,\n",
    "    )\n",
    "\n",
    "Noise_augment = gp.NoiseAugment(raw, mode=\"gaussian\")\n",
    "\n",
    "pipeline = (\n",
    "    source + gp.Normalize(raw)+\n",
    "            Intensity_augment+Elastic_augment + Simple_augment + Noise_augment\n",
    "           )\n",
    "\n",
    "# build the pipeline\n",
    "with gp.build(pipeline):\n",
    "    for x in range(10):\n",
    "        batch_vol1p = pipeline.request_batch(request_vol1p)\n",
    "        batch_vol2p = pipeline.request_batch(request_vol2p)\n",
    "        batch_vol1u = pipeline.request_batch(request_vol1u)\n",
    "        batch_vol2u = pipeline.request_batch(request_vol2u)\n",
    "        # show the content of the batch\n",
    "        #print(f\"batch returned: {batch}\")\n",
    "\n",
    "        # plot first slice of volume\n",
    "\n",
    "        # fig, (ax1, ax2) = plt.subplots(1, 2)\n",
    "        # ax1.imshow(np.flipud(batch_vol1p[raw].data[0,1,:,:]))\n",
    "        # ax2.imshow(np.flipud(batch_vol2p[raw].data[0,1,:,:]))\n",
    "        # plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "54945ec0-4a63-486a-bd16-8d8829fef1a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# specify request \n",
    "#plt.imshow(np.flipud(batch_vol1[raw].data[0,0,:,:]))\n",
    "\n",
    "# request = gp.BatchRequest()\n",
    "# request[raw] = gp.Roi(coord, volSize)\n",
    "\n",
    "# with gp.build(pipeline):\n",
    "#     batch_vol1_aug = pipeline.request_batch(request)\n",
    "#     batch_vol2_aug = pipeline.request_batch(request)\n",
    "\n",
    "# fig, (ax1, ax2, ax3, ax4) = plt.subplots(1, 4)\n",
    "# ax1.imshow(np.flipud(batch_vol1[raw].data[0,0,:,:]))\n",
    "# ax1.set_title('input vol1')\n",
    "# ax2.imshow(np.flipud(batch_vol1_aug[raw].data[0,0,:,:]))\n",
    "# ax2.set_title('aug vol1')\n",
    "# ax3.imshow(np.flipud(batch_vol2[raw].data[0,0,:,:]))\n",
    "# ax3.set_title('input vol2')\n",
    "# ax4.imshow(np.flipud(batch_vol2_aug[raw].data[0,0,:,:]))\n",
    "# ax4.set_title('aug vol2')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a77f74b5-d746-4fe4-8661-2f5efcc0e95b",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Define the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "4517e490-95cb-4786-b8d8-52b7a051da79",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Vgg3D(torch.nn.Module):\n",
    "\n",
    "    def __init__(self, input_size, output_classes, downsample_factors, fmaps=12):\n",
    "\n",
    "        super(Vgg3D, self).__init__()\n",
    "\n",
    "        self.input_size = input_size\n",
    "        self.downsample_factors = downsample_factors\n",
    "        self.output_classes = 2\n",
    "\n",
    "        current_fmaps, h, w, d = tuple(input_size)\n",
    "        current_size = (h, w,d)\n",
    "\n",
    "        features = []\n",
    "        for i in range(len(downsample_factors)):\n",
    "\n",
    "            features += [\n",
    "                torch.nn.Conv3d(current_fmaps,fmaps,kernel_size=3,padding=1),\n",
    "                torch.nn.BatchNorm3d(fmaps),\n",
    "                torch.nn.ReLU(inplace=True),\n",
    "                torch.nn.Conv3d(fmaps,fmaps,kernel_size=3,padding=1),\n",
    "                torch.nn.BatchNorm3d(fmaps),\n",
    "                torch.nn.ReLU(inplace=True),\n",
    "                torch.nn.MaxPool3d(downsample_factors[i])\n",
    "            ]\n",
    "\n",
    "            current_fmaps = fmaps\n",
    "            fmaps *= 2\n",
    "\n",
    "            size = tuple(\n",
    "                int(c/d)\n",
    "                for c, d in zip(current_size, downsample_factors[i]))\n",
    "            check = (\n",
    "                s*d == c\n",
    "                for s, d, c in zip(size, downsample_factors[i], current_size))\n",
    "            assert all(check), \\\n",
    "                \"Can not downsample %s by chosen downsample factor\" % \\\n",
    "                (current_size,)\n",
    "            current_size = size\n",
    "\n",
    "        self.features = torch.nn.Sequential(*features)\n",
    "\n",
    "        classifier = [\n",
    "            torch.nn.Linear(current_size[0] *current_size[1]*current_size[2] *current_fmaps,4096),\n",
    "            torch.nn.ReLU(inplace=True),\n",
    "            torch.nn.Dropout(),\n",
    "            torch.nn.Linear(4096,4096),\n",
    "            torch.nn.ReLU(inplace=True),\n",
    "            torch.nn.Dropout(),\n",
    "            torch.nn.Linear(4096,output_classes)\n",
    "        ]\n",
    "\n",
    "        self.classifier = torch.nn.Sequential(*classifier)\n",
    "    \n",
    "    def forward(self, raw):\n",
    "\n",
    "        # add a channel dimension to raw\n",
    "        # shape = tuple(raw.shape)\n",
    "        # raw = raw.reshape(shape[0], 1, shape[1], shape[2])\n",
    "        \n",
    "        # compute features\n",
    "        f = self.features(raw)\n",
    "        f = f.view(f.size(0), -1)\n",
    "        \n",
    "        # classify\n",
    "        y = self.classifier(f)\n",
    "\n",
    "        return y"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "29ff22bf-d49f-42bf-b92d-b110037d97fc",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Loss Functions\n",
    "\n",
    "We'll probably need to test some different loss functions. List some here:\n",
    "Contrastive loss\n",
    "cosine similarity\n",
    "triplet loss\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "7c52a2b5-1749-4209-b022-41a445109799",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ContrastiveLoss(nn.Module):\n",
    "    \"Contrastive loss function\"\n",
    "\n",
    "    def __init__(self, margin=2.0):\n",
    "        super(ContrastiveLoss, self).__init__()\n",
    "        self.margin = margin\n",
    "\n",
    "    def forward(self, output1, output2, label):\n",
    "        euclidean_distance = F.pairwise_distance(output1, output2)\n",
    "        loss_contrastive = torch.mean(\n",
    "            (1 - label) * torch.pow(euclidean_distance, 2)\n",
    "            + (label)\n",
    "            * torch.pow(torch.clamp(self.margin - euclidean_distance, min=0.0), 2)\n",
    "        )\n",
    "\n",
    "        return loss_contrastive"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "9da12ed3-cb32-4e26-809d-8aed7cf9ec28",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_size = (1, 64, 64, 5)\n",
    "downsample_factors =[(2, 2, 1), (2, 2, 1), (2, 2, 1), (2, 2, 1)];\n",
    "output_classes = 12\n",
    "\n",
    "# create the model to train\n",
    "model = Vgg3D(input_size, output_classes,  downsample_factors = downsample_factors)\n",
    "model = model.to(device)\n",
    "\n",
    "#summary(model, input_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "27bbf7d8-1dfb-441b-a523-894c3be93493",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Training length\n",
    "epochs = 5000\n",
    "\n",
    "#loss_function = torch.nn.BCELoss()\n",
    "loss_function = torch.nn.CosineEmbeddingLoss()\n",
    "#loss_function = ContrastiveLoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=1e-4, weight_decay=0.0005)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e03dec6c-14c4-4400-8ff5-d523845d6105",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Training Test"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "79686e15-7006-4f8d-8875-b2f9aa03b396",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Implementing the Siamese Network\n",
    "\n",
    "The above training is just to test if the VGG model works for 3D data. Here, the training will take two pairs of images and calculate the loss from both pairs of images."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "28a74c3a-e50e-47c1-9689-4cbea55308e6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "      <iframe id=\"tensorboard-frame-5edf3846e40d550d\" width=\"100%\" height=\"800\" frameborder=\"0\">\n",
       "      </iframe>\n",
       "      <script>\n",
       "        (function() {\n",
       "          const frame = document.getElementById(\"tensorboard-frame-5edf3846e40d550d\");\n",
       "          const url = new URL(\"/\", window.location);\n",
       "          const port = 6006;\n",
       "          if (port) {\n",
       "            url.port = port;\n",
       "          }\n",
       "          frame.src = url;\n",
       "        })();\n",
       "      </script>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#%tensorboard --logdir models\n",
    "\n",
    "logger = SummaryWriter()\n",
    "%tensorboard --logdir runs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "71160755-6f76-42e1-9d36-c70fca812139",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/100 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([8, 12])\n",
      "torch.Size([8, 12])\n",
      "torch.Size([8, 12])\n",
      "torch.Size([8, 12])\n",
      "torch.Size([8, 12])\n",
      "torch.Size([8, 12])\n",
      "torch.Size([8, 12])\n",
      "torch.Size([8, 12])\n",
      "epoch 0, total_loss = 25.322317123413086, positive_loss=3.0853044986724854, negative_loss=22.23701286315918\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  1%|          | 1/100 [00:53<1:27:33, 53.07s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([8, 12])\n",
      "torch.Size([8, 12])\n",
      "torch.Size([8, 12])\n",
      "torch.Size([8, 12])\n",
      "torch.Size([8, 12])\n",
      "torch.Size([8, 12])\n",
      "torch.Size([8, 12])\n",
      "torch.Size([8, 12])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  2%|▏         | 2/100 [01:31<1:12:14, 44.23s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 1, total_loss = 23.363521575927734, positive_loss=1.536923885345459, negative_loss=21.826597213745117\n",
      "torch.Size([8, 12])\n",
      "torch.Size([8, 12])\n",
      "torch.Size([8, 12])\n",
      "torch.Size([8, 12])\n",
      "torch.Size([8, 12])\n",
      "torch.Size([8, 12])\n",
      "torch.Size([8, 12])\n",
      "torch.Size([8, 12])\n",
      "epoch 2, total_loss = 20.607154846191406, positive_loss=3.756053924560547, negative_loss=16.85110092163086\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  3%|▎         | 3/100 [02:13<1:10:22, 43.53s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([8, 12])\n",
      "torch.Size([8, 12])\n",
      "torch.Size([8, 12])\n",
      "torch.Size([8, 12])\n",
      "torch.Size([8, 12])\n",
      "torch.Size([8, 12])\n",
      "torch.Size([8, 12])\n",
      "torch.Size([8, 12])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  4%|▍         | 4/100 [02:53<1:07:10, 41.98s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 3, total_loss = 19.341991424560547, positive_loss=6.272160053253174, negative_loss=13.069833755493164\n",
      "torch.Size([8, 12])\n",
      "torch.Size([8, 12])\n",
      "torch.Size([8, 12])\n",
      "torch.Size([8, 12])\n",
      "torch.Size([8, 12])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  4%|▍         | 4/100 [03:24<1:21:53, 51.19s/it]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Input \u001b[0;32mIn [18]\u001b[0m, in \u001b[0;36m<cell line: 114>\u001b[0;34m()\u001b[0m\n\u001b[1;32m    110\u001b[0m                 torch\u001b[38;5;241m.\u001b[39msave(model\u001b[38;5;241m.\u001b[39mstate_dict(), saveP)\n\u001b[1;32m    112\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m model\n\u001b[0;32m--> 114\u001b[0m model \u001b[38;5;241m=\u001b[39m \u001b[43mtrain\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtb_logger\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mlogger\u001b[49m\u001b[43m)\u001b[49m\n",
      "Input \u001b[0;32mIn [18]\u001b[0m, in \u001b[0;36mtrain\u001b[0;34m(tb_logger, log_image_interval)\u001b[0m\n\u001b[1;32m     17\u001b[0m unpaired \u001b[38;5;241m=\u001b[39m pipeline_unpaired\u001b[38;5;241m.\u001b[39mrequest_batch(request)\n\u001b[1;32m     18\u001b[0m yu \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m \u001b[38;5;66;03m#zero if using contrastive loss, -1 if using cosine similarity\u001b[39;00m\n\u001b[0;32m---> 20\u001b[0m paired \u001b[38;5;241m=\u001b[39m \u001b[43mpipeline_paired\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrequest_batch\u001b[49m\u001b[43m(\u001b[49m\u001b[43mrequest\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     21\u001b[0m yp \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[1;32m     23\u001b[0m unpaired1 \u001b[38;5;241m=\u001b[39m unpaired[raw]\u001b[38;5;241m.\u001b[39mdata\n",
      "File \u001b[0;32m~/miniconda3/envs/celltracking/lib/python3.9/site-packages/gunpowder/pipeline.py:140\u001b[0m, in \u001b[0;36mPipeline.request_batch\u001b[0;34m(self, request)\u001b[0m\n\u001b[1;32m    137\u001b[0m \u001b[38;5;124;03m'''Request a batch from the pipeline.'''\u001b[39;00m\n\u001b[1;32m    139\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 140\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moutput\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrequest_batch\u001b[49m\u001b[43m(\u001b[49m\u001b[43mrequest\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    141\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m    142\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m PipelineRequestError(\u001b[38;5;28mself\u001b[39m, request) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01me\u001b[39;00m\n",
      "File \u001b[0;32m~/miniconda3/envs/celltracking/lib/python3.9/site-packages/gunpowder/nodes/batch_provider.py:187\u001b[0m, in \u001b[0;36mBatchProvider.request_batch\u001b[0;34m(self, request)\u001b[0m\n\u001b[1;32m    185\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mremove_placeholders:\n\u001b[1;32m    186\u001b[0m     upstream_request\u001b[38;5;241m.\u001b[39mremove_placeholders()\n\u001b[0;32m--> 187\u001b[0m batch \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mprovide\u001b[49m\u001b[43m(\u001b[49m\u001b[43mupstream_request\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    189\u001b[0m request\u001b[38;5;241m.\u001b[39mremove_placeholders()\n\u001b[1;32m    191\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcheck_batch_consistency(batch, request)\n",
      "File \u001b[0;32m~/miniconda3/envs/celltracking/lib/python3.9/site-packages/gunpowder/nodes/stack.py:28\u001b[0m, in \u001b[0;36mStack.provide\u001b[0;34m(self, request)\u001b[0m\n\u001b[1;32m     26\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mprovide\u001b[39m(\u001b[38;5;28mself\u001b[39m, request):\n\u001b[0;32m---> 28\u001b[0m     batches \u001b[38;5;241m=\u001b[39m [\n\u001b[1;32m     29\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mget_upstream_provider()\u001b[38;5;241m.\u001b[39mrequest_batch(request)\n\u001b[1;32m     30\u001b[0m         \u001b[38;5;28;01mfor\u001b[39;00m _ \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnum_repetitions)\n\u001b[1;32m     31\u001b[0m     ]\n\u001b[1;32m     33\u001b[0m     timing \u001b[38;5;241m=\u001b[39m Timing(\u001b[38;5;28mself\u001b[39m)\n\u001b[1;32m     34\u001b[0m     timing\u001b[38;5;241m.\u001b[39mstart()\n",
      "File \u001b[0;32m~/miniconda3/envs/celltracking/lib/python3.9/site-packages/gunpowder/nodes/stack.py:29\u001b[0m, in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m     26\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mprovide\u001b[39m(\u001b[38;5;28mself\u001b[39m, request):\n\u001b[1;32m     28\u001b[0m     batches \u001b[38;5;241m=\u001b[39m [\n\u001b[0;32m---> 29\u001b[0m         \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_upstream_provider\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrequest_batch\u001b[49m\u001b[43m(\u001b[49m\u001b[43mrequest\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     30\u001b[0m         \u001b[38;5;28;01mfor\u001b[39;00m _ \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnum_repetitions)\n\u001b[1;32m     31\u001b[0m     ]\n\u001b[1;32m     33\u001b[0m     timing \u001b[38;5;241m=\u001b[39m Timing(\u001b[38;5;28mself\u001b[39m)\n\u001b[1;32m     34\u001b[0m     timing\u001b[38;5;241m.\u001b[39mstart()\n",
      "File \u001b[0;32m~/miniconda3/envs/celltracking/lib/python3.9/site-packages/gunpowder/nodes/batch_provider.py:187\u001b[0m, in \u001b[0;36mBatchProvider.request_batch\u001b[0;34m(self, request)\u001b[0m\n\u001b[1;32m    185\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mremove_placeholders:\n\u001b[1;32m    186\u001b[0m     upstream_request\u001b[38;5;241m.\u001b[39mremove_placeholders()\n\u001b[0;32m--> 187\u001b[0m batch \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mprovide\u001b[49m\u001b[43m(\u001b[49m\u001b[43mupstream_request\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    189\u001b[0m request\u001b[38;5;241m.\u001b[39mremove_placeholders()\n\u001b[1;32m    191\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcheck_batch_consistency(batch, request)\n",
      "File \u001b[0;32m~/miniconda3/envs/celltracking/lib/python3.9/site-packages/gunpowder/nodes/precache.py:117\u001b[0m, in \u001b[0;36mPreCache.provide\u001b[0;34m(self, request)\u001b[0m\n\u001b[1;32m    115\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    116\u001b[0m     logger\u001b[38;5;241m.\u001b[39mdebug(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mgetting batch from queue...\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m--> 117\u001b[0m     batch \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mworkers\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    119\u001b[0m     timing\u001b[38;5;241m.\u001b[39mstop()\n\u001b[1;32m    120\u001b[0m     batch\u001b[38;5;241m.\u001b[39mprofiling_stats\u001b[38;5;241m.\u001b[39madd(timing)\n",
      "File \u001b[0;32m~/miniconda3/envs/celltracking/lib/python3.9/site-packages/gunpowder/producer_pool.py:64\u001b[0m, in \u001b[0;36mProducerPool.get\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m     61\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m item \u001b[38;5;241m==\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m     63\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m---> 64\u001b[0m         item \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m__result_queue\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtimeout\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtimeout\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     65\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m Queue\u001b[38;5;241m.\u001b[39mEmpty:\n\u001b[1;32m     66\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m block:\n",
      "File \u001b[0;32m~/miniconda3/envs/celltracking/lib/python3.9/multiprocessing/queues.py:113\u001b[0m, in \u001b[0;36mQueue.get\u001b[0;34m(self, block, timeout)\u001b[0m\n\u001b[1;32m    111\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m block:\n\u001b[1;32m    112\u001b[0m     timeout \u001b[38;5;241m=\u001b[39m deadline \u001b[38;5;241m-\u001b[39m time\u001b[38;5;241m.\u001b[39mmonotonic()\n\u001b[0;32m--> 113\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_poll\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m)\u001b[49m:\n\u001b[1;32m    114\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m Empty\n\u001b[1;32m    115\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_poll():\n",
      "File \u001b[0;32m~/miniconda3/envs/celltracking/lib/python3.9/multiprocessing/connection.py:262\u001b[0m, in \u001b[0;36m_ConnectionBase.poll\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    260\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_check_closed()\n\u001b[1;32m    261\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_check_readable()\n\u001b[0;32m--> 262\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_poll\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/envs/celltracking/lib/python3.9/multiprocessing/connection.py:429\u001b[0m, in \u001b[0;36mConnection._poll\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    428\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_poll\u001b[39m(\u001b[38;5;28mself\u001b[39m, timeout):\n\u001b[0;32m--> 429\u001b[0m     r \u001b[38;5;241m=\u001b[39m \u001b[43mwait\u001b[49m\u001b[43m(\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    430\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mbool\u001b[39m(r)\n",
      "File \u001b[0;32m~/miniconda3/envs/celltracking/lib/python3.9/multiprocessing/connection.py:936\u001b[0m, in \u001b[0;36mwait\u001b[0;34m(object_list, timeout)\u001b[0m\n\u001b[1;32m    933\u001b[0m     deadline \u001b[38;5;241m=\u001b[39m time\u001b[38;5;241m.\u001b[39mmonotonic() \u001b[38;5;241m+\u001b[39m timeout\n\u001b[1;32m    935\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m:\n\u001b[0;32m--> 936\u001b[0m     ready \u001b[38;5;241m=\u001b[39m \u001b[43mselector\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mselect\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    937\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m ready:\n\u001b[1;32m    938\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m [key\u001b[38;5;241m.\u001b[39mfileobj \u001b[38;5;28;01mfor\u001b[39;00m (key, events) \u001b[38;5;129;01min\u001b[39;00m ready]\n",
      "File \u001b[0;32m~/miniconda3/envs/celltracking/lib/python3.9/selectors.py:416\u001b[0m, in \u001b[0;36m_PollLikeSelector.select\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    414\u001b[0m ready \u001b[38;5;241m=\u001b[39m []\n\u001b[1;32m    415\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 416\u001b[0m     fd_event_list \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_selector\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpoll\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    417\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mInterruptedError\u001b[39;00m:\n\u001b[1;32m    418\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m ready\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "from tqdm import tqdm\n",
    "\n",
    "def train(tb_logger = None, log_image_interval = 10):\n",
    "    if torch.cuda.is_available():\n",
    "        device = torch.device(\"cuda\")\n",
    "    else:\n",
    "        device = torch.device(\"cpu\")\n",
    "        \n",
    "    loss=[] \n",
    "    counter=[]\n",
    "    with gp.build(pipeline_paired), gp.build(pipeline_unpaired):\n",
    "        for epoch in tqdm(range(epochs)):\n",
    "            epoch_loss = 0\n",
    "            epoch_loss_pos = 0\n",
    "            epoch_loss_neg = 0\n",
    "            for x in range(8):\n",
    "                unpaired = pipeline_unpaired.request_batch(request)\n",
    "                yu = -1 #zero if using contrastive loss, -1 if using cosine similarity\n",
    "                \n",
    "                paired = pipeline_paired.request_batch(request)\n",
    "                yp = 1\n",
    "                \n",
    "                unpaired1 = unpaired[raw].data\n",
    "                unpaired2 = unpaired[raw_shift].data\n",
    "                paired1 = paired[raw].data\n",
    "                paired2 = paired[raw_shift].data\n",
    "                \n",
    "                unpaired1 = np.reshape(unpaired1, (batch_size,64, 64, 5))\n",
    "                unpaired2 = np.reshape(unpaired2, (batch_size,64, 64, 5))\n",
    "                paired1 = np.reshape(paired1, (batch_size,64, 64, 5))\n",
    "                paired2 = np.reshape(paired2, (batch_size,64, 64, 5))\n",
    "                \n",
    "                # unpaired1 = np.reshape(unpaired1, (batch_size,16, 16, 5))\n",
    "                # unpaired2 = np.reshape(unpaired2, (batch_size,16, 16, 5))\n",
    "                # paired1 = np.reshape(paired1, (batch_size,16, 16, 5))\n",
    "                # paired2 = np.reshape(paired2, (batch_size,16, 16, 5))\n",
    "                \n",
    "                unpaired1 = np.expand_dims(unpaired1, axis =1)\n",
    "                unpaired2 = np.expand_dims(unpaired2, axis=1)\n",
    "                paired1 = np.expand_dims(paired1, axis =1)\n",
    "                paired2 = np.expand_dims(paired2, axis=1)\n",
    "\n",
    "                unpaired1 = torch.from_numpy(unpaired1).to(device).float()\n",
    "                unpaired2 = torch.from_numpy(unpaired2).to(device).float()\n",
    "                yu = torch.from_numpy(np.array([yu])).to(device).float()\n",
    "                \n",
    "                paired1 = torch.from_numpy(paired1).to(device).float()\n",
    "                paired2 = torch.from_numpy(paired2).to(device).float() \n",
    "                yp = torch.from_numpy(np.array([yp])).to(device).float()\n",
    "\n",
    "                optimizer.zero_grad()\n",
    "                \n",
    "                predp1 = model(paired1)\n",
    "                predp2 = model(paired2)\n",
    "                predu1 = model(unpaired1)\n",
    "                predu2 = model(unpaired2)\n",
    "                #print(model(unpaired1).shape)\n",
    "                #print(predp1.shape)\n",
    "\n",
    "                #loss = loss_function(pred, y)\n",
    "                \n",
    "                print(predp1.shape)\n",
    "\n",
    "                loss_contrastivep = loss_function(predp1,predp2,yp)\n",
    "                loss_contrastiveu = loss_function(predu1,predu2,yu)\n",
    "\n",
    "                loss_contrastivep.backward()\n",
    "                loss_contrastiveu.backward()\n",
    "                optimizer.step()    \n",
    "                epoch_loss_pos += loss_contrastivep\n",
    "                epoch_loss_neg += loss_contrastiveu\n",
    "                epoch_loss += loss_contrastivep + loss_contrastiveu\n",
    "                \n",
    "                \n",
    "                \n",
    "                if tb_logger is not None:\n",
    "                    step = epoch * 10 + x\n",
    "                    tb_logger.add_scalar(\n",
    "                        tag=\"positive_loss\", scalar_value=epoch_loss_pos.item(), global_step=step\n",
    "                    )\n",
    "                    tb_logger.add_scalar(\n",
    "                        tag=\"negative_loss\", scalar_value=epoch_loss_neg.item(), global_step=step\n",
    "                    )\n",
    "                    tb_logger.add_scalar(\n",
    "                        tag=\"total_loss\", scalar_value=epoch_loss.item(), global_step = step\n",
    "                    )\n",
    "                    # check if we log images in this iteration\n",
    "                    # if step % log_image_interval == 0:\n",
    "                    #     tb_logger.add_images(\n",
    "                    #         tag=\"in_unpaired1\", img_tensor=unpaired1.to(\"cpu\"), global_step=step\n",
    "                    #     )\n",
    "                    #     tb_logger.add_images(\n",
    "                    #         tag=\"in_unpaired2\", img_tensor=unpaired2.to(\"cpu\"), global_step=step\n",
    "                    #     )\n",
    "                    #     tb_logger.add_images(\n",
    "                    #         tag=\"in_paired1\", img_tensor=paired1.to(\"cpu\"), global_step=step\n",
    "                    #     )\n",
    "                    #     tb_logger.add_images(\n",
    "                    #         tag=\"in_paired2\", img_tensor=paired2.to(\"cpu\"), global_step=step\n",
    "                    #     )\n",
    "\n",
    "\n",
    "            print(f\"epoch {epoch}, total_loss = {epoch_loss}, positive_loss={epoch_loss_pos}, negative_loss={epoch_loss_neg}\")\n",
    "            \n",
    "            if(epoch % 10 == 0):\n",
    "                baseP = '/mnt/shared/celltracking/modelstates/'\n",
    "                machine = 'aaron'\n",
    "                e = epoch ### replace\n",
    "                saveP = (baseP+'/'+machine+'/'+str(f'epoch_{e}'))\n",
    "                torch.save(model.state_dict(), saveP)\n",
    "\n",
    "    return model\n",
    "\n",
    "model = train(tb_logger = logger)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4bad3724-0af7-4a27-94c5-b25d542a50ee",
   "metadata": {},
   "source": [
    "# Tracking / Linear Assignment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25131276-e24d-48bd-99eb-bc3585b94fe6",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
