{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "96fa3a08-111f-4d26-8e65-7be9ba004054",
   "metadata": {},
   "source": [
    "# Model Implementation for 3D Cell Tracking\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "15fd6961-5904-42c4-9fd7-190c0685c312",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting tensorboard\n",
      "  Using cached tensorboard-2.10.0-py3-none-any.whl (5.9 MB)\n",
      "Collecting absl-py>=0.4\n",
      "  Using cached absl_py-1.2.0-py3-none-any.whl (123 kB)\n",
      "Collecting markdown>=2.6.8\n",
      "  Using cached Markdown-3.4.1-py3-none-any.whl (93 kB)\n",
      "Collecting google-auth-oauthlib<0.5,>=0.4.1\n",
      "  Using cached google_auth_oauthlib-0.4.6-py2.py3-none-any.whl (18 kB)\n",
      "Collecting tensorboard-plugin-wit>=1.6.0\n",
      "  Using cached tensorboard_plugin_wit-1.8.1-py3-none-any.whl (781 kB)\n",
      "Requirement already satisfied: numpy>=1.12.0 in /home/bourquea/miniconda3/envs/celltracking/lib/python3.9/site-packages (from tensorboard) (1.23.2)\n",
      "Collecting protobuf<3.20,>=3.9.2\n",
      "  Using cached protobuf-3.19.4-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.1 MB)\n",
      "Collecting tensorboard-data-server<0.7.0,>=0.6.0\n",
      "  Using cached tensorboard_data_server-0.6.1-py3-none-manylinux2010_x86_64.whl (4.9 MB)\n",
      "Collecting werkzeug>=1.0.1\n",
      "  Using cached Werkzeug-2.2.2-py3-none-any.whl (232 kB)\n",
      "Requirement already satisfied: requests<3,>=2.21.0 in /home/bourquea/miniconda3/envs/celltracking/lib/python3.9/site-packages (from tensorboard) (2.28.1)\n",
      "Requirement already satisfied: setuptools>=41.0.0 in /home/bourquea/miniconda3/envs/celltracking/lib/python3.9/site-packages (from tensorboard) (63.4.1)\n",
      "Requirement already satisfied: wheel>=0.26 in /home/bourquea/miniconda3/envs/celltracking/lib/python3.9/site-packages (from tensorboard) (0.37.1)\n",
      "Collecting google-auth<3,>=1.6.3\n",
      "  Using cached google_auth-2.11.0-py2.py3-none-any.whl (167 kB)\n",
      "Collecting grpcio>=1.24.3\n",
      "  Downloading grpcio-1.48.1-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (4.6 MB)\n",
      "\u001b[2K     \u001b[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m4.6/4.6 MB\u001b[0m \u001b[31m38.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0mm eta \u001b[36m0:00:01\u001b[0m0:01\u001b[0m\n",
      "\u001b[?25hCollecting rsa<5,>=3.1.4\n",
      "  Using cached rsa-4.9-py3-none-any.whl (34 kB)\n",
      "Requirement already satisfied: six>=1.9.0 in /home/bourquea/miniconda3/envs/celltracking/lib/python3.9/site-packages (from google-auth<3,>=1.6.3->tensorboard) (1.16.0)\n",
      "Collecting pyasn1-modules>=0.2.1\n",
      "  Using cached pyasn1_modules-0.2.8-py2.py3-none-any.whl (155 kB)\n",
      "Collecting cachetools<6.0,>=2.0.0\n",
      "  Using cached cachetools-5.2.0-py3-none-any.whl (9.3 kB)\n",
      "Collecting requests-oauthlib>=0.7.0\n",
      "  Using cached requests_oauthlib-1.3.1-py2.py3-none-any.whl (23 kB)\n",
      "Requirement already satisfied: importlib-metadata>=4.4 in /home/bourquea/miniconda3/envs/celltracking/lib/python3.9/site-packages (from markdown>=2.6.8->tensorboard) (4.11.4)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /home/bourquea/miniconda3/envs/celltracking/lib/python3.9/site-packages (from requests<3,>=2.21.0->tensorboard) (2022.6.15)\n",
      "Requirement already satisfied: charset-normalizer<3,>=2 in /home/bourquea/miniconda3/envs/celltracking/lib/python3.9/site-packages (from requests<3,>=2.21.0->tensorboard) (2.1.1)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /home/bourquea/miniconda3/envs/celltracking/lib/python3.9/site-packages (from requests<3,>=2.21.0->tensorboard) (1.26.11)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /home/bourquea/miniconda3/envs/celltracking/lib/python3.9/site-packages (from requests<3,>=2.21.0->tensorboard) (3.3)\n",
      "Requirement already satisfied: MarkupSafe>=2.1.1 in /home/bourquea/miniconda3/envs/celltracking/lib/python3.9/site-packages (from werkzeug>=1.0.1->tensorboard) (2.1.1)\n",
      "Requirement already satisfied: zipp>=0.5 in /home/bourquea/miniconda3/envs/celltracking/lib/python3.9/site-packages (from importlib-metadata>=4.4->markdown>=2.6.8->tensorboard) (3.8.1)\n",
      "Collecting pyasn1<0.5.0,>=0.4.6\n",
      "  Using cached pyasn1-0.4.8-py2.py3-none-any.whl (77 kB)\n",
      "Collecting oauthlib>=3.0.0\n",
      "  Using cached oauthlib-3.2.0-py3-none-any.whl (151 kB)\n",
      "Installing collected packages: tensorboard-plugin-wit, pyasn1, werkzeug, tensorboard-data-server, rsa, pyasn1-modules, protobuf, oauthlib, grpcio, cachetools, absl-py, requests-oauthlib, markdown, google-auth, google-auth-oauthlib, tensorboard\n",
      "Successfully installed absl-py-1.2.0 cachetools-5.2.0 google-auth-2.11.0 google-auth-oauthlib-0.4.6 grpcio-1.48.1 markdown-3.4.1 oauthlib-3.2.0 protobuf-3.19.4 pyasn1-0.4.8 pyasn1-modules-0.2.8 requests-oauthlib-1.3.1 rsa-4.9 tensorboard-2.10.0 tensorboard-data-server-0.6.1 tensorboard-plugin-wit-1.8.1 werkzeug-2.2.2\n"
     ]
    }
   ],
   "source": [
    "# !pip install torchsummary \n",
    "# !pip install gunpowder\n",
    "# !pip install zarr\n",
    "# !pip install matplotlib\n",
    "#!pip install tensorboard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "2503c9e5-eea9-4751-9600-fd8c537aecea",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The tensorboard extension is already loaded. To reload it, use:\n",
      "  %reload_ext tensorboard\n"
     ]
    }
   ],
   "source": [
    "from torch.utils.data import DataLoader, random_split\n",
    "from torch.utils.data.sampler import WeightedRandomSampler\n",
    "from torchvision.datasets import ImageFolder\n",
    "from torchvision import transforms\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import numpy as np\n",
    "import random \n",
    "import matplotlib.pyplot as plt\n",
    "from torchvision import models\n",
    "from torchsummary import summary\n",
    "\n",
    "from torchvision import datasets\n",
    "from torchvision import transforms\n",
    "from torch.utils.data.sampler import SubsetRandomSampler\n",
    "import gunpowder as gp\n",
    "import zarr\n",
    "import math\n",
    "#%load_ext tensorboard\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "\n",
    "# Device configuration\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "835c90df-e975-4373-9a30-ff0977d23544",
   "metadata": {},
   "source": [
    "# Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "ead44e01-a035-424e-84e3-3d2968cf0132",
   "metadata": {},
   "outputs": [],
   "source": [
    "# provide path to zarr directory\n",
    "zarrdir = '/mnt/shared/celltracking/data/cho/01.zarr'\n",
    "\n",
    "data = zarr.open(zarrdir)\n",
    "loader = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "31f1af22-baa3-4eba-ae20-c9c752d661d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# provide path to zarr directory\n",
    "#zarrdir = '/mnt/shared/celltracking/data/cho/01.zarr'\n",
    "\n",
    "# pre-selected volumes from cho dataset\n",
    "coord_paired = ((0,0,80, 175),(1,0,80, 180))\n",
    "coord_unpaired = ((0,0,80, 175),(1,0,92, 232))\n",
    "\n",
    "# specify subvolume size and volume source\n",
    "volSize = (1,5,64, 64)\n",
    "coord = coord_paired[0]\n",
    "\n",
    "# declare arrays to use in the pipeline\n",
    "key ='raw'\n",
    "raw = gp.ArrayKey(key)\n",
    "\n",
    "# create \"pipeline\" consisting only of a data source\n",
    "source = gp.ZarrSource(\n",
    "    zarrdir,  # the zarr container\n",
    "    {raw: key},  # which dataset to associate to the array key\n",
    "    {raw: gp.ArraySpec(interpolatable=True, voxel_size = (1,1,1,1))}  # meta-information\n",
    ")\n",
    "pipeline = source\n",
    "\n",
    "# specify request paired\n",
    "request_vol1p = gp.BatchRequest()\n",
    "request_vol2p = gp.BatchRequest()\n",
    "request_vol1p[raw] = gp.Roi(coord_paired[0], volSize)\n",
    "request_vol2p[raw] = gp.Roi(coord_paired[1], volSize)\n",
    "\n",
    "# specify request unpaired\n",
    "request_vol1u = gp.BatchRequest()\n",
    "request_vol2u = gp.BatchRequest()\n",
    "request_vol1u[raw] = gp.Roi(coord_unpaired[0], volSize)\n",
    "request_vol2u[raw] = gp.Roi(coord_unpaired[1], volSize)\n",
    "\n",
    "# build the pipeline\n",
    "with gp.build(pipeline):\n",
    "    batch_vol1p = pipeline.request_batch(request_vol1p)\n",
    "    batch_vol2p = pipeline.request_batch(request_vol2p)\n",
    "    batch_vol1u = pipeline.request_batch(request_vol1u)\n",
    "    batch_vol2u = pipeline.request_batch(request_vol2u)\n",
    "    \n",
    "# # specify request \n",
    "# request_vol1 = gp.BatchRequest()\n",
    "# request_vol2 = gp.BatchRequest()\n",
    "# request_vol1[raw] = gp.Roi(coord_paired[0], volSize)\n",
    "# request_vol2[raw] = gp.Roi(coord_paired[1], volSize)\n",
    "\n",
    "# # build the pipeline\n",
    "# with gp.build(pipeline):\n",
    "#     batch_vol1 = pipeline.request_batch(request_vol1)\n",
    "#     batch_vol2 = pipeline.request_batch(request_vol2)\n",
    "    \n",
    "# show the content of the batch\n",
    "#print(f\"batch returned: {batch_vol1}\")\n",
    "\n",
    "# plot first slice of volume\n",
    "\n",
    "# fig, (ax1, ax2) = plt.subplots(1, 2)\n",
    "# ax1.imshow(np.flipud(batch_vol1[raw].data[0,1,:,:]))\n",
    "# ax2.imshow(np.flipud(batch_vol2[raw].data[0,1,:,:]))\n",
    "\n",
    "# load volume into napari\n",
    "# viewer = napari.Viewer()\n",
    "# viewer.add_image(batch[raw].data, name=\"volume 1\");"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "a76bc986-256e-40f2-a255-6d10055e906e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1, 3)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vol1 = batch_vol1p[raw].data\n",
    "vol2 = batch_vol2p[raw].data\n",
    "\n",
    "vol1 = np.reshape(vol1, (1,64, 64, 5))\n",
    "vol2 = np.reshape(vol2, (1,64, 64, 5))\n",
    "y = 1\n",
    "\n",
    "vol1 = np.expand_dims(vol1, axis =0)\n",
    "vol2 = np.expand_dims(vol2, axis=0)\n",
    "\n",
    "loader.append((vol1, vol2, y))\n",
    "np.shape(loader)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b322f3f-106a-484b-a790-bee3da998c0d",
   "metadata": {},
   "source": [
    "# Augmentations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "286b229d-0e67-4fce-b2df-509b31132f0d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Augmentations=\n",
    "\n",
    "# chose a random source (i.e., sample) from the above\n",
    "#random_location = gp.RandomLocation()\n",
    "\n",
    "# elastically deform the batch\n",
    "Elastic_augment=gp.ElasticAugment(\n",
    "    [2,10,10],\n",
    "    [0,2,2],\n",
    "    [0,0*math.pi/2.0],\n",
    "    prob_slip=0.05,\n",
    "    prob_shift=0.05,\n",
    "    max_misalign=25)\n",
    "\n",
    "# apply transpose and mirror augmentations\n",
    "# Simple_augment=gp.SimpleAugment(transpose_only=[2, 3], mirror_only=[]) \n",
    "Simple_augment=gp.SimpleAugment(transpose_only=[], mirror_only=[])\n",
    "\n",
    "# scale and shift the intensity of the raw array\n",
    "Intensity_augment=gp.IntensityAugment(\n",
    "    raw,\n",
    "    scale_min=0.9,\n",
    "    scale_max=1.1,\n",
    "    shift_min=-0.1,\n",
    "    shift_max=0.1,\n",
    "    )\n",
    "\n",
    "Noise_augment = gp.NoiseAugment(raw, mode=\"gaussian\")\n",
    "\n",
    "pipeline = (\n",
    "    source + gp.Normalize(raw)+\n",
    "            Intensity_augment+Elastic_augment + Simple_augment + Noise_augment\n",
    "           )\n",
    "\n",
    "# build the pipeline\n",
    "with gp.build(pipeline):\n",
    "    for x in range(10):\n",
    "        batch_vol1p = pipeline.request_batch(request_vol1p)\n",
    "        batch_vol2p = pipeline.request_batch(request_vol2p)\n",
    "        batch_vol1u = pipeline.request_batch(request_vol1u)\n",
    "        batch_vol2u = pipeline.request_batch(request_vol2u)\n",
    "        # show the content of the batch\n",
    "        #print(f\"batch returned: {batch}\")\n",
    "\n",
    "        # plot first slice of volume\n",
    "\n",
    "        # fig, (ax1, ax2) = plt.subplots(1, 2)\n",
    "        # ax1.imshow(np.flipud(batch_vol1p[raw].data[0,1,:,:]))\n",
    "        # ax2.imshow(np.flipud(batch_vol2p[raw].data[0,1,:,:]))\n",
    "        # plt.show()\n",
    "\n",
    "with gp.build(pipeline):\n",
    "    for x in range(10):\n",
    "        batch_vol1p = pipeline.request_batch(request_vol1p)\n",
    "        batch_vol2p = pipeline.request_batch(request_vol2p)\n",
    "        batch_vol1u = pipeline.request_batch(request_vol1u)\n",
    "        batch_vol2u = pipeline.request_batch(request_vol2u)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "54945ec0-4a63-486a-bd16-8d8829fef1a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# specify request \n",
    "#plt.imshow(np.flipud(batch_vol1[raw].data[0,0,:,:]))\n",
    "\n",
    "# request = gp.BatchRequest()\n",
    "# request[raw] = gp.Roi(coord, volSize)\n",
    "\n",
    "# with gp.build(pipeline):\n",
    "#     batch_vol1_aug = pipeline.request_batch(request)\n",
    "#     batch_vol2_aug = pipeline.request_batch(request)\n",
    "\n",
    "# fig, (ax1, ax2, ax3, ax4) = plt.subplots(1, 4)\n",
    "# ax1.imshow(np.flipud(batch_vol1[raw].data[0,0,:,:]))\n",
    "# ax1.set_title('input vol1')\n",
    "# ax2.imshow(np.flipud(batch_vol1_aug[raw].data[0,0,:,:]))\n",
    "# ax2.set_title('aug vol1')\n",
    "# ax3.imshow(np.flipud(batch_vol2[raw].data[0,0,:,:]))\n",
    "# ax3.set_title('input vol2')\n",
    "# ax4.imshow(np.flipud(batch_vol2_aug[raw].data[0,0,:,:]))\n",
    "# ax4.set_title('aug vol2')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0942971b-fa86-49b9-a26b-83d01af3d1ad",
   "metadata": {},
   "source": [
    "Add augmentations to loader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd93d20f-f637-465a-a0d1-f8393fae5402",
   "metadata": {},
   "outputs": [],
   "source": [
    "# vol1 = batch_vol1_aug[raw].data\n",
    "# vol2 = batch_vol2_aug[raw].data\n",
    "\n",
    "# vol1 = np.reshape(vol1, (1,64, 64, 5))\n",
    "# vol2 = np.reshape(vol2, (1,64, 64, 5))\n",
    "# y = 1\n",
    "\n",
    "# vol1 = np.expand_dims(vol1, axis =0)\n",
    "# vol2 = np.expand_dims(vol2, axis=0)\n",
    "\n",
    "# loader.append((vol1, vol2, y))\n",
    "# np.shape(loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "1a2b1964-d84b-42e4-b74f-21412b02fd8f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# loader[2][2]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a77f74b5-d746-4fe4-8661-2f5efcc0e95b",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Define the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "4517e490-95cb-4786-b8d8-52b7a051da79",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Vgg3D(torch.nn.Module):\n",
    "\n",
    "    def __init__(self, input_size, output_classes, downsample_factors, fmaps=12):\n",
    "\n",
    "        super(Vgg3D, self).__init__()\n",
    "\n",
    "        self.input_size = input_size\n",
    "        self.downsample_factors = downsample_factors\n",
    "        self.output_classes = 2\n",
    "\n",
    "        current_fmaps, h, w, d = tuple(input_size)\n",
    "        current_size = (h, w,d)\n",
    "\n",
    "        features = []\n",
    "        for i in range(len(downsample_factors)):\n",
    "\n",
    "            features += [\n",
    "                torch.nn.Conv3d(current_fmaps,fmaps,kernel_size=3,padding=1),\n",
    "                torch.nn.BatchNorm3d(fmaps),\n",
    "                torch.nn.ReLU(inplace=True),\n",
    "                torch.nn.Conv3d(fmaps,fmaps,kernel_size=3,padding=1),\n",
    "                torch.nn.BatchNorm3d(fmaps),\n",
    "                torch.nn.ReLU(inplace=True),\n",
    "                torch.nn.MaxPool3d(downsample_factors[i])\n",
    "            ]\n",
    "\n",
    "            current_fmaps = fmaps\n",
    "            fmaps *= 2\n",
    "\n",
    "            size = tuple(\n",
    "                int(c/d)\n",
    "                for c, d in zip(current_size, downsample_factors[i]))\n",
    "            check = (\n",
    "                s*d == c\n",
    "                for s, d, c in zip(size, downsample_factors[i], current_size))\n",
    "            assert all(check), \\\n",
    "                \"Can not downsample %s by chosen downsample factor\" % \\\n",
    "                (current_size,)\n",
    "            current_size = size\n",
    "\n",
    "        self.features = torch.nn.Sequential(*features)\n",
    "\n",
    "        classifier = [\n",
    "            torch.nn.Linear(current_size[0] *current_size[1]*current_size[2] *current_fmaps,4096),\n",
    "            torch.nn.ReLU(inplace=True),\n",
    "            torch.nn.Dropout(),\n",
    "            torch.nn.Linear(4096,4096),\n",
    "            torch.nn.ReLU(inplace=True),\n",
    "            torch.nn.Dropout(),\n",
    "            torch.nn.Linear(4096,output_classes)\n",
    "        ]\n",
    "\n",
    "        self.classifier = torch.nn.Sequential(*classifier)\n",
    "    \n",
    "    def forward(self, raw):\n",
    "\n",
    "        # add a channel dimension to raw\n",
    "        # shape = tuple(raw.shape)\n",
    "        # raw = raw.reshape(shape[0], 1, shape[1], shape[2])\n",
    "        \n",
    "        # compute features\n",
    "        f = self.features(raw)\n",
    "        f = f.view(f.size(0), -1)\n",
    "        \n",
    "        # classify\n",
    "        y = self.classifier(f)\n",
    "\n",
    "        return y"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "29ff22bf-d49f-42bf-b92d-b110037d97fc",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Loss Functions\n",
    "\n",
    "We'll probably need to test some different loss functions. List some here:\n",
    "Contrastive loss\n",
    "cosine similarity\n",
    "triplet loss\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "7c52a2b5-1749-4209-b022-41a445109799",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ContrastiveLoss(nn.Module):\n",
    "    \"Contrastive loss function\"\n",
    "\n",
    "    def __init__(self, margin=2.0):\n",
    "        super(ContrastiveLoss, self).__init__()\n",
    "        self.margin = margin\n",
    "\n",
    "    def forward(self, output1, output2, label):\n",
    "        euclidean_distance = F.pairwise_distance(output1, output2)\n",
    "        loss_contrastive = torch.mean(\n",
    "            (1 - label) * torch.pow(euclidean_distance, 2)\n",
    "            + (label)\n",
    "            * torch.pow(torch.clamp(self.margin - euclidean_distance, min=0.0), 2)\n",
    "        )\n",
    "\n",
    "        return loss_contrastive"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "9da12ed3-cb32-4e26-809d-8aed7cf9ec28",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------------------------------\n",
      "        Layer (type)               Output Shape         Param #\n",
      "================================================================\n",
      "            Conv3d-1        [-1, 12, 64, 64, 5]             336\n",
      "       BatchNorm3d-2        [-1, 12, 64, 64, 5]              24\n",
      "              ReLU-3        [-1, 12, 64, 64, 5]               0\n",
      "            Conv3d-4        [-1, 12, 64, 64, 5]           3,900\n",
      "       BatchNorm3d-5        [-1, 12, 64, 64, 5]              24\n",
      "              ReLU-6        [-1, 12, 64, 64, 5]               0\n",
      "         MaxPool3d-7        [-1, 12, 32, 32, 5]               0\n",
      "            Conv3d-8        [-1, 24, 32, 32, 5]           7,800\n",
      "       BatchNorm3d-9        [-1, 24, 32, 32, 5]              48\n",
      "             ReLU-10        [-1, 24, 32, 32, 5]               0\n",
      "           Conv3d-11        [-1, 24, 32, 32, 5]          15,576\n",
      "      BatchNorm3d-12        [-1, 24, 32, 32, 5]              48\n",
      "             ReLU-13        [-1, 24, 32, 32, 5]               0\n",
      "        MaxPool3d-14        [-1, 24, 16, 16, 5]               0\n",
      "           Conv3d-15        [-1, 48, 16, 16, 5]          31,152\n",
      "      BatchNorm3d-16        [-1, 48, 16, 16, 5]              96\n",
      "             ReLU-17        [-1, 48, 16, 16, 5]               0\n",
      "           Conv3d-18        [-1, 48, 16, 16, 5]          62,256\n",
      "      BatchNorm3d-19        [-1, 48, 16, 16, 5]              96\n",
      "             ReLU-20        [-1, 48, 16, 16, 5]               0\n",
      "        MaxPool3d-21          [-1, 48, 8, 8, 5]               0\n",
      "           Conv3d-22          [-1, 96, 8, 8, 5]         124,512\n",
      "      BatchNorm3d-23          [-1, 96, 8, 8, 5]             192\n",
      "             ReLU-24          [-1, 96, 8, 8, 5]               0\n",
      "           Conv3d-25          [-1, 96, 8, 8, 5]         248,928\n",
      "      BatchNorm3d-26          [-1, 96, 8, 8, 5]             192\n",
      "             ReLU-27          [-1, 96, 8, 8, 5]               0\n",
      "        MaxPool3d-28          [-1, 96, 4, 4, 5]               0\n",
      "           Linear-29                 [-1, 4096]      31,461,376\n",
      "             ReLU-30                 [-1, 4096]               0\n",
      "          Dropout-31                 [-1, 4096]               0\n",
      "           Linear-32                 [-1, 4096]      16,781,312\n",
      "             ReLU-33                 [-1, 4096]               0\n",
      "          Dropout-34                 [-1, 4096]               0\n",
      "           Linear-35                   [-1, 12]          49,164\n",
      "================================================================\n",
      "Total params: 48,787,032\n",
      "Trainable params: 48,787,032\n",
      "Non-trainable params: 0\n",
      "----------------------------------------------------------------\n",
      "Input size (MB): 0.08\n",
      "Forward/backward pass size (MB): 22.16\n",
      "Params size (MB): 186.11\n",
      "Estimated Total Size (MB): 208.35\n",
      "----------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "input_size = (1, 64, 64, 5)\n",
    "downsample_factors =[(2, 2, 1), (2, 2, 1), (2, 2, 1), (2, 2, 1)];\n",
    "output_classes = 12\n",
    "\n",
    "# create the model to train\n",
    "model = Vgg3D(input_size, output_classes,  downsample_factors = downsample_factors)\n",
    "model = model.to(device)\n",
    "\n",
    "summary(model, input_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "27bbf7d8-1dfb-441b-a523-894c3be93493",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Training length\n",
    "epochs = 2000\n",
    "\n",
    "#loss_function = torch.nn.BCELoss()\n",
    "loss_function = torch.nn.CosineEmbeddingLoss()\n",
    "#loss_function = ContrastiveLoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=1e-4, weight_decay=0.0005)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e03dec6c-14c4-4400-8ff5-d523845d6105",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Training Test"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "79686e15-7006-4f8d-8875-b2f9aa03b396",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Implementing the Siamese Network\n",
    "\n",
    "The above training is just to test if the VGG model works for 3D data. Here, the training will take two pairs of images and calculate the loss from both pairs of images."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "28a74c3a-e50e-47c1-9689-4cbea55308e6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "      <iframe id=\"tensorboard-frame-dce122262ed42843\" width=\"100%\" height=\"800\" frameborder=\"0\">\n",
       "      </iframe>\n",
       "      <script>\n",
       "        (function() {\n",
       "          const frame = document.getElementById(\"tensorboard-frame-dce122262ed42843\");\n",
       "          const url = new URL(\"/\", window.location);\n",
       "          const port = 6006;\n",
       "          if (port) {\n",
       "            url.port = port;\n",
       "          }\n",
       "          frame.src = url;\n",
       "        })();\n",
       "      </script>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#%tensorboard --logdir models\n",
    "\n",
    "logger = SummaryWriter()\n",
    "%tensorboard --logdir runs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "71160755-6f76-42e1-9d36-c70fca812139",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 1/2000 [00:33<18:51:41, 33.97s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 0, total_loss = 7.232059478759766, positive_loss=0.5443277955055237, negative_loss=6.687731742858887\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 2/2000 [01:08<19:08:49, 34.50s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 1, total_loss = 10.415596008300781, positive_loss=4.628561973571777, negative_loss=5.78703498840332\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 3/2000 [01:42<18:56:01, 34.13s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 2, total_loss = 2.9506771564483643, positive_loss=1.1045331954956055, negative_loss=1.8461437225341797\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 4/2000 [02:15<18:42:53, 33.75s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 3, total_loss = 4.185060024261475, positive_loss=1.3474764823913574, negative_loss=2.837583065032959\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 4/2000 [02:16<18:59:02, 34.24s/it]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Input \u001b[0;32mIn [68]\u001b[0m, in \u001b[0;36m<cell line: 100>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     96\u001b[0m             \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mepoch \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mepoch\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m, total_loss = \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mepoch_loss\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m, positive_loss=\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mepoch_loss_pos\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m, negative_loss=\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mepoch_loss_neg\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m     98\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m model\n\u001b[0;32m--> 100\u001b[0m model \u001b[38;5;241m=\u001b[39m \u001b[43mtrain\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtb_logger\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mlogger\u001b[49m\u001b[43m)\u001b[49m\n",
      "Input \u001b[0;32mIn [68]\u001b[0m, in \u001b[0;36mtrain\u001b[0;34m(tb_logger, log_image_interval)\u001b[0m\n\u001b[1;32m     19\u001b[0m yu \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m\n\u001b[1;32m     21\u001b[0m paired1 \u001b[38;5;241m=\u001b[39m pipeline\u001b[38;5;241m.\u001b[39mrequest_batch(request_vol1p)\n\u001b[0;32m---> 22\u001b[0m paired2 \u001b[38;5;241m=\u001b[39m \u001b[43mpipeline\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrequest_batch\u001b[49m\u001b[43m(\u001b[49m\u001b[43mrequest_vol2p\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     23\u001b[0m yp \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[1;32m     25\u001b[0m unpaired1 \u001b[38;5;241m=\u001b[39m unpaired1[raw]\u001b[38;5;241m.\u001b[39mdata[:,:,:,:]\n",
      "File \u001b[0;32m~/miniconda3/envs/celltracking/lib/python3.9/site-packages/gunpowder/pipeline.py:140\u001b[0m, in \u001b[0;36mPipeline.request_batch\u001b[0;34m(self, request)\u001b[0m\n\u001b[1;32m    137\u001b[0m \u001b[38;5;124;03m'''Request a batch from the pipeline.'''\u001b[39;00m\n\u001b[1;32m    139\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 140\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moutput\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrequest_batch\u001b[49m\u001b[43m(\u001b[49m\u001b[43mrequest\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    141\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m    142\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m PipelineRequestError(\u001b[38;5;28mself\u001b[39m, request) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01me\u001b[39;00m\n",
      "File \u001b[0;32m~/miniconda3/envs/celltracking/lib/python3.9/site-packages/gunpowder/nodes/batch_provider.py:187\u001b[0m, in \u001b[0;36mBatchProvider.request_batch\u001b[0;34m(self, request)\u001b[0m\n\u001b[1;32m    185\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mremove_placeholders:\n\u001b[1;32m    186\u001b[0m     upstream_request\u001b[38;5;241m.\u001b[39mremove_placeholders()\n\u001b[0;32m--> 187\u001b[0m batch \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mprovide\u001b[49m\u001b[43m(\u001b[49m\u001b[43mupstream_request\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    189\u001b[0m request\u001b[38;5;241m.\u001b[39mremove_placeholders()\n\u001b[1;32m    191\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcheck_batch_consistency(batch, request)\n",
      "File \u001b[0;32m~/miniconda3/envs/celltracking/lib/python3.9/site-packages/gunpowder/nodes/batch_filter.py:170\u001b[0m, in \u001b[0;36mBatchFilter.provide\u001b[0;34m(self, request)\u001b[0m\n\u001b[1;32m    166\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mremove_provided(upstream_request)\n\u001b[1;32m    168\u001b[0m timing_prepare\u001b[38;5;241m.\u001b[39mstop()\n\u001b[0;32m--> 170\u001b[0m batch \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_upstream_provider\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrequest_batch\u001b[49m\u001b[43m(\u001b[49m\u001b[43mupstream_request\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    172\u001b[0m timing_process \u001b[38;5;241m=\u001b[39m Timing(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mprocess\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    173\u001b[0m timing_process\u001b[38;5;241m.\u001b[39mstart()\n",
      "File \u001b[0;32m~/miniconda3/envs/celltracking/lib/python3.9/site-packages/gunpowder/nodes/batch_provider.py:187\u001b[0m, in \u001b[0;36mBatchProvider.request_batch\u001b[0;34m(self, request)\u001b[0m\n\u001b[1;32m    185\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mremove_placeholders:\n\u001b[1;32m    186\u001b[0m     upstream_request\u001b[38;5;241m.\u001b[39mremove_placeholders()\n\u001b[0;32m--> 187\u001b[0m batch \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mprovide\u001b[49m\u001b[43m(\u001b[49m\u001b[43mupstream_request\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    189\u001b[0m request\u001b[38;5;241m.\u001b[39mremove_placeholders()\n\u001b[1;32m    191\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcheck_batch_consistency(batch, request)\n",
      "File \u001b[0;32m~/miniconda3/envs/celltracking/lib/python3.9/site-packages/gunpowder/nodes/batch_filter.py:170\u001b[0m, in \u001b[0;36mBatchFilter.provide\u001b[0;34m(self, request)\u001b[0m\n\u001b[1;32m    166\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mremove_provided(upstream_request)\n\u001b[1;32m    168\u001b[0m timing_prepare\u001b[38;5;241m.\u001b[39mstop()\n\u001b[0;32m--> 170\u001b[0m batch \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_upstream_provider\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrequest_batch\u001b[49m\u001b[43m(\u001b[49m\u001b[43mupstream_request\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    172\u001b[0m timing_process \u001b[38;5;241m=\u001b[39m Timing(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mprocess\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    173\u001b[0m timing_process\u001b[38;5;241m.\u001b[39mstart()\n",
      "File \u001b[0;32m~/miniconda3/envs/celltracking/lib/python3.9/site-packages/gunpowder/nodes/batch_provider.py:187\u001b[0m, in \u001b[0;36mBatchProvider.request_batch\u001b[0;34m(self, request)\u001b[0m\n\u001b[1;32m    185\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mremove_placeholders:\n\u001b[1;32m    186\u001b[0m     upstream_request\u001b[38;5;241m.\u001b[39mremove_placeholders()\n\u001b[0;32m--> 187\u001b[0m batch \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mprovide\u001b[49m\u001b[43m(\u001b[49m\u001b[43mupstream_request\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    189\u001b[0m request\u001b[38;5;241m.\u001b[39mremove_placeholders()\n\u001b[1;32m    191\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcheck_batch_consistency(batch, request)\n",
      "File \u001b[0;32m~/miniconda3/envs/celltracking/lib/python3.9/site-packages/gunpowder/nodes/batch_filter.py:152\u001b[0m, in \u001b[0;36mBatchFilter.provide\u001b[0;34m(self, request)\u001b[0m\n\u001b[1;32m    149\u001b[0m downstream_request \u001b[38;5;241m=\u001b[39m request\u001b[38;5;241m.\u001b[39mcopy()\n\u001b[1;32m    151\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m skip:\n\u001b[0;32m--> 152\u001b[0m     dependencies \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mprepare\u001b[49m\u001b[43m(\u001b[49m\u001b[43mrequest\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    153\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(dependencies, BatchRequest):\n\u001b[1;32m    154\u001b[0m         upstream_request \u001b[38;5;241m=\u001b[39m request\u001b[38;5;241m.\u001b[39mupdate_with(dependencies)\n",
      "File \u001b[0;32m~/miniconda3/envs/celltracking/lib/python3.9/site-packages/gunpowder/nodes/elastic_augment.py:157\u001b[0m, in \u001b[0;36mElasticAugment.prepare\u001b[0;34m(self, request)\u001b[0m\n\u001b[1;32m    150\u001b[0m logger\u001b[38;5;241m.\u001b[39mdebug(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmaster ROI in voxels is \u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m%\u001b[39m master_roi_voxels)\n\u001b[1;32m    152\u001b[0m \u001b[38;5;66;03m# Second, create a master transformation. This is a transformation that\u001b[39;00m\n\u001b[1;32m    153\u001b[0m \u001b[38;5;66;03m# covers all voxels of the all requested ROIs. The master transformation\u001b[39;00m\n\u001b[1;32m    154\u001b[0m \u001b[38;5;66;03m# is zero-based.\u001b[39;00m\n\u001b[1;32m    155\u001b[0m \n\u001b[1;32m    156\u001b[0m \u001b[38;5;66;03m# create a transformation with the size of the master ROI in voxels\u001b[39;00m\n\u001b[0;32m--> 157\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmaster_transformation \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m__create_transformation\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    158\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmaster_roi_voxels\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_shape\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    159\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    161\u001b[0m \u001b[38;5;66;03m# Third, crop out parts of the master transformation for each of the\u001b[39;00m\n\u001b[1;32m    162\u001b[0m \u001b[38;5;66;03m# smaller requested ROIs. Since these ROIs now have to align with the\u001b[39;00m\n\u001b[1;32m    163\u001b[0m \u001b[38;5;66;03m# voxel size (which for points does not have to be the case), we also\u001b[39;00m\n\u001b[1;32m    164\u001b[0m \u001b[38;5;66;03m# remember these smaller ROIs as target_rois in global world units.\u001b[39;00m\n\u001b[1;32m    165\u001b[0m \n\u001b[1;32m    166\u001b[0m \u001b[38;5;66;03m# crop the parts corresponding to the requested ROIs\u001b[39;00m\n\u001b[1;32m    167\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtransformations \u001b[38;5;241m=\u001b[39m {}\n",
      "File \u001b[0;32m~/miniconda3/envs/celltracking/lib/python3.9/site-packages/gunpowder/nodes/elastic_augment.py:395\u001b[0m, in \u001b[0;36mElasticAugment.__create_transformation\u001b[0;34m(self, target_shape)\u001b[0m\n\u001b[1;32m    391\u001b[0m transformation \u001b[38;5;241m=\u001b[39m augment\u001b[38;5;241m.\u001b[39mcreate_identity_transformation(\n\u001b[1;32m    392\u001b[0m     target_shape, subsample\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msubsample, scale\u001b[38;5;241m=\u001b[39mscale\n\u001b[1;32m    393\u001b[0m )\n\u001b[1;32m    394\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28msum\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mjitter_sigma) \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[0;32m--> 395\u001b[0m     transformation \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[43maugment\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcreate_elastic_transformation\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    396\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtarget_shape\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    397\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcontrol_point_spacing\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    398\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mjitter_sigma\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    399\u001b[0m \u001b[43m        \u001b[49m\u001b[43msubsample\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msubsample\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    400\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    401\u001b[0m rotation \u001b[38;5;241m=\u001b[39m random\u001b[38;5;241m.\u001b[39mrandom() \u001b[38;5;241m*\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mrotation_max_amount \u001b[38;5;241m+\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mrotation_start\n\u001b[1;32m    402\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m rotation \u001b[38;5;241m!=\u001b[39m \u001b[38;5;241m0\u001b[39m:\n",
      "File \u001b[0;32m~/miniconda3/envs/celltracking/lib/python3.9/site-packages/augment/transform.py:116\u001b[0m, in \u001b[0;36mcreate_elastic_transformation\u001b[0;34m(shape, control_point_spacing, jitter_sigma, subsample)\u001b[0m\n\u001b[1;32m    113\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m sigmas[d] \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[1;32m    114\u001b[0m         control_point_offsets[d] \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mrandom\u001b[38;5;241m.\u001b[39mnormal(scale\u001b[38;5;241m=\u001b[39msigmas[d], size\u001b[38;5;241m=\u001b[39mcontrol_points)\n\u001b[0;32m--> 116\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mupscale_transformation\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcontrol_point_offsets\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msubsample_shape\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minterpolate_order\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m3\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/envs/celltracking/lib/python3.9/site-packages/augment/transform.py:29\u001b[0m, in \u001b[0;36mupscale_transformation\u001b[0;34m(transformation, output_shape, interpolate_order)\u001b[0m\n\u001b[1;32m     27\u001b[0m scaled \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mzeros((dims,)\u001b[38;5;241m+\u001b[39moutput_shape, dtype\u001b[38;5;241m=\u001b[39mnp\u001b[38;5;241m.\u001b[39mfloat32)\n\u001b[1;32m     28\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m d \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(dims):\n\u001b[0;32m---> 29\u001b[0m     \u001b[43mzoom\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtransformation\u001b[49m\u001b[43m[\u001b[49m\u001b[43md\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mzoom\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mscale\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moutput\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mscaled\u001b[49m\u001b[43m[\u001b[49m\u001b[43md\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43morder\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minterpolate_order\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     30\u001b[0m \u001b[38;5;66;03m# print(\"\\tupsampled in \" + str(time.time() - start) + \"s\")\u001b[39;00m\n\u001b[1;32m     32\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m scaled\n",
      "File \u001b[0;32m~/miniconda3/envs/celltracking/lib/python3.9/site-packages/scipy/ndimage/_interpolation.py:816\u001b[0m, in \u001b[0;36mzoom\u001b[0;34m(input, zoom, output, order, mode, cval, prefilter, grid_mode)\u001b[0m\n\u001b[1;32m    812\u001b[0m zoom \u001b[38;5;241m=\u001b[39m numpy\u001b[38;5;241m.\u001b[39mdivide(zoom_nominator, zoom_div,\n\u001b[1;32m    813\u001b[0m                     out\u001b[38;5;241m=\u001b[39mnumpy\u001b[38;5;241m.\u001b[39mones_like(\u001b[38;5;28minput\u001b[39m\u001b[38;5;241m.\u001b[39mshape, dtype\u001b[38;5;241m=\u001b[39mnumpy\u001b[38;5;241m.\u001b[39mfloat64),\n\u001b[1;32m    814\u001b[0m                     where\u001b[38;5;241m=\u001b[39mzoom_div \u001b[38;5;241m!=\u001b[39m \u001b[38;5;241m0\u001b[39m)\n\u001b[1;32m    815\u001b[0m zoom \u001b[38;5;241m=\u001b[39m numpy\u001b[38;5;241m.\u001b[39mascontiguousarray(zoom)\n\u001b[0;32m--> 816\u001b[0m \u001b[43m_nd_image\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mzoom_shift\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfiltered\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mzoom\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moutput\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43morder\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmode\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcval\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnpad\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    817\u001b[0m \u001b[43m                     \u001b[49m\u001b[43mgrid_mode\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    818\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m output\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "from tqdm import tqdm\n",
    "\n",
    "def train(tb_logger = None, log_image_interval = 10):\n",
    "    if torch.cuda.is_available():\n",
    "        device = torch.device(\"cuda\")\n",
    "    else:\n",
    "        device = torch.device(\"cpu\")\n",
    "        \n",
    "    loss=[] \n",
    "    counter=[]\n",
    "    with gp.build(pipeline):\n",
    "        for epoch in tqdm(range(epochs)):\n",
    "            epoch_loss = 0\n",
    "            epoch_loss_pos = 0\n",
    "            epoch_loss_neg = 0\n",
    "            for x in range(100):\n",
    "                unpaired1 = pipeline.request_batch(request_vol1u)\n",
    "                unpaired2 = pipeline.request_batch(request_vol2u)\n",
    "                yu = -1\n",
    "                \n",
    "                paired1 = pipeline.request_batch(request_vol1p)\n",
    "                paired2 = pipeline.request_batch(request_vol2p)\n",
    "                yp = 1\n",
    "                \n",
    "                unpaired1 = unpaired1[raw].data[:,:,:,:]\n",
    "                unpaired2 = unpaired2[raw].data[:,:,:,:]\n",
    "                paired1 = paired1[raw].data[:,:,:,:]\n",
    "                paired2 = paired2[raw].data[:,:,:,:]\n",
    "                \n",
    "                unpaired1 = np.reshape(unpaired1, (1,64, 64, 5))\n",
    "                unpaired2 = np.reshape(unpaired2, (1,64, 64, 5))\n",
    "                paired1 = np.reshape(paired1, (1,64, 64, 5))\n",
    "                paired2 = np.reshape(paired2, (1,64, 64, 5))\n",
    "                \n",
    "                unpaired1 = np.expand_dims(unpaired1, axis =0)\n",
    "                unpaired2 = np.expand_dims(unpaired2, axis=0)\n",
    "                paired1 = np.expand_dims(paired1, axis =0)\n",
    "                paired2 = np.expand_dims(paired2, axis=0)\n",
    "\n",
    "                unpaired1 = torch.from_numpy(unpaired1).to(device).float()\n",
    "                unpaired2 = torch.from_numpy(unpaired2).to(device).float()\n",
    "                yu = torch.from_numpy(np.array([yu])).to(device).float()\n",
    "                \n",
    "                paired1 = torch.from_numpy(paired1).to(device).float()\n",
    "                paired2 = torch.from_numpy(paired2).to(device).float() \n",
    "                yp = torch.from_numpy(np.array([yp])).to(device).float()\n",
    "\n",
    "                optimizer.zero_grad()\n",
    "                \n",
    "                predp1 = model(unpaired1)\n",
    "                predp2 = model(unpaired2)\n",
    "                predu1 = model(paired1)\n",
    "                predu2 = model(paired2)\n",
    "                # print(model(unpaired1).shape)\n",
    "                # print(predp1.shape)\n",
    "\n",
    "                #loss = loss_function(pred, y)\n",
    "\n",
    "                loss_contrastivep = loss_function(predp1,predp2,yp)\n",
    "                loss_contrastiveu = loss_function(predu1,predu2,yu)\n",
    "\n",
    "                loss_contrastivep.backward()\n",
    "                loss_contrastiveu.backward()\n",
    "                optimizer.step()    \n",
    "                epoch_loss_pos += loss_contrastivep\n",
    "                epoch_loss_neg += loss_contrastiveu\n",
    "                epoch_loss += loss_contrastivep + loss_contrastiveu\n",
    "                \n",
    "                if tb_logger is not None:\n",
    "                    step = epoch * 100 + x\n",
    "                    tb_logger.add_scalar(\n",
    "                        tag=\"positive_loss\", scalar_value=epoch_loss_pos.item(), global_step=step\n",
    "                    )\n",
    "                    tb_logger.add_scalar(\n",
    "                        tag=\"negative_loss\", scalar_value=epoch_loss_neg.item(), global_step=step\n",
    "                    )\n",
    "                    tb_logger.add_scalar(\n",
    "                        tag=\"total_loss\", scalar_value=epoch_loss.item(), global_step = step\n",
    "                    )\n",
    "                    # check if we log images in this iteration\n",
    "                    # if step % log_image_interval == 0:\n",
    "                    #     tb_logger.add_images(\n",
    "                    #         tag=\"in_unpaired1\", img_tensor=unpaired1.to(\"cpu\"), global_step=step\n",
    "                    #     )\n",
    "                    #     tb_logger.add_images(\n",
    "                    #         tag=\"in_unpaired2\", img_tensor=unpaired2.to(\"cpu\"), global_step=step\n",
    "                    #     )\n",
    "                    #     tb_logger.add_images(\n",
    "                    #         tag=\"in_paired1\", img_tensor=paired1.to(\"cpu\"), global_step=step\n",
    "                    #     )\n",
    "                    #     tb_logger.add_images(\n",
    "                    #         tag=\"in_paired2\", img_tensor=paired2.to(\"cpu\"), global_step=step\n",
    "                    #     )\n",
    "\n",
    "\n",
    "            print(f\"epoch {epoch}, total_loss = {epoch_loss}, positive_loss={epoch_loss_pos}, negative_loss={epoch_loss_neg}\")\n",
    "        \n",
    "    return model\n",
    "\n",
    "model = train(tb_logger = logger)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4bad3724-0af7-4a27-94c5-b25d542a50ee",
   "metadata": {},
   "source": [
    "# Tracking / Linear Assignment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25131276-e24d-48bd-99eb-bc3585b94fe6",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
