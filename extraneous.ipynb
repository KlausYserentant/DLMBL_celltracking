{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "760f81ef-9353-4688-b9d8-f6221705f6b6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "467e4d38-c30e-40b5-bba7-d3ea8e874c33",
   "metadata": {},
   "outputs": [],
   "source": [
    "# class VGG(nn.Module):\n",
    "\n",
    "#     def __init__(self, features, num_classes=1000, init_weights=True):\n",
    "#         super(VGG, self).__init__()\n",
    "#         self.features = features\n",
    "#         self.avgpool = nn.AdaptiveAvgPool2d((7, 7))\n",
    "        \n",
    "#         self.classifier = nn.Sequential(\n",
    "#             nn.Linear(512 * 7 * 7, 4096),\n",
    "#             nn.ReLU(True),\n",
    "#             nn.Dropout(),\n",
    "#             nn.Linear(4096, 4096),\n",
    "#             nn.ReLU(True),\n",
    "#             nn.Dropout(),\n",
    "#             nn.Linear(4096, num_classes),\n",
    "#         )\n",
    "        \n",
    "#         if init_weights:\n",
    "#             self._initialize_weights()\n",
    "\n",
    "#     def forward(self, x):\n",
    "#         x = self.features(x)\n",
    "#         x = self.avgpool(x)\n",
    "#         x = torch.flatten(x, 1)\n",
    "#         x = self.classifier(x)\n",
    "#         return x\n",
    "\n",
    "#     def _initialize_weights(self):\n",
    "#         for m in self.modules():\n",
    "#             if isinstance(m, nn.Conv2d):\n",
    "#                 nn.init.kaiming_normal_(m.weight, mode='fan_out', nonlinearity='relu')\n",
    "#                 if m.bias is not None:\n",
    "#                     nn.init.constant_(m.bias, 0)\n",
    "#             elif isinstance(m, nn.BatchNorm2d):\n",
    "#                 nn.init.constant_(m.weight, 1)\n",
    "#                 nn.init.constant_(m.bias, 0)\n",
    "#             elif isinstance(m, nn.Linear):\n",
    "#                 nn.init.normal_(m.weight, 0, 0.01)\n",
    "#                 nn.init.constant_(m.bias, 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a5523000-c513-4737-8fc9-bf5f4c9645a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# class Vgg2D(torch.nn.Module):\n",
    "\n",
    "#     def __init__(\n",
    "#             self,\n",
    "#             input_size,\n",
    "#             fmaps=12,\n",
    "#             downsample_factors=[(2, 2), (2, 2), (2, 2), (2, 2)],\n",
    "#             output_classes=6):\n",
    "\n",
    "#         super(Vgg2D, self).__init__()\n",
    "\n",
    "#         self.input_size = input_size\n",
    "\n",
    "#         current_fmaps, h, w = tuple(input_size)\n",
    "#         current_size = (h, w)\n",
    "\n",
    "#         features = []\n",
    "#         for i in range(len(downsample_factors)):\n",
    "\n",
    "#             features += [\n",
    "#                 torch.nn.Conv2d(\n",
    "#                     current_fmaps,\n",
    "#                     fmaps,\n",
    "#                     kernel_size=3,\n",
    "#                     padding=1),\n",
    "#                 torch.nn.BatchNorm2d(fmaps),\n",
    "#                 torch.nn.ReLU(inplace=True),\n",
    "#                 torch.nn.Conv2d(\n",
    "#                     fmaps,\n",
    "#                     fmaps,\n",
    "#                     kernel_size=3,\n",
    "#                     padding=1),\n",
    "#                 torch.nn.BatchNorm2d(fmaps),\n",
    "#                 torch.nn.ReLU(inplace=True),\n",
    "#                 torch.nn.MaxPool2d(downsample_factors[i])\n",
    "#             ]\n",
    "\n",
    "#             current_fmaps = fmaps\n",
    "#             fmaps *= 2\n",
    "\n",
    "#             size = tuple(\n",
    "#                 int(c/d)\n",
    "#                 for c, d in zip(current_size, downsample_factors[i]))\n",
    "#             check = (\n",
    "#                 s*d == c\n",
    "#                 for s, d, c in zip(size, downsample_factors[i], current_size))\n",
    "#             assert all(check), \\\n",
    "#                 \"Can not downsample %s by chosen downsample factor\" % \\\n",
    "#                 (current_size,)\n",
    "#             current_size = size\n",
    "\n",
    "#         self.features = torch.nn.Sequential(*features)\n",
    "\n",
    "#         classifier = [\n",
    "#             torch.nn.Linear(\n",
    "#                 current_size[0] *\n",
    "#                 current_size[1] *\n",
    "#                 current_fmaps,\n",
    "#                 4096),\n",
    "#             torch.nn.ReLU(inplace=True),\n",
    "#             torch.nn.Dropout(),\n",
    "#             torch.nn.Linear(\n",
    "#                 4096,\n",
    "#                 4096),\n",
    "#             torch.nn.ReLU(inplace=True),\n",
    "#             torch.nn.Dropout(),\n",
    "#             torch.nn.Linear(\n",
    "#                 4096,\n",
    "#                 output_classes)\n",
    "#         ]\n",
    "\n",
    "#         self.classifier = torch.nn.Sequential(*classifier)\n",
    "    \n",
    "#     def forward(self, raw):\n",
    "\n",
    "#         # add a channel dimension to raw\n",
    "#         # shape = tuple(raw.shape)\n",
    "#         # raw = raw.reshape(shape[0], 1, shape[1], shape[2])\n",
    "        \n",
    "#         # compute features\n",
    "#         f = self.features(raw)\n",
    "#         f = f.view(f.size(0), -1)\n",
    "        \n",
    "#         # classify\n",
    "#         y = self.classifier(f)\n",
    "\n",
    "#         return y"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
