{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "96fa3a08-111f-4d26-8e65-7be9ba004054",
   "metadata": {},
   "source": [
    "# Model Implementation for 3D Cell Tracking\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "15fd6961-5904-42c4-9fd7-190c0685c312",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: torchsummary in /home/bourquea/miniconda3/envs/09_knowledge_extraction/lib/python3.10/site-packages (1.5.1)\n"
     ]
    }
   ],
   "source": [
    "!pip install torchsummary "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2503c9e5-eea9-4751-9600-fd8c537aecea",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import DataLoader, random_split\n",
    "from torch.utils.data.sampler import WeightedRandomSampler\n",
    "from torchvision.datasets import ImageFolder\n",
    "from torchvision import transforms\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import numpy as np\n",
    "import random \n",
    "import matplotlib.pyplot as plt\n",
    "from torchvision import models\n",
    "from torchsummary import summary\n",
    "\n",
    "from torchvision import datasets\n",
    "from torchvision import transforms\n",
    "from torch.utils.data.sampler import SubsetRandomSampler\n",
    "\n",
    "\n",
    "# Device configuration\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aae23f64-6f4c-42b5-b523-43668c65f2f7",
   "metadata": {},
   "source": [
    "## Designed VGG Model from Exercise 9"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f2716b1-af41-47db-a7bc-4036b86a5823",
   "metadata": {},
   "source": [
    "We will use a VGG network to classify the synapse images. The input to the network will be a 2D image as provided by your dataloader. The output will be a vector of six floats, corresponding to the probability of the input to belong to the six classes.\n",
    "\n",
    "Implement a VGG network with the following specificatons:\n",
    "\n",
    "* the constructor takes the size of the 2D input image as height and width\n",
    "* the network starts with a downsample path consisting of:\n",
    "    * one convolutional layer, kernel size (3, 3), to create 12 `fmaps`\n",
    "    * `nn.BatchNorm2d` over those feature maps\n",
    "    * `nn.ReLU` activation function\n",
    "    * `nn.Conv2d` layer, kernel size (3, 3), to create 12 `fmaps`\n",
    "    * `nn.BatchNorm2d` over those feature maps\n",
    "    * `nn.ReLU` activation function\n",
    "    * `nn.MaxPool2d` with a `downsample_factor` of (2, 2) at each level\n",
    "* followed by three more downsampling paths like the one above, every time doubling the number of `fmaps` (i.e., the second one will have 24, the third 48, and the fourth 96). Make sure to keep track of the `current_fmaps` each time!\n",
    "* then two times:\n",
    "    * `nn.Linear` layer with `out_features=4096`. Be careful withe in `in_features` of the first one, which will depend on the size of the previous output!\n",
    "    * `nn.ReLU` activation function\n",
    "    * `nn.DropOut`\n",
    "* Finally, one more fully connected layer with\n",
    "    * `nn.Linear` to the 6 classes\n",
    "    * no activation function "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "70e5e4a8-6b2c-4de7-9817-7510aafe3a70",
   "metadata": {},
   "source": [
    "Original One (from https://blog.paperspace.com/vgg-from-scratch-pytorch/)\n",
    "https://github.com/pytorch/vision/blob/6db1569c89094cf23f3bc41f79275c45e9fcb3f3/torchvision/models/vgg.py#L24"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d205ad50-7c0e-4181-b291-f5b505a85e94",
   "metadata": {},
   "source": [
    "# Create and Load Artificial Data\n",
    "Make a fake dataset to test on the VGG model while waiting for data.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "9ed5d836-6886-484e-9890-2aa969c6803c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#original data size = 512x712x34 \n",
    "\n",
    "fd_class1 = np.random.randn(1, 1, 128,128,128) + 0.5\n",
    "fd_class2 = np.random.randn(1,1,128,128,128)\n",
    "y1 = 1\n",
    "y2 = 0\n",
    "# fd_class1 = np.expand_dims(fd_class1, axis=0)\n",
    "# fd_class2 = np.expand_dims(fd_class2, axis=0)\n",
    "\n",
    "loader = [(fd_class1, y1), (fd_class2,y2)]\n",
    "\n",
    "#Split\n",
    "# train_set_size = int(len(fd_class1) * 0.7)\n",
    "# valid_set_size = int(len(fd_class1) * 0.2)\n",
    "# test_data_size = len(fd_class1) - train_set_size - valid_set_size\n",
    "    \n",
    "# train_data_C1, val_data_C1, test_data_C1 = random_split(\n",
    "#     fd_class1,\n",
    "#     [train_set_size, valid_set_size, test_data_size],\n",
    "#     generator=torch.Generator().manual_seed(23061912))\n",
    "\n",
    "# train_data_C2, val_data_C2, test_data_C2 = random_split(\n",
    "#     fd_class2,\n",
    "#     [train_set_size, valid_set_size, test_data_size],\n",
    "#     generator=torch.Generator().manual_seed(23061912))\n",
    "\n",
    "#train = np.ndarray.flatten(fd_class1)\n",
    "#train2 = np.ndarray.flatten(fd_class2)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "3e8366e9-94dc-4dcf-8eda-71b8bcc237c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "#sampler = balanced_sampler(train_data_C1)\n",
    "#dataloader = DataLoader(train_data_C1, batch_size=8, drop_last=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a77f74b5-d746-4fe4-8661-2f5efcc0e95b",
   "metadata": {},
   "source": [
    "# Define the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "4517e490-95cb-4786-b8d8-52b7a051da79",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Vgg3D(torch.nn.Module):\n",
    "\n",
    "    def __init__(self, input_size, output_classes, downsample_factors, fmaps=12):\n",
    "\n",
    "        super(Vgg3D, self).__init__()\n",
    "\n",
    "        self.input_size = input_size\n",
    "        self.downsample_factors = downsample_factors\n",
    "        self.output_classes = 2\n",
    "\n",
    "        current_fmaps, h, w, d = tuple(input_size)\n",
    "        current_size = (h, w,d)\n",
    "\n",
    "        features = []\n",
    "        for i in range(len(downsample_factors)):\n",
    "\n",
    "            features += [\n",
    "                torch.nn.Conv3d(current_fmaps,fmaps,kernel_size=3,padding=1),\n",
    "                torch.nn.BatchNorm3d(fmaps),\n",
    "                torch.nn.ReLU(inplace=True),\n",
    "                torch.nn.Conv3d(fmaps,fmaps,kernel_size=3,padding=1),\n",
    "                torch.nn.BatchNorm3d(fmaps),\n",
    "                torch.nn.ReLU(inplace=True),\n",
    "                torch.nn.MaxPool3d(downsample_factors[i])\n",
    "            ]\n",
    "\n",
    "            current_fmaps = fmaps\n",
    "            fmaps *= 2\n",
    "\n",
    "            size = tuple(\n",
    "                int(c/d)\n",
    "                for c, d in zip(current_size, downsample_factors[i]))\n",
    "            check = (\n",
    "                s*d == c\n",
    "                for s, d, c in zip(size, downsample_factors[i], current_size))\n",
    "            assert all(check), \\\n",
    "                \"Can not downsample %s by chosen downsample factor\" % \\\n",
    "                (current_size,)\n",
    "            current_size = size\n",
    "\n",
    "        self.features = torch.nn.Sequential(*features)\n",
    "\n",
    "        classifier = [\n",
    "            torch.nn.Linear(current_size[0] *current_size[1]*current_size[2] *current_fmaps,4096),\n",
    "            torch.nn.ReLU(inplace=True),\n",
    "            torch.nn.Dropout(),\n",
    "            torch.nn.Linear(4096,4096),\n",
    "            torch.nn.ReLU(inplace=True),\n",
    "            torch.nn.Dropout(),\n",
    "            torch.nn.Linear(4096,output_classes)\n",
    "        ]\n",
    "\n",
    "        self.classifier = torch.nn.Sequential(*classifier)\n",
    "    \n",
    "    def forward(self, raw):\n",
    "\n",
    "        # add a channel dimension to raw\n",
    "        # shape = tuple(raw.shape)\n",
    "        # raw = raw.reshape(shape[0], 1, shape[1], shape[2])\n",
    "        \n",
    "        # compute features\n",
    "        f = self.features(raw)\n",
    "        f = f.view(f.size(0), -1)\n",
    "        \n",
    "        # classify\n",
    "        y = self.classifier(f)\n",
    "\n",
    "        return y"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b3e2402c-a5d9-4538-88e8-4dac17d5bda7",
   "metadata": {},
   "source": [
    "# Training and Evaluation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "29ff22bf-d49f-42bf-b92d-b110037d97fc",
   "metadata": {},
   "source": [
    "# Loss Functions\n",
    "\n",
    "We'll probably need to test some different loss functions. List some here:\n",
    "Contrastive loss\n",
    "cosine similarity\n",
    "triplet loss\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "7c52a2b5-1749-4209-b022-41a445109799",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ContrastiveLoss(nn.Module):\n",
    "    \"Contrastive loss function\"\n",
    "\n",
    "    def __init__(self, margin=2.0):\n",
    "        super(ContrastiveLoss, self).__init__()\n",
    "        self.margin = margin\n",
    "\n",
    "    def forward(self, output1, output2, label):\n",
    "        euclidean_distance = F.pairwise_distance(output1, output2)\n",
    "        loss_contrastive = torch.mean(\n",
    "            (1 - label) * torch.pow(euclidean_distance, 2)\n",
    "            + (label)\n",
    "            * torch.pow(torch.clamp(self.margin - euclidean_distance, min=0.0), 2)\n",
    "        )\n",
    "\n",
    "        return loss_contrastive"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "9da12ed3-cb32-4e26-809d-8aed7cf9ec28",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------------------------------\n",
      "        Layer (type)               Output Shape         Param #\n",
      "================================================================\n",
      "            Conv3d-1    [-1, 12, 128, 128, 128]             336\n",
      "       BatchNorm3d-2    [-1, 12, 128, 128, 128]              24\n",
      "              ReLU-3    [-1, 12, 128, 128, 128]               0\n",
      "            Conv3d-4    [-1, 12, 128, 128, 128]           3,900\n",
      "       BatchNorm3d-5    [-1, 12, 128, 128, 128]              24\n",
      "              ReLU-6    [-1, 12, 128, 128, 128]               0\n",
      "         MaxPool3d-7       [-1, 12, 64, 64, 64]               0\n",
      "            Conv3d-8       [-1, 24, 64, 64, 64]           7,800\n",
      "       BatchNorm3d-9       [-1, 24, 64, 64, 64]              48\n",
      "             ReLU-10       [-1, 24, 64, 64, 64]               0\n",
      "           Conv3d-11       [-1, 24, 64, 64, 64]          15,576\n",
      "      BatchNorm3d-12       [-1, 24, 64, 64, 64]              48\n",
      "             ReLU-13       [-1, 24, 64, 64, 64]               0\n",
      "        MaxPool3d-14       [-1, 24, 32, 32, 32]               0\n",
      "           Conv3d-15       [-1, 48, 32, 32, 32]          31,152\n",
      "      BatchNorm3d-16       [-1, 48, 32, 32, 32]              96\n",
      "             ReLU-17       [-1, 48, 32, 32, 32]               0\n",
      "           Conv3d-18       [-1, 48, 32, 32, 32]          62,256\n",
      "      BatchNorm3d-19       [-1, 48, 32, 32, 32]              96\n",
      "             ReLU-20       [-1, 48, 32, 32, 32]               0\n",
      "        MaxPool3d-21       [-1, 48, 16, 16, 16]               0\n",
      "           Conv3d-22       [-1, 96, 16, 16, 16]         124,512\n",
      "      BatchNorm3d-23       [-1, 96, 16, 16, 16]             192\n",
      "             ReLU-24       [-1, 96, 16, 16, 16]               0\n",
      "           Conv3d-25       [-1, 96, 16, 16, 16]         248,928\n",
      "      BatchNorm3d-26       [-1, 96, 16, 16, 16]             192\n",
      "             ReLU-27       [-1, 96, 16, 16, 16]               0\n",
      "        MaxPool3d-28          [-1, 96, 8, 8, 8]               0\n",
      "           Linear-29                 [-1, 4096]     201,330,688\n",
      "             ReLU-30                 [-1, 4096]               0\n",
      "          Dropout-31                 [-1, 4096]               0\n",
      "           Linear-32                 [-1, 4096]      16,781,312\n",
      "             ReLU-33                 [-1, 4096]               0\n",
      "          Dropout-34                 [-1, 4096]               0\n",
      "           Linear-35                   [-1, 16]          65,552\n",
      "================================================================\n",
      "Total params: 218,672,732\n",
      "Trainable params: 218,672,732\n",
      "Non-trainable params: 0\n",
      "----------------------------------------------------------------\n",
      "Input size (MB): 8.00\n",
      "Forward/backward pass size (MB): 1562.06\n",
      "Params size (MB): 834.17\n",
      "Estimated Total Size (MB): 2404.23\n",
      "----------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "input_size = (1, 128, 128, 128)\n",
    "downsample_factors =[(2, 2, 2), (2, 2, 2), (2, 2, 2), (2, 2, 2)];\n",
    "output_classes = 16\n",
    "\n",
    "# create the model to train\n",
    "model = Vgg3D(input_size, output_classes,  downsample_factors = downsample_factors)\n",
    "model = model.to(device)\n",
    "\n",
    "summary(model, input_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "27bbf7d8-1dfb-441b-a523-894c3be93493",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Training length\n",
    "epochs = 2000\n",
    "\n",
    "loss_function = torch.nn.BCELoss()\n",
    "#loss_function = torch.nn.CosineSimilarity()\n",
    "#loss_function = ContrastiveLoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=1e-4, weight_decay=0.0005)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e03dec6c-14c4-4400-8ff5-d523845d6105",
   "metadata": {},
   "source": [
    "# Training Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "540a7588-c2cc-4a69-afe5-f584ba804cbb",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|                                        | 1/2000 [00:02<1:20:59,  2.43s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 0, training loss=2.3841860752327193e-07\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|                                        | 2/2000 [00:04<1:18:43,  2.36s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 1, training loss=2.3841887468734058e-06\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|                                        | 3/2000 [00:07<1:17:59,  2.34s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 2, training loss=2.6010806560516357\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|                                        | 4/2000 [00:09<1:17:32,  2.33s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 3, training loss=0.00338159897364676\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|                                        | 5/2000 [00:11<1:17:16,  2.32s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 4, training loss=0.01047830656170845\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|                                        | 6/2000 [00:14<1:17:05,  2.32s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 5, training loss=2.414116859436035\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|▏                                       | 7/2000 [00:16<1:16:57,  2.32s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 6, training loss=1.1742184142349288e-05\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|▏                                       | 8/2000 [00:18<1:16:53,  2.32s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 7, training loss=0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|▏                                       | 9/2000 [00:20<1:16:54,  2.32s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 8, training loss=0.00011981251009274274\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|▏                                      | 10/2000 [00:23<1:16:53,  2.32s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 9, training loss=4.734710693359375\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  1%|▏                                      | 11/2000 [00:25<1:16:50,  2.32s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 10, training loss=2.3841860752327193e-07\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  1%|▏                                      | 12/2000 [00:27<1:16:44,  2.32s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 11, training loss=0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  1%|▎                                      | 13/2000 [00:30<1:16:42,  2.32s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 12, training loss=1.788139485370266e-07\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  1%|▎                                      | 14/2000 [00:32<1:16:40,  2.32s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 13, training loss=0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  1%|▎                                      | 15/2000 [00:34<1:16:35,  2.32s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 14, training loss=0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  1%|▎                                      | 16/2000 [00:37<1:16:32,  2.31s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 15, training loss=1.585496102052275e-05\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  1%|▎                                      | 17/2000 [00:39<1:16:30,  2.31s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 16, training loss=0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  1%|▎                                      | 18/2000 [00:41<1:16:28,  2.32s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 17, training loss=0.001489257556386292\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  1%|▎                                      | 19/2000 [00:44<1:16:25,  2.31s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 18, training loss=0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  1%|▍                                      | 20/2000 [00:46<1:16:23,  2.31s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 19, training loss=0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  1%|▍                                      | 21/2000 [00:48<1:16:19,  2.31s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 20, training loss=0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  1%|▍                                      | 22/2000 [00:51<1:16:18,  2.31s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 21, training loss=5.960464477539063e-08\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  1%|▍                                      | 23/2000 [00:53<1:16:20,  2.32s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 22, training loss=3.099446303167497e-06\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  1%|▍                                      | 24/2000 [00:55<1:16:19,  2.32s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 23, training loss=5.960464477539063e-08\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  1%|▍                                      | 25/2000 [00:58<1:16:18,  2.32s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 24, training loss=0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  1%|▌                                      | 26/2000 [01:00<1:16:15,  2.32s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 25, training loss=0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  1%|▌                                      | 27/2000 [01:02<1:16:12,  2.32s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 26, training loss=0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  1%|▌                                      | 28/2000 [01:04<1:16:08,  2.32s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 27, training loss=0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  1%|▌                                      | 29/2000 [01:07<1:16:03,  2.32s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 28, training loss=0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  2%|▌                                      | 30/2000 [01:09<1:16:01,  2.32s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 29, training loss=0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  2%|▌                                      | 31/2000 [01:11<1:16:01,  2.32s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 30, training loss=0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  2%|▌                                      | 32/2000 [01:14<1:16:00,  2.32s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 31, training loss=0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  2%|▋                                      | 33/2000 [01:16<1:15:58,  2.32s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 32, training loss=0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  2%|▋                                      | 34/2000 [01:18<1:15:58,  2.32s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 33, training loss=5.960464477539063e-08\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  2%|▋                                      | 35/2000 [01:21<1:15:55,  2.32s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 34, training loss=0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  2%|▋                                      | 36/2000 [01:23<1:15:55,  2.32s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 35, training loss=5.960464477539063e-08\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  2%|▋                                      | 37/2000 [01:25<1:15:53,  2.32s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 36, training loss=1.788139485370266e-07\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  2%|▋                                      | 38/2000 [01:28<1:15:51,  2.32s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 37, training loss=0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  2%|▊                                      | 39/2000 [01:30<1:15:48,  2.32s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 38, training loss=5.960464477539063e-08\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  2%|▊                                      | 40/2000 [01:32<1:15:45,  2.32s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 39, training loss=0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  2%|▊                                      | 41/2000 [01:35<1:15:43,  2.32s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 40, training loss=0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  2%|▊                                      | 42/2000 [01:37<1:15:43,  2.32s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 41, training loss=0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  2%|▊                                      | 43/2000 [01:39<1:15:41,  2.32s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 42, training loss=1.1920930376163597e-07\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  2%|▊                                      | 44/2000 [01:42<1:15:39,  2.32s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 43, training loss=0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  2%|▉                                      | 45/2000 [01:44<1:15:38,  2.32s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 44, training loss=0.011329271830618382\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  2%|▉                                      | 46/2000 [01:46<1:15:36,  2.32s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 45, training loss=0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  2%|▉                                      | 47/2000 [01:49<1:15:34,  2.32s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 46, training loss=0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  2%|▉                                      | 48/2000 [01:51<1:15:35,  2.32s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 47, training loss=1.7881409348774469e-06\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  2%|▉                                      | 49/2000 [01:53<1:15:34,  2.32s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 48, training loss=0.2014390528202057\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  2%|▉                                      | 50/2000 [01:56<1:15:29,  2.32s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 49, training loss=0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  3%|▉                                      | 51/2000 [01:58<1:15:28,  2.32s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 50, training loss=5.960464477539063e-08\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  3%|█                                      | 52/2000 [02:00<1:15:24,  2.32s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 51, training loss=0.05431920662522316\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  3%|█                                      | 53/2000 [02:02<1:15:21,  2.32s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 52, training loss=0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  3%|█                                      | 54/2000 [02:05<1:15:22,  2.32s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 53, training loss=0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  3%|█                                      | 55/2000 [02:07<1:15:18,  2.32s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 54, training loss=0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  3%|█                                      | 56/2000 [02:09<1:15:17,  2.32s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 55, training loss=0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  3%|█                                      | 57/2000 [02:12<1:15:14,  2.32s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 56, training loss=0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  3%|█▏                                     | 58/2000 [02:14<1:15:14,  2.32s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 57, training loss=0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  3%|█▏                                     | 59/2000 [02:16<1:15:12,  2.32s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 58, training loss=0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  3%|█▏                                     | 60/2000 [02:19<1:15:09,  2.32s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 59, training loss=0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  3%|█▏                                     | 61/2000 [02:21<1:15:09,  2.33s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 60, training loss=0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  3%|█▏                                     | 62/2000 [02:23<1:15:08,  2.33s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 61, training loss=2.3841887468734058e-06\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  3%|█▏                                     | 63/2000 [02:26<1:15:03,  2.32s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 62, training loss=0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  3%|█▏                                     | 64/2000 [02:28<1:14:58,  2.32s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 63, training loss=0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  3%|█▎                                     | 65/2000 [02:30<1:15:00,  2.33s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 64, training loss=0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  3%|█▎                                     | 66/2000 [02:33<1:14:57,  2.33s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 65, training loss=0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  3%|█▎                                     | 67/2000 [02:35<1:14:53,  2.32s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 66, training loss=0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  3%|█▎                                     | 68/2000 [02:37<1:14:50,  2.32s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 67, training loss=0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  3%|█▎                                     | 69/2000 [02:40<1:14:48,  2.32s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 68, training loss=0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  4%|█▎                                     | 70/2000 [02:42<1:14:44,  2.32s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 69, training loss=7.152560215217818e-07\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  4%|█▍                                     | 71/2000 [02:44<1:14:37,  2.32s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 70, training loss=0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  4%|█▍                                     | 72/2000 [02:47<1:14:32,  2.32s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 71, training loss=0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  4%|█▍                                     | 73/2000 [02:49<1:14:34,  2.32s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 72, training loss=0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  4%|█▍                                     | 74/2000 [02:51<1:14:34,  2.32s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 73, training loss=7.033372639853042e-06\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  4%|█▍                                     | 75/2000 [02:54<1:14:32,  2.32s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 74, training loss=0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  4%|█▍                                     | 76/2000 [02:56<1:14:30,  2.32s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 75, training loss=0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  4%|█▌                                     | 77/2000 [02:58<1:14:26,  2.32s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 76, training loss=0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  4%|█▌                                     | 78/2000 [03:01<1:14:28,  2.32s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 77, training loss=3.4570753086882178e-06\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  4%|█▌                                     | 79/2000 [03:03<1:14:24,  2.32s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 78, training loss=0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  4%|█▌                                     | 80/2000 [03:05<1:14:24,  2.33s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 79, training loss=0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  4%|█▌                                     | 81/2000 [03:08<1:14:24,  2.33s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 80, training loss=0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  4%|█▌                                     | 82/2000 [03:10<1:14:25,  2.33s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 81, training loss=0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  4%|█▌                                     | 83/2000 [03:12<1:14:26,  2.33s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 82, training loss=4.172333774477011e-06\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  4%|█▋                                     | 84/2000 [03:15<1:14:21,  2.33s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 83, training loss=0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  4%|█▋                                     | 85/2000 [03:17<1:14:22,  2.33s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 84, training loss=2.3841860752327193e-07\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  4%|█▋                                     | 86/2000 [03:19<1:14:27,  2.33s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 85, training loss=0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  4%|█▋                                     | 87/2000 [03:22<1:14:20,  2.33s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 86, training loss=0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  4%|█▋                                     | 88/2000 [03:24<1:14:14,  2.33s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 87, training loss=6.55653229841846e-06\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  4%|█▋                                     | 89/2000 [03:26<1:14:07,  2.33s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 88, training loss=0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  4%|█▊                                     | 90/2000 [03:29<1:14:06,  2.33s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 89, training loss=0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  5%|█▊                                     | 91/2000 [03:31<1:14:05,  2.33s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 90, training loss=0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  5%|█▊                                     | 92/2000 [03:33<1:14:05,  2.33s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 91, training loss=0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  5%|█▊                                     | 93/2000 [03:36<1:14:08,  2.33s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 92, training loss=0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  5%|█▊                                     | 94/2000 [03:38<1:14:09,  2.33s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 93, training loss=0.00015498408174607903\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  5%|█▊                                     | 95/2000 [03:40<1:14:07,  2.33s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 94, training loss=0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  5%|█▊                                     | 96/2000 [03:43<1:14:04,  2.33s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 95, training loss=0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  5%|█▉                                     | 97/2000 [03:45<1:14:05,  2.34s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 96, training loss=0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  5%|█▉                                     | 98/2000 [03:47<1:13:56,  2.33s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 97, training loss=0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  5%|█▉                                     | 99/2000 [03:50<1:13:54,  2.33s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 98, training loss=0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  5%|█▉                                     | 99/2000 [03:51<1:13:59,  2.34s/it]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Input \u001b[0;32mIn [41]\u001b[0m, in \u001b[0;36m<cell line: 42>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     38\u001b[0m     \u001b[38;5;66;03m#show_plot(epoch, loss)\u001b[39;00m\n\u001b[1;32m     40\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m model\n\u001b[0;32m---> 42\u001b[0m model \u001b[38;5;241m=\u001b[39m \u001b[43mtrain\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "Input \u001b[0;32mIn [41]\u001b[0m, in \u001b[0;36mtrain\u001b[0;34m()\u001b[0m\n\u001b[1;32m     12\u001b[0m epoch_loss \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m\n\u001b[1;32m     13\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m i, (x, y) \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(loader):\n\u001b[0;32m---> 15\u001b[0m     x \u001b[38;5;241m=\u001b[39m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfrom_numpy\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mto\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241m.\u001b[39mfloat()\n\u001b[1;32m     16\u001b[0m     y \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mfrom_numpy(np\u001b[38;5;241m.\u001b[39marray([y]))\u001b[38;5;241m.\u001b[39mto(device)\u001b[38;5;241m.\u001b[39mfloat()\n\u001b[1;32m     18\u001b[0m     \u001b[38;5;66;03m#vol0, vol1 , label = data\u001b[39;00m\n\u001b[1;32m     19\u001b[0m     \u001b[38;5;66;03m#vol0, vol1 , label = vol0.to(device), vol1.to(device) , label.to(device)\u001b[39;00m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "from tqdm import tqdm\n",
    "\n",
    "def train():\n",
    "    if torch.cuda.is_available():\n",
    "        device = torch.device(\"cuda\")\n",
    "    else:\n",
    "        device = torch.device(\"cpu\")\n",
    "        \n",
    "    loss=[] \n",
    "    counter=[]\n",
    "    for epoch in tqdm(range(epochs)):\n",
    "        epoch_loss = 0\n",
    "        for i, (x, y) in enumerate(loader):\n",
    "            \n",
    "            x = torch.from_numpy(x).to(device).float()\n",
    "            y = torch.from_numpy(np.array([y])).to(device).float()\n",
    "            \n",
    "            #vol0, vol1 , label = data\n",
    "            #vol0, vol1 , label = vol0.to(device), vol1.to(device) , label.to(device)\n",
    "            \n",
    "            optimizer.zero_grad()\n",
    "            \n",
    "            pred = model(x).mean(axis = 1).sigmoid()\n",
    "            #print(model(x))\n",
    "            #output1 = model(vol0)\n",
    "            #output2 = model(vol1)\n",
    "            \n",
    "            #print(pred,y)\n",
    "            loss = loss_function(pred, y)\n",
    "            #loss_contrastive = loss_function(output1,output2,label)\n",
    "            \n",
    "            loss.backward()\n",
    "            optimizer.step()    \n",
    "            epoch_loss += loss\n",
    "            \n",
    "        print(f\"epoch {epoch}, training loss={epoch_loss}\")\n",
    "    \n",
    "    #show_plot(epoch, loss)\n",
    "    \n",
    "    return model\n",
    "\n",
    "model = train()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "46e8ae0a-3ca1-476b-8055-32e418c702fd",
   "metadata": {},
   "source": [
    "# Implementing the Siamese Network\n",
    "\n",
    "The above training is just to test if the VGG model works for 3D data. Here, the training will take two pairs of images and calculate the loss from both pairs of images."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "3afd5827-5f98-435c-b1c6-9c212d20dbf8",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import tqdm\n",
    "\n",
    "def train():\n",
    "    if torch.cuda.is_available():\n",
    "        device = torch.device(\"cuda\")\n",
    "    else:\n",
    "        device = torch.device(\"cpu\")\n",
    "        \n",
    "    loss=[] \n",
    "    counter=[]\n",
    "    for epoch in tqdm(range(epochs)):\n",
    "        epoch_loss = 0\n",
    "        for i, (x, y) in enumerate(loader):\n",
    "            \n",
    "            x = torch.from_numpy(x).to(device).float()\n",
    "            y = torch.from_numpy(np.array([y])).to(device).float()\n",
    "            \n",
    "            #vol0, vol1 , label = data\n",
    "            #vol0, vol1 , label = vol0.to(device), vol1.to(device) , label.to(device)\n",
    "            \n",
    "            optimizer.zero_grad()\n",
    "            \n",
    "            pred = model(x).mean(axis = 1).sigmoid()\n",
    "            #print(model(x))\n",
    "            #output1 = model(vol0)\n",
    "            #output2 = model(vol1)\n",
    "            \n",
    "            #print(pred,y)\n",
    "            loss = loss_function(pred, y)\n",
    "            #loss_contrastive = loss_function(output1,output2,label)\n",
    "            \n",
    "            loss.backward()\n",
    "            optimizer.step()    \n",
    "            epoch_loss += loss\n",
    "            \n",
    "        print(f\"epoch {epoch}, training loss={epoch_loss}\")\n",
    "    \n",
    "    return model\n",
    "\n",
    "model = train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "6a57bab7-f476-4415-aab3-ce1d7a1cd173",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1, 1, 128, 128, 128)\n",
      "1\n",
      "(1, 1, 128, 128, 128)\n",
      "0\n"
     ]
    }
   ],
   "source": [
    "for i, (x, y) in enumerate(loader):\n",
    "    #print(i)\n",
    "    print(np.shape(x))\n",
    "    print((y))\n",
    "#print(x)\n",
    "#print(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba92e1a0-0318-41d5-9b7b-ab2a98211d83",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
